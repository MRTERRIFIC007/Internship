{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Sequence-to-Sequence Models: Fundamentals and Concepts\n",
        "\n",
        "## Learning Objectives\n",
        "- Understand the core problem that sequence-to-sequence models solve\n",
        "- Learn about the limitations of traditional neural networks for variable-length input/output\n",
        "- Explore real-world applications of seq2seq models\n",
        "- Grasp the intuition behind encoder-decoder architectures\n",
        "\n",
        "## The Sequence-to-Sequence Problem\n",
        "\n",
        "Traditional neural networks have fixed input and output dimensions. But many real-world problems require:\n",
        "- **Variable-length inputs**: Sentences, paragraphs, DNA sequences\n",
        "- **Variable-length outputs**: Translations, summaries, responses\n",
        "- **Different input/output lengths**: \"Hi\" ‚Üí \"Bonjour\" (2 chars ‚Üí 7 chars)\n",
        "\n",
        "This notebook explores the fundamental concepts behind sequence-to-sequence modeling.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "import random\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "random.seed(42)\n",
        "\n",
        "print(\"PyTorch Version:\", torch.__version__)\n",
        "print(\"CUDA Available:\", torch.cuda.is_available())\n",
        "\n",
        "# Set style for plots\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Problem 1: Traditional Neural Networks vs. Variable Sequences\n",
        "\n",
        "Let's start by understanding why traditional neural networks struggle with variable-length sequences.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example: Traditional neural network with fixed dimensions\n",
        "class TraditionalNN(nn.Module):\n",
        "    def __init__(self, input_size=10, hidden_size=20, output_size=5):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
        "        self.relu = nn.ReLU()\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# This works fine for fixed-size inputs\n",
        "traditional_model = TraditionalNN()\n",
        "fixed_input = torch.randn(1, 10)  # Batch size 1, 10 features\n",
        "output = traditional_model(fixed_input)\n",
        "print(f\"Input shape: {fixed_input.shape}\")\n",
        "print(f\"Output shape: {output.shape}\")\n",
        "\n",
        "# But what if we have variable-length sequences?\n",
        "sentences = [\n",
        "    \"Hello\",\n",
        "    \"How are you today?\",\n",
        "    \"This is a much longer sentence with many words\",\n",
        "    \"Hi\"\n",
        "]\n",
        "\n",
        "print(\"\\nVariable-length sentence examples:\")\n",
        "for i, sentence in enumerate(sentences):\n",
        "    print(f\"Sentence {i+1}: '{sentence}' (length: {len(sentence.split())} words)\")\n",
        "\n",
        "print(\"\\nProblem: How do we feed these into a traditional neural network?\")\n",
        "print(\"- Different input sizes: Can't use fixed Linear layers\")\n",
        "print(\"- Different output needs: Translations have different lengths\")\n",
        "print(\"- Information loss: How to represent variable content in fixed size?\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Real-World Sequence-to-Sequence Applications\n",
        "\n",
        "Let's explore some concrete examples where we need to transform one sequence into another.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Real-world sequence-to-sequence examples\n",
        "seq2seq_examples = {\n",
        "    \"Machine Translation\": {\n",
        "        \"input\": \"Hello, how are you?\",\n",
        "        \"output\": \"Bonjour, comment allez-vous?\",\n",
        "        \"challenge\": \"Different languages have different word orders and lengths\"\n",
        "    },\n",
        "    \"Text Summarization\": {\n",
        "        \"input\": \"The quick brown fox jumps over the lazy dog. This sentence contains every letter of the alphabet.\",\n",
        "        \"output\": \"Sentence with all alphabet letters.\",\n",
        "        \"challenge\": \"Output much shorter than input, must capture key information\"\n",
        "    },\n",
        "    \"Question Answering\": {\n",
        "        \"input\": \"What is the capital of France? Context: France is a country in Europe with Paris as its capital.\",\n",
        "        \"output\": \"Paris\",\n",
        "        \"challenge\": \"Extract specific information from longer context\"\n",
        "    },\n",
        "    \"Code Generation\": {\n",
        "        \"input\": \"Create a function that adds two numbers\",\n",
        "        \"output\": \"def add_numbers(a, b):\\n    return a + b\",\n",
        "        \"challenge\": \"Natural language to structured code with syntax\"\n",
        "    },\n",
        "    \"Chatbot Response\": {\n",
        "        \"input\": \"I'm feeling sad today\",\n",
        "        \"output\": \"I'm sorry to hear that. What's been bothering you?\",\n",
        "        \"challenge\": \"Context-aware, empathetic response generation\"\n",
        "    }\n",
        "}\n",
        "\n",
        "# Visualize the examples\n",
        "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i, (task, example) in enumerate(seq2seq_examples.items()):\n",
        "    if i < len(axes):\n",
        "        ax = axes[i]\n",
        "        \n",
        "        # Calculate lengths\n",
        "        input_len = len(example[\"input\"].split())\n",
        "        output_len = len(example[\"output\"].split())\n",
        "        \n",
        "        # Create bar chart\n",
        "        ax.bar(['Input', 'Output'], [input_len, output_len], \n",
        "               color=['skyblue', 'lightcoral'], alpha=0.7)\n",
        "        ax.set_title(f'{task}\\nLength Comparison', fontsize=10, fontweight='bold')\n",
        "        ax.set_ylabel('Word Count')\n",
        "        \n",
        "        # Add example text as annotation\n",
        "        ax.text(0.5, max(input_len, output_len) * 0.8, \n",
        "                f'Input: \"{example[\"input\"][:30]}...\"\\nOutput: \"{example[\"output\"][:30]}...\"',\n",
        "                ha='center', va='top', fontsize=8, \n",
        "                bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"wheat\", alpha=0.7))\n",
        "\n",
        "# Remove empty subplot\n",
        "if len(seq2seq_examples) < len(axes):\n",
        "    axes[-1].remove()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.suptitle('Sequence-to-Sequence Applications: Input vs Output Lengths', \n",
        "             fontsize=14, fontweight='bold', y=0.98)\n",
        "plt.show()\n",
        "\n",
        "# Print detailed examples\n",
        "print(\"Detailed Sequence-to-Sequence Examples:\\n\")\n",
        "for task, example in seq2seq_examples.items():\n",
        "    print(f\"=== {task} ===\")\n",
        "    print(f\"Input:  '{example['input']}'\")\n",
        "    print(f\"Output: '{example['output']}'\")\n",
        "    print(f\"Challenge: {example['challenge']}\")\n",
        "    print(f\"Input length: {len(example['input'].split())} words\")\n",
        "    print(f\"Output length: {len(example['output'].split())} words\")\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## The Encoder-Decoder Intuition\n",
        "\n",
        "The breakthrough insight was to split the problem into two parts:\n",
        "1. **Encoder**: Understand and compress the input sequence into a fixed-size representation\n",
        "2. **Decoder**: Generate the output sequence from this compressed representation\n",
        "\n",
        "Think of it like a human translator:\n",
        "- **Reading phase** (Encoder): Read and understand the entire source sentence\n",
        "- **Writing phase** (Decoder): Generate the translation word by word\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize the encoder-decoder concept\n",
        "def create_encoder_decoder_diagram():\n",
        "    fig, ax = plt.subplots(1, 1, figsize=(14, 8))\n",
        "    \n",
        "    # Input sequence\n",
        "    input_words = [\"Hello\", \"world\", \"!\"]\n",
        "    input_positions = np.arange(len(input_words))\n",
        "    \n",
        "    # Context vector position\n",
        "    context_pos = len(input_words) + 1\n",
        "    \n",
        "    # Output sequence\n",
        "    output_words = [\"Bonjour\", \"le\", \"monde\", \"!\"]\n",
        "    output_positions = np.arange(context_pos + 2, context_pos + 2 + len(output_words))\n",
        "    \n",
        "    # Draw input sequence\n",
        "    for i, word in enumerate(input_words):\n",
        "        rect = plt.Rectangle((i-0.4, 0.5), 0.8, 0.8, \n",
        "                           facecolor='lightblue', edgecolor='blue', linewidth=2)\n",
        "        ax.add_patch(rect)\n",
        "        ax.text(i, 0.9, word, ha='center', va='center', fontweight='bold')\n",
        "    \n",
        "    # Draw arrows from input to context\n",
        "    for i in range(len(input_words)):\n",
        "        ax.arrow(i, 0.5, context_pos - i - 0.1, -0.3, \n",
        "                head_width=0.1, head_length=0.1, fc='red', ec='red')\n",
        "    \n",
        "    # Draw context vector\n",
        "    rect = plt.Rectangle((context_pos-0.6, -0.4), 1.2, 1.2, \n",
        "                       facecolor='yellow', edgecolor='orange', linewidth=3)\n",
        "    ax.add_patch(rect)\n",
        "    ax.text(context_pos, 0.2, 'Context\\nVector', ha='center', va='center', \n",
        "            fontweight='bold', fontsize=12)\n",
        "    \n",
        "    # Draw arrows from context to output\n",
        "    for i, pos in enumerate(output_positions):\n",
        "        ax.arrow(context_pos + 0.1, 0.2, pos - context_pos - 0.2, 0.6, \n",
        "                head_width=0.1, head_length=0.1, fc='green', ec='green')\n",
        "    \n",
        "    # Draw output sequence\n",
        "    for i, (word, pos) in enumerate(zip(output_words, output_positions)):\n",
        "        rect = plt.Rectangle((pos-0.4, 0.9), 0.8, 0.8, \n",
        "                           facecolor='lightgreen', edgecolor='green', linewidth=2)\n",
        "        ax.add_patch(rect)\n",
        "        ax.text(pos, 1.3, word, ha='center', va='center', fontweight='bold')\n",
        "    \n",
        "    # Labels\n",
        "    ax.text(len(input_words)/2 - 0.5, -0.8, 'ENCODER', ha='center', va='center', \n",
        "            fontsize=14, fontweight='bold', color='blue')\n",
        "    ax.text(np.mean(output_positions), 2.1, 'DECODER', ha='center', va='center', \n",
        "            fontsize=14, fontweight='bold', color='green')\n",
        "    \n",
        "    # Set limits and remove axes\n",
        "    ax.set_xlim(-1, max(output_positions) + 1)\n",
        "    ax.set_ylim(-1.2, 2.5)\n",
        "    ax.set_aspect('equal')\n",
        "    ax.axis('off')\n",
        "    \n",
        "    plt.title('Encoder-Decoder Architecture Concept', fontsize=16, fontweight='bold', pad=20)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "create_encoder_decoder_diagram()\n",
        "\n",
        "# Explain the process step by step\n",
        "print(\"Encoder-Decoder Process:\")\n",
        "print(\"1. ENCODER reads input sequence word by word\")\n",
        "print(\"2. ENCODER creates a fixed-size context vector containing sequence information\")\n",
        "print(\"3. DECODER takes context vector and generates output sequence word by word\")\n",
        "print(\"4. Each decoder step uses previous word and context to predict next word\")\n",
        "print(\"\\nKey Innovation: Fixed-size context vector bridges variable-length sequences!\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Simple Example: Number Sequence Transformation\n",
        "\n",
        "Let's create a simple example to understand the concept better. We'll transform sequences of numbers.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simple seq2seq task: reverse a sequence of numbers\n",
        "def generate_reverse_data(num_samples=1000, max_length=10):\n",
        "    \"\"\"Generate data for sequence reversal task\"\"\"\n",
        "    data = []\n",
        "    \n",
        "    for _ in range(num_samples):\n",
        "        # Random length between 3 and max_length\n",
        "        length = random.randint(3, max_length)\n",
        "        \n",
        "        # Random sequence of numbers 1-9\n",
        "        sequence = [random.randint(1, 9) for _ in range(length)]\n",
        "        \n",
        "        # Target is the reversed sequence\n",
        "        target = sequence[::-1]\n",
        "        \n",
        "        data.append((sequence, target))\n",
        "    \n",
        "    return data\n",
        "\n",
        "# Generate sample data\n",
        "sample_data = generate_reverse_data(10, 6)\n",
        "\n",
        "print(\"Sample Sequence Reversal Data:\")\n",
        "print(\"Input -> Target\")\n",
        "print(\"-\" * 30)\n",
        "for i, (input_seq, target_seq) in enumerate(sample_data):\n",
        "    print(f\"{input_seq} -> {target_seq}\")\n",
        "\n",
        "# Analyze the data characteristics\n",
        "all_input_lengths = [len(seq[0]) for seq in sample_data]\n",
        "all_output_lengths = [len(seq[1]) for seq in sample_data]\n",
        "\n",
        "print(f\"\\nData Characteristics:\")\n",
        "print(f\"Input lengths: {sorted(set(all_input_lengths))}\")\n",
        "print(f\"Output lengths: {sorted(set(all_output_lengths))}\")\n",
        "print(f\"Same length? {all_input_lengths == all_output_lengths}\")\n",
        "\n",
        "# Visualize length distribution\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "# Length distribution\n",
        "length_counts = Counter(all_input_lengths)\n",
        "ax1.bar(length_counts.keys(), length_counts.values(), color='skyblue', alpha=0.7)\n",
        "ax1.set_xlabel('Sequence Length')\n",
        "ax1.set_ylabel('Count')\n",
        "ax1.set_title('Sequence Length Distribution')\n",
        "\n",
        "# Sample sequences visualization\n",
        "ax2.barh(range(len(sample_data[:5])), [len(seq[0]) for seq in sample_data[:5]], \n",
        "         color='lightgreen', alpha=0.7, label='Input')\n",
        "ax2.barh(range(len(sample_data[:5])), [len(seq[1]) for seq in sample_data[:5]], \n",
        "         color='lightcoral', alpha=0.7, label='Output')\n",
        "ax2.set_xlabel('Length')\n",
        "ax2.set_ylabel('Sample Index')\n",
        "ax2.set_title('Input vs Output Lengths (First 5 samples)')\n",
        "ax2.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nKey Observations:\")\n",
        "print(\"1. Input and output have same length (for reversal task)\")\n",
        "print(\"2. But in general, seq2seq models handle different input/output lengths\")\n",
        "print(\"3. This is a simple task to understand the encoder-decoder concept\")\n",
        "print(\"4. Encoder must capture the entire sequence information\")\n",
        "print(\"5. Decoder must generate sequence in reverse order\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Understanding the Context Vector Challenge\n",
        "\n",
        "The context vector is the heart of the encoder-decoder architecture, but it's also its biggest limitation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Demonstrate the context vector bottleneck problem\n",
        "def simulate_context_vector_limitation():\n",
        "    \"\"\"Simulate how information gets compressed in context vector\"\"\"\n",
        "    \n",
        "    # Different length sequences\n",
        "    sequences = [\n",
        "        \"Hi\",\n",
        "        \"Hello there\",\n",
        "        \"How are you doing today my friend\",\n",
        "        \"This is a very long sentence with lots of important information that needs to be preserved\"\n",
        "    ]\n",
        "    \n",
        "    # Simulate fixed-size context vector (e.g., 128 dimensions)\n",
        "    context_size = 128\n",
        "    \n",
        "    print(\"Context Vector Information Compression:\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    for i, seq in enumerate(sequences):\n",
        "        words = seq.split()\n",
        "        input_info = len(words) * 50  # Assume each word has 50 \"units\" of information\n",
        "        \n",
        "        # Information loss calculation (simplified)\n",
        "        compression_ratio = input_info / context_size\n",
        "        information_retained = min(100, 100 / compression_ratio)\n",
        "        \n",
        "        print(f\"\\nSequence {i+1}: '{seq}'\")\n",
        "        print(f\"  Input length: {len(words)} words\")\n",
        "        print(f\"  Estimated input information: {input_info} units\")\n",
        "        print(f\"  Context vector size: {context_size} units\")\n",
        "        print(f\"  Compression ratio: {compression_ratio:.2f}x\")\n",
        "        print(f\"  Information retained: {information_retained:.1f}%\")\n",
        "        \n",
        "        if compression_ratio > 2:\n",
        "            print(\"  ‚ö†Ô∏è  HIGH COMPRESSION - Potential information loss!\")\n",
        "        elif compression_ratio > 1.5:\n",
        "            print(\"  ‚ö†Ô∏è  MODERATE COMPRESSION - Some information loss\")\n",
        "        else:\n",
        "            print(\"  ‚úÖ LOW COMPRESSION - Most information preserved\")\n",
        "\n",
        "simulate_context_vector_limitation()\n",
        "\n",
        "# Visualize the bottleneck effect\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# Sequence lengths vs context vector size\n",
        "seq_lengths = [2, 3, 8, 16, 32, 64]\n",
        "context_size = 128\n",
        "information_units = [length * 50 for length in seq_lengths]\n",
        "\n",
        "ax1.plot(seq_lengths, information_units, 'bo-', linewidth=2, markersize=8, label='Input Information')\n",
        "ax1.axhline(y=context_size, color='red', linestyle='--', linewidth=2, label='Context Vector Capacity')\n",
        "ax1.fill_between(seq_lengths, 0, context_size, alpha=0.3, color='red', label='Context Vector Limit')\n",
        "ax1.set_xlabel('Sequence Length (words)')\n",
        "ax1.set_ylabel('Information Units')\n",
        "ax1.set_title('Information Bottleneck Problem')\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Information retention percentage\n",
        "retention = [min(100, 100 * context_size / info) for info in information_units]\n",
        "ax2.plot(seq_lengths, retention, 'ro-', linewidth=2, markersize=8)\n",
        "ax2.axhline(y=100, color='green', linestyle='--', alpha=0.7, label='Perfect Retention')\n",
        "ax2.axhline(y=50, color='orange', linestyle='--', alpha=0.7, label='50% Retention')\n",
        "ax2.set_xlabel('Sequence Length (words)')\n",
        "ax2.set_ylabel('Information Retained (%)')\n",
        "ax2.set_title('Information Retention vs Sequence Length')\n",
        "ax2.legend()\n",
        "ax2.grid(True, alpha=0.3)\n",
        "ax2.set_ylim(0, 105)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nüîç Key Insights:\")\n",
        "print(\"1. Fixed-size context vector creates an information bottleneck\")\n",
        "print(\"2. Longer sequences suffer more information loss\")\n",
        "print(\"3. This is why basic seq2seq models struggle with long sequences\")\n",
        "print(\"4. Tomorrow we'll learn about attention mechanisms to solve this!\")\n",
        "print(\"\\nüí° This limitation led to the invention of attention mechanisms!\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Summary and Next Steps\n",
        "\n",
        "### What We've Learned Today\n",
        "1. **Problem Definition**: Traditional neural networks can't handle variable-length input/output sequences\n",
        "2. **Encoder-Decoder Solution**: Split the problem into understanding (encoder) and generation (decoder)\n",
        "3. **Context Vector**: Fixed-size representation that bridges variable-length sequences\n",
        "4. **Information Bottleneck**: The fundamental limitation of basic encoder-decoder models\n",
        "\n",
        "### Key Takeaways\n",
        "- Sequence-to-sequence models enable many important NLP applications\n",
        "- The encoder-decoder paradigm is intuitive and powerful\n",
        "- Context vector creates an information bottleneck for long sequences\n",
        "- This limitation motivates the need for attention mechanisms\n",
        "\n",
        "### Tomorrow's Preview\n",
        "We'll dive deep into attention mechanisms that solve the information bottleneck problem by allowing the decoder to \"attend\" to different parts of the input sequence at each generation step.\n",
        "\n",
        "### Personal Reflections\n",
        "- The encoder-decoder concept feels like how humans process language\n",
        "- Understanding the context vector limitation helps appreciate why attention was revolutionary\n",
        "- Looking forward to implementing actual encoder-decoder models tomorrow!\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
