{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Multi-Task Learning Strategies with T5\n",
        "\n",
        "## Learning Objectives\n",
        "- Understand multi-task learning principles and benefits\n",
        "- Explore different task sampling strategies\n",
        "- Learn about task interference and positive transfer\n",
        "- Implement task balancing techniques\n",
        "- Analyze multi-task training dynamics\n",
        "\n",
        "## What is Multi-Task Learning?\n",
        "Multi-task learning (MTL) is a machine learning approach where a model learns multiple related tasks simultaneously. In T5's context, this means training one model to handle multiple NLP tasks like translation, summarization, and classification together.\n",
        "\n",
        "## Benefits of Multi-Task Learning\n",
        "1. **Shared Representations**: Common patterns across tasks\n",
        "2. **Data Efficiency**: Tasks with limited data benefit from others\n",
        "3. **Generalization**: Better performance on unseen data\n",
        "4. **Resource Efficiency**: One model instead of many\n",
        "5. **Transfer Learning**: Knowledge transfer between tasks\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import defaultdict, Counter\n",
        "import random\n",
        "from typing import List, Dict, Tuple\n",
        "import math\n",
        "\n",
        "# Set style for better visualizations\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "random.seed(42)\n",
        "\n",
        "print(\"Libraries imported successfully!\")\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"Device available: {'GPU' if torch.cuda.is_available() else 'CPU'}\")\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 1. Task Sampling Strategies\n",
        "\n",
        "In multi-task learning, we need to decide how to sample examples from different tasks during training. Different strategies can lead to very different outcomes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TaskSampler:\n",
        "    \"\"\"Implements different task sampling strategies for multi-task learning\"\"\"\n",
        "    \n",
        "    def __init__(self, task_sizes: Dict[str, int]):\n",
        "        self.task_sizes = task_sizes\n",
        "        self.total_examples = sum(task_sizes.values())\n",
        "        self.tasks = list(task_sizes.keys())\n",
        "    \n",
        "    def uniform_sampling(self, num_samples: int) -> List[str]:\n",
        "        \"\"\"Sample tasks uniformly (equal probability for each task)\"\"\"\n",
        "        return random.choices(self.tasks, k=num_samples)\n",
        "    \n",
        "    def proportional_sampling(self, num_samples: int) -> List[str]:\n",
        "        \"\"\"Sample tasks proportionally to their dataset sizes\"\"\"\n",
        "        weights = [self.task_sizes[task] / self.total_examples for task in self.tasks]\n",
        "        return random.choices(self.tasks, weights=weights, k=num_samples)\n",
        "    \n",
        "    def temperature_sampling(self, num_samples: int, temperature: float = 0.5) -> List[str]:\n",
        "        \"\"\"Sample with temperature scaling to balance between uniform and proportional\"\"\"\n",
        "        # Apply temperature scaling to dataset sizes\n",
        "        scaled_sizes = [size ** (1/temperature) for size in self.task_sizes.values()]\n",
        "        total_scaled = sum(scaled_sizes)\n",
        "        weights = [size / total_scaled for size in scaled_sizes]\n",
        "        return random.choices(self.tasks, weights=weights, k=num_samples)\n",
        "    \n",
        "    def sqrt_sampling(self, num_samples: int) -> List[str]:\n",
        "        \"\"\"Square root sampling - compromise between uniform and proportional\"\"\"\n",
        "        sqrt_sizes = [math.sqrt(size) for size in self.task_sizes.values()]\n",
        "        total_sqrt = sum(sqrt_sizes)\n",
        "        weights = [size / total_sqrt for size in sqrt_sizes]\n",
        "        return random.choices(self.tasks, weights=weights, k=num_samples)\n",
        "\n",
        "# Example task dataset sizes (realistic scenario)\n",
        "task_sizes = {\n",
        "    'translation': 1000000,  # Large dataset\n",
        "    'sentiment': 50000,      # Medium dataset\n",
        "    'summarization': 10000,  # Small dataset\n",
        "    'qa': 25000,            # Medium-small dataset\n",
        "    'classification': 75000  # Medium-large dataset\n",
        "}\n",
        "\n",
        "sampler = TaskSampler(task_sizes)\n",
        "\n",
        "# Compare different sampling strategies\n",
        "num_samples = 10000\n",
        "strategies = {\n",
        "    'Uniform': sampler.uniform_sampling(num_samples),\n",
        "    'Proportional': sampler.proportional_sampling(num_samples),\n",
        "    'Temperature (T=0.5)': sampler.temperature_sampling(num_samples, 0.5),\n",
        "    'Square Root': sampler.sqrt_sampling(num_samples)\n",
        "}\n",
        "\n",
        "# Analyze sampling results\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i, (strategy_name, samples) in enumerate(strategies.items()):\n",
        "    task_counts = Counter(samples)\n",
        "    \n",
        "    # Create bar plot\n",
        "    tasks = list(task_sizes.keys())\n",
        "    counts = [task_counts[task] for task in tasks]\n",
        "    \n",
        "    bars = axes[i].bar(tasks, counts, alpha=0.8)\n",
        "    axes[i].set_title(f'{strategy_name} Sampling', fontweight='bold')\n",
        "    axes[i].set_ylabel('Number of Samples')\n",
        "    axes[i].tick_params(axis='x', rotation=45)\n",
        "    \n",
        "    # Add value labels on bars\n",
        "    for bar, count in zip(bars, counts):\n",
        "        height = bar.get_height()\n",
        "        axes[i].text(bar.get_x() + bar.get_width()/2., height + 50,\n",
        "                    f'{count}', ha='center', va='bottom')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print detailed statistics\n",
        "print(\"TASK SAMPLING COMPARISON\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"Original dataset sizes:\")\n",
        "for task, size in task_sizes.items():\n",
        "    print(f\"  {task}: {size:,} examples\")\n",
        "\n",
        "print(f\"\\nSampling results ({num_samples:,} samples):\")\n",
        "for strategy_name, samples in strategies.items():\n",
        "    task_counts = Counter(samples)\n",
        "    print(f\"\\n{strategy_name}:\")\n",
        "    for task in task_sizes.keys():\n",
        "        count = task_counts[task]\n",
        "        percentage = count / num_samples * 100\n",
        "        print(f\"  {task}: {count} ({percentage:.1f}%)\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 2. Task Interference vs Positive Transfer\n",
        "\n",
        "In multi-task learning, tasks can either help each other (positive transfer) or hurt each other (negative transfer/interference). Understanding this is crucial for successful multi-task training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analysis complete - this notebook demonstrates core multi-task learning concepts\n",
        "print(\"MULTI-TASK LEARNING STRATEGIES ANALYSIS COMPLETE\")\n",
        "print(\"=\" * 60)\n",
        "print(\"Key Insights:\")\n",
        "print(\"1. Different sampling strategies lead to very different task coverage\")\n",
        "print(\"2. Proportional sampling can overwhelm smaller datasets\")\n",
        "print(\"3. Temperature and sqrt sampling provide good balance\")\n",
        "print(\"4. Task relationships matter for positive/negative transfer\")\n",
        "print(\"5. Strategic task weighting can improve overall performance\")\n",
        "print()\n",
        "print(\"Next Steps:\")\n",
        "print(\"- Experiment with real T5 models\")\n",
        "print(\"- Try different temperature values\")\n",
        "print(\"- Monitor individual task performance during training\")\n",
        "print(\"- Consider task curriculum strategies\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simulate task relationships and transfer effects\n",
        "\n",
        "def simulate_task_relationships():\n",
        "    \"\"\"Simulate how different tasks might affect each other\"\"\"\n",
        "    \n",
        "    tasks = ['sentiment', 'translation', 'summarization', 'qa', 'classification']\n",
        "    \n",
        "    # Simulated transfer matrix (how much task A helps/hurts task B)\n",
        "    # Positive values = positive transfer, negative = interference\n",
        "    transfer_matrix = np.array([\n",
        "        # sent  trans  summ   qa    class\n",
        "        [ 0.0,  0.1,   0.2,  0.15,  0.3],  # sentiment\n",
        "        [ 0.1,  0.0,   0.05, 0.1,   0.05], # translation\n",
        "        [ 0.2,  0.05,  0.0,  0.25,  0.1],  # summarization\n",
        "        [ 0.15, 0.1,   0.25, 0.0,   0.2],  # qa\n",
        "        [ 0.3,  0.05,  0.1,  0.2,   0.0]   # classification\n",
        "    ])\n",
        "    \n",
        "    # Simulate single-task baseline performance\n",
        "    single_task_performance = {\n",
        "        'sentiment': 0.85,\n",
        "        'translation': 0.72,\n",
        "        'summarization': 0.68,\n",
        "        'qa': 0.78,\n",
        "        'classification': 0.82\n",
        "    }\n",
        "    \n",
        "    return tasks, transfer_matrix, single_task_performance\n",
        "\n",
        "def calculate_multitask_performance(tasks, transfer_matrix, single_task_perf, task_weights):\n",
        "    \"\"\"Calculate expected multi-task performance given task weights\"\"\"\n",
        "    multitask_perf = {}\n",
        "    \n",
        "    for i, task in enumerate(tasks):\n",
        "        # Start with single-task performance\n",
        "        performance = single_task_perf[task]\n",
        "        \n",
        "        # Add transfer effects from other tasks\n",
        "        for j, other_task in enumerate(tasks):\n",
        "            if i != j:  # Don't include self-transfer\n",
        "                transfer_effect = transfer_matrix[j, i] * task_weights[other_task]\n",
        "                performance += transfer_effect\n",
        "        \n",
        "        multitask_perf[task] = max(0, min(1, performance))  # Clamp between 0 and 1\n",
        "    \n",
        "    return multitask_perf\n",
        "\n",
        "# Get simulation data\n",
        "tasks, transfer_matrix, single_task_perf = simulate_task_relationships()\n",
        "\n",
        "# Visualize transfer matrix\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(transfer_matrix, \n",
        "            xticklabels=tasks, \n",
        "            yticklabels=tasks,\n",
        "            annot=True, \n",
        "            cmap='RdYlBu_r', \n",
        "            center=0,\n",
        "            square=True,\n",
        "            fmt='.2f')\n",
        "plt.title('Task Transfer Matrix\\n(How much source task (row) helps target task (column))', \n",
        "          fontweight='bold', fontsize=12)\n",
        "plt.ylabel('Source Task (helps →)')\n",
        "plt.xlabel('Target Task (← gets help)')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Test different task weighting scenarios\n",
        "scenarios = {\n",
        "    'Uniform': {task: 0.2 for task in tasks},\n",
        "    'Translation Heavy': {'sentiment': 0.1, 'translation': 0.5, 'summarization': 0.1, 'qa': 0.15, 'classification': 0.15},\n",
        "    'Classification Heavy': {'sentiment': 0.1, 'translation': 0.1, 'summarization': 0.1, 'qa': 0.2, 'classification': 0.5},\n",
        "    'Balanced NLU': {'sentiment': 0.25, 'translation': 0.1, 'summarization': 0.2, 'qa': 0.25, 'classification': 0.2}\n",
        "}\n",
        "\n",
        "# Calculate performance for each scenario\n",
        "results = []\n",
        "for scenario_name, task_weights in scenarios.items():\n",
        "    multitask_perf = calculate_multitask_performance(tasks, transfer_matrix, single_task_perf, task_weights)\n",
        "    \n",
        "    for task in tasks:\n",
        "        results.append({\n",
        "            'Scenario': scenario_name,\n",
        "            'Task': task,\n",
        "            'Single-Task': single_task_perf[task],\n",
        "            'Multi-Task': multitask_perf[task],\n",
        "            'Transfer Effect': multitask_perf[task] - single_task_perf[task]\n",
        "        })\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "# Visualize results\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# Performance comparison\n",
        "pivot_perf = results_df.pivot(index='Task', columns='Scenario', values='Multi-Task')\n",
        "pivot_perf.plot(kind='bar', ax=ax1, alpha=0.8)\n",
        "ax1.set_title('Multi-Task Performance by Scenario', fontweight='bold')\n",
        "ax1.set_ylabel('Performance Score')\n",
        "ax1.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "ax1.tick_params(axis='x', rotation=45)\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Transfer effect\n",
        "pivot_transfer = results_df.pivot(index='Task', columns='Scenario', values='Transfer Effect')\n",
        "pivot_transfer.plot(kind='bar', ax=ax2, alpha=0.8)\n",
        "ax2.set_title('Transfer Effect by Scenario', fontweight='bold')\n",
        "ax2.set_ylabel('Performance Change')\n",
        "ax2.axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
        "ax2.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "ax2.tick_params(axis='x', rotation=45)\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"MULTI-TASK LEARNING ANALYSIS\")\n",
        "print(\"=\" * 40)\n",
        "print(\"Transfer Effects Summary:\")\n",
        "for scenario in scenarios.keys():\n",
        "    scenario_data = results_df[results_df['Scenario'] == scenario]\n",
        "    avg_transfer = scenario_data['Transfer Effect'].mean()\n",
        "    print(f\"  {scenario}: {avg_transfer:+.3f} average transfer\")\n",
        "\n",
        "print(\"\\nBest performing scenarios per task:\")\n",
        "for task in tasks:\n",
        "    task_data = results_df[results_df['Task'] == task]\n",
        "    best_scenario = task_data.loc[task_data['Multi-Task'].idxmax(), 'Scenario']\n",
        "    best_perf = task_data['Multi-Task'].max()\n",
        "    print(f\"  {task}: {best_scenario} ({best_perf:.3f})\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
