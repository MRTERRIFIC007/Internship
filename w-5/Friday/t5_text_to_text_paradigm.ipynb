{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# T5: Text-to-Text Transfer Transformer Paradigm\n",
        "\n",
        "## Learning Objectives\n",
        "- Understand the \"Text-to-Text\" concept and its revolutionary impact\n",
        "- Learn how T5 unifies all NLP tasks under one framework\n",
        "- Explore task formatting and prefix-based training\n",
        "- Implement basic T5-style data preparation\n",
        "- Compare T5 with traditional task-specific models\n",
        "\n",
        "## The Text-to-Text Revolution\n",
        "T5 introduced a paradigm shift: **every NLP task becomes a text generation problem**\n",
        "- **Translation**: \"translate English to French: Hello\" ‚Üí \"Bonjour\"\n",
        "- **Summarization**: \"summarize: Long article...\" ‚Üí \"Short summary\"\n",
        "- **Classification**: \"sentiment: I love this movie\" ‚Üí \"positive\"\n",
        "- **Question Answering**: \"question: What is AI? context: AI is...\" ‚Üí \"Artificial Intelligence\"\n",
        "\n",
        "## Key Innovations\n",
        "- **Unified Framework**: One model architecture for all tasks\n",
        "- **Task Prefixes**: Simple text prefixes to specify the task\n",
        "- **Transfer Learning**: Pre-train on massive text, fine-tune on specific tasks\n",
        "- **Multi-Task Learning**: Train on multiple tasks simultaneously\n",
        "\n",
        "This notebook explores the conceptual foundation of T5 and its text-to-text approach.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "import re\n",
        "import random\n",
        "from typing import List, Dict, Tuple\n",
        "\n",
        "# Set style for better visualizations\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "random.seed(42)\n",
        "\n",
        "print(\"Libraries imported successfully!\")\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"Device available: {'GPU' if torch.cuda.is_available() else 'CPU'}\")\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 1. Understanding the Text-to-Text Paradigm\n",
        "\n",
        "### Traditional Approach vs T5 Approach\n",
        "\n",
        "**Traditional NLP**: Different models for different tasks\n",
        "- **Classification**: Input text ‚Üí Class probability distribution\n",
        "- **NER**: Input text ‚Üí BIO tags for each token\n",
        "- **Translation**: Input sequence ‚Üí Output sequence\n",
        "- **QA**: Context + Question ‚Üí Answer span\n",
        "\n",
        "**T5 Approach**: All tasks become text generation\n",
        "- **Input**: Always a text string with task prefix\n",
        "- **Output**: Always a text string (the answer)\n",
        "- **Model**: Single encoder-decoder transformer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Let's create examples of how different NLP tasks are converted to text-to-text format\n",
        "\n",
        "def create_task_examples():\n",
        "    \"\"\"Create examples showing traditional vs T5 formatting\"\"\"\n",
        "    \n",
        "    examples = {\n",
        "        \"Sentiment Classification\": {\n",
        "            \"traditional\": {\n",
        "                \"input\": \"I love this movie! It's amazing.\",\n",
        "                \"output\": \"positive (probability: 0.95)\"\n",
        "            },\n",
        "            \"t5\": {\n",
        "                \"input\": \"sentiment: I love this movie! It's amazing.\",\n",
        "                \"output\": \"positive\"\n",
        "            }\n",
        "        },\n",
        "        \n",
        "        \"Translation\": {\n",
        "            \"traditional\": {\n",
        "                \"input\": \"Hello world\",\n",
        "                \"output\": \"Bonjour le monde\"\n",
        "            },\n",
        "            \"t5\": {\n",
        "                \"input\": \"translate English to French: Hello world\",\n",
        "                \"output\": \"Bonjour le monde\"\n",
        "            }\n",
        "        },\n",
        "        \n",
        "        \"Question Answering\": {\n",
        "            \"traditional\": {\n",
        "                \"input\": \"Context: Paris is the capital of France. Question: What is the capital of France?\",\n",
        "                \"output\": \"span_start: 0, span_end: 5 (Paris)\"\n",
        "            },\n",
        "            \"t5\": {\n",
        "                \"input\": \"question: What is the capital of France? context: Paris is the capital of France.\",\n",
        "                \"output\": \"Paris\"\n",
        "            }\n",
        "        },\n",
        "        \n",
        "        \"Summarization\": {\n",
        "            \"traditional\": {\n",
        "                \"input\": \"Long article about AI development spanning multiple paragraphs...\",\n",
        "                \"output\": \"Generated summary tokens with attention weights\"\n",
        "            },\n",
        "            \"t5\": {\n",
        "                \"input\": \"summarize: Long article about AI development spanning multiple paragraphs...\",\n",
        "                \"output\": \"AI development has made significant progress\"\n",
        "            }\n",
        "        },\n",
        "        \n",
        "        \"Text Generation\": {\n",
        "            \"traditional\": {\n",
        "                \"input\": \"The weather today is\",\n",
        "                \"output\": \"Next token probabilities\"\n",
        "            },\n",
        "            \"t5\": {\n",
        "                \"input\": \"generate: The weather today is\",\n",
        "                \"output\": \"sunny and warm with clear skies\"\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "    \n",
        "    return examples\n",
        "\n",
        "# Display the examples\n",
        "examples = create_task_examples()\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"TRADITIONAL APPROACH vs T5 TEXT-TO-TEXT APPROACH\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "for task, formats in examples.items():\n",
        "    print(f\"\\nüîπ {task.upper()}\")\n",
        "    print(\"-\" * 60)\n",
        "    \n",
        "    print(\"Traditional Approach:\")\n",
        "    print(f\"  Input:  {formats['traditional']['input']}\")\n",
        "    print(f\"  Output: {formats['traditional']['output']}\")\n",
        "    \n",
        "    print(\"\\nT5 Text-to-Text Approach:\")\n",
        "    print(f\"  Input:  {formats['t5']['input']}\")\n",
        "    print(f\"  Output: {formats['t5']['output']}\")\n",
        "    print()\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"KEY INSIGHT: T5 converts ALL tasks to the same input-output format!\")\n",
        "print(\"This allows one model to handle multiple tasks through task prefixes.\")\n",
        "print(\"=\" * 80)\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 2. T5 Architecture Overview\n",
        "\n",
        "T5 is based on the original Transformer architecture but with some key modifications:\n",
        "\n",
        "### Architecture Components\n",
        "1. **Encoder-Decoder Structure**: Like the original Transformer\n",
        "2. **Relative Position Embeddings**: Instead of absolute positional encoding\n",
        "3. **Layer Normalization**: Applied before (not after) each sub-layer\n",
        "4. **No Dropout**: In the final version\n",
        "5. **SentencePiece Tokenization**: Subword tokenization\n",
        "\n",
        "### Model Sizes\n",
        "- **T5-Small**: 60M parameters\n",
        "- **T5-Base**: 220M parameters  \n",
        "- **T5-Large**: 770M parameters\n",
        "- **T5-3B**: 3B parameters\n",
        "- **T5-11B**: 11B parameters\n",
        "\n",
        "### Key Differences from BERT\n",
        "- **Generative**: Can produce new text (not just representations)\n",
        "- **Text-to-Text**: Unified framework for all tasks\n",
        "- **Encoder-Decoder**: Full sequence-to-sequence capability\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Let's implement a simplified T5-style task formatter\n",
        "\n",
        "class T5TaskFormatter:\n",
        "    \"\"\"Formats different NLP tasks into T5's text-to-text format\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.task_prefixes = {\n",
        "            'sentiment': 'sentiment:',\n",
        "            'translate_en_fr': 'translate English to French:',\n",
        "            'translate_fr_en': 'translate French to English:',\n",
        "            'summarize': 'summarize:',\n",
        "            'question': 'question:',\n",
        "            'generate': 'generate:',\n",
        "            'classify': 'classify:',\n",
        "            'paraphrase': 'paraphrase:'\n",
        "        }\n",
        "    \n",
        "    def format_sentiment(self, text: str) -> str:\n",
        "        \"\"\"Format sentiment analysis task\"\"\"\n",
        "        return f\"{self.task_prefixes['sentiment']} {text}\"\n",
        "    \n",
        "    def format_translation(self, text: str, src_lang: str = 'en', tgt_lang: str = 'fr') -> str:\n",
        "        \"\"\"Format translation task\"\"\"\n",
        "        if src_lang == 'en' and tgt_lang == 'fr':\n",
        "            prefix = self.task_prefixes['translate_en_fr']\n",
        "        elif src_lang == 'fr' and tgt_lang == 'en':\n",
        "            prefix = self.task_prefixes['translate_fr_en']\n",
        "        else:\n",
        "            prefix = f\"translate {src_lang} to {tgt_lang}:\"\n",
        "        \n",
        "        return f\"{prefix} {text}\"\n",
        "    \n",
        "    def format_qa(self, question: str, context: str) -> str:\n",
        "        \"\"\"Format question answering task\"\"\"\n",
        "        return f\"{self.task_prefixes['question']} {question} context: {context}\"\n",
        "    \n",
        "    def format_summarization(self, text: str) -> str:\n",
        "        \"\"\"Format summarization task\"\"\"\n",
        "        return f\"{self.task_prefixes['summarize']} {text}\"\n",
        "    \n",
        "    def format_generation(self, prompt: str) -> str:\n",
        "        \"\"\"Format text generation task\"\"\"\n",
        "        return f\"{self.task_prefixes['generate']} {prompt}\"\n",
        "\n",
        "# Create formatter instance\n",
        "formatter = T5TaskFormatter()\n",
        "\n",
        "# Test the formatter with sample data\n",
        "print(\"T5 TASK FORMATTING EXAMPLES\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Sentiment Analysis\n",
        "sentiment_text = \"This movie was absolutely fantastic!\"\n",
        "formatted_sentiment = formatter.format_sentiment(sentiment_text)\n",
        "print(f\"Original: {sentiment_text}\")\n",
        "print(f\"T5 Format: {formatted_sentiment}\")\n",
        "print(f\"Expected Output: positive\\n\")\n",
        "\n",
        "# Translation\n",
        "english_text = \"Good morning, how are you?\"\n",
        "formatted_translation = formatter.format_translation(english_text)\n",
        "print(f\"Original: {english_text}\")\n",
        "print(f\"T5 Format: {formatted_translation}\")\n",
        "print(f\"Expected Output: Bonjour, comment allez-vous?\\n\")\n",
        "\n",
        "# Question Answering\n",
        "question = \"What is the capital of Japan?\"\n",
        "context = \"Tokyo is the capital and largest city of Japan.\"\n",
        "formatted_qa = formatter.format_qa(question, context)\n",
        "print(f\"Question: {question}\")\n",
        "print(f\"Context: {context}\")\n",
        "print(f\"T5 Format: {formatted_qa}\")\n",
        "print(f\"Expected Output: Tokyo\\n\")\n",
        "\n",
        "# Summarization\n",
        "long_text = \"Machine learning is a subset of artificial intelligence that focuses on algorithms that can learn from data. It has applications in many fields including computer vision, natural language processing, and robotics.\"\n",
        "formatted_summary = formatter.format_summarization(long_text)\n",
        "print(f\"Original: {long_text}\")\n",
        "print(f\"T5 Format: {formatted_summary}\")\n",
        "print(f\"Expected Output: ML is AI that learns from data for vision, NLP, and robotics.\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"Notice how all tasks now have the same input-output structure!\")\n",
        "print(\"This is the power of the text-to-text paradigm.\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 3. Multi-Task Dataset Creation\n",
        "\n",
        "One of T5's key strengths is its ability to learn multiple tasks simultaneously. Let's create a multi-task dataset that demonstrates this capability.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a multi-task dataset for T5 training\n",
        "\n",
        "class MultiTaskDataset:\n",
        "    \"\"\"Creates a dataset with multiple NLP tasks in T5 format\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.formatter = T5TaskFormatter()\n",
        "        self.data = []\n",
        "        self.task_counts = defaultdict(int)\n",
        "    \n",
        "    def add_sentiment_data(self):\n",
        "        \"\"\"Add sentiment analysis examples\"\"\"\n",
        "        sentiment_examples = [\n",
        "            (\"I love this product! It's amazing.\", \"positive\"),\n",
        "            (\"This is the worst thing I've ever bought.\", \"negative\"),\n",
        "            (\"The movie was okay, nothing special.\", \"neutral\"),\n",
        "            (\"Absolutely fantastic experience!\", \"positive\"),\n",
        "            (\"Terrible customer service.\", \"negative\"),\n",
        "            (\"It's an average product.\", \"neutral\"),\n",
        "            (\"Best purchase ever!\", \"positive\"),\n",
        "            (\"Complete waste of money.\", \"negative\"),\n",
        "            (\"Pretty good, would recommend.\", \"positive\"),\n",
        "            (\"Not worth the price.\", \"negative\")\n",
        "        ]\n",
        "        \n",
        "        for text, label in sentiment_examples:\n",
        "            input_text = self.formatter.format_sentiment(text)\n",
        "            self.data.append({\n",
        "                'task': 'sentiment',\n",
        "                'input': input_text,\n",
        "                'output': label\n",
        "            })\n",
        "            self.task_counts['sentiment'] += 1\n",
        "    \n",
        "    def add_translation_data(self):\n",
        "        \"\"\"Add translation examples\"\"\"\n",
        "        translation_examples = [\n",
        "            (\"Hello\", \"Bonjour\"),\n",
        "            (\"Thank you\", \"Merci\"),\n",
        "            (\"Good morning\", \"Bonjour\"),\n",
        "            (\"How are you?\", \"Comment allez-vous?\"),\n",
        "            (\"I am fine\", \"Je vais bien\"),\n",
        "            (\"What is your name?\", \"Comment vous appelez-vous?\"),\n",
        "            (\"Nice to meet you\", \"Enchant√© de vous rencontrer\"),\n",
        "            (\"See you later\", \"√Ä bient√¥t\"),\n",
        "            (\"Have a good day\", \"Bonne journ√©e\"),\n",
        "            (\"Where is the library?\", \"O√π est la biblioth√®que?\")\n",
        "        ]\n",
        "        \n",
        "        for en, fr in translation_examples:\n",
        "            # English to French\n",
        "            input_text = self.formatter.format_translation(en, 'en', 'fr')\n",
        "            self.data.append({\n",
        "                'task': 'translation_en_fr',\n",
        "                'input': input_text,\n",
        "                'output': fr\n",
        "            })\n",
        "            self.task_counts['translation_en_fr'] += 1\n",
        "            \n",
        "            # French to English\n",
        "            input_text = self.formatter.format_translation(fr, 'fr', 'en')\n",
        "            self.data.append({\n",
        "                'task': 'translation_fr_en',\n",
        "                'input': input_text,\n",
        "                'output': en\n",
        "            })\n",
        "            self.task_counts['translation_fr_en'] += 1\n",
        "    \n",
        "    def add_qa_data(self):\n",
        "        \"\"\"Add question answering examples\"\"\"\n",
        "        qa_examples = [\n",
        "            (\"What is the capital of France?\", \"Paris is the capital of France.\", \"Paris\"),\n",
        "            (\"Who invented the telephone?\", \"Alexander Graham Bell invented the telephone.\", \"Alexander Graham Bell\"),\n",
        "            (\"What is the largest planet?\", \"Jupiter is the largest planet in our solar system.\", \"Jupiter\"),\n",
        "            (\"When was Python created?\", \"Python was created by Guido van Rossum in 1991.\", \"1991\"),\n",
        "            (\"What is machine learning?\", \"Machine learning is a subset of AI that learns from data.\", \"A subset of AI that learns from data\")\n",
        "        ]\n",
        "        \n",
        "        for question, context, answer in qa_examples:\n",
        "            input_text = self.formatter.format_qa(question, context)\n",
        "            self.data.append({\n",
        "                'task': 'qa',\n",
        "                'input': input_text,\n",
        "                'output': answer\n",
        "            })\n",
        "            self.task_counts['qa'] += 1\n",
        "    \n",
        "    def add_summarization_data(self):\n",
        "        \"\"\"Add summarization examples\"\"\"\n",
        "        summarization_examples = [\n",
        "            (\"Machine learning is a branch of artificial intelligence that uses statistical techniques to give computers the ability to learn from data without being explicitly programmed.\", \"ML is AI that learns from data\"),\n",
        "            (\"Deep learning is a subset of machine learning that uses neural networks with multiple layers to model and understand complex patterns in data.\", \"Deep learning uses multi-layer neural networks for complex patterns\"),\n",
        "            (\"Natural language processing enables computers to understand, interpret, and generate human language in a valuable way.\", \"NLP helps computers understand and generate human language\"),\n",
        "            (\"Computer vision is a field of artificial intelligence that trains computers to interpret and understand the visual world from digital images and videos.\", \"Computer vision teaches AI to understand visual data\"),\n",
        "            (\"Transformers are a type of neural network architecture that has revolutionized natural language processing with their attention mechanism.\", \"Transformers revolutionized NLP with attention mechanisms\")\n",
        "        ]\n",
        "        \n",
        "        for text, summary in summarization_examples:\n",
        "            input_text = self.formatter.format_summarization(text)\n",
        "            self.data.append({\n",
        "                'task': 'summarization',\n",
        "                'input': input_text,\n",
        "                'output': summary\n",
        "            })\n",
        "            self.task_counts['summarization'] += 1\n",
        "    \n",
        "    def create_dataset(self):\n",
        "        \"\"\"Create the complete multi-task dataset\"\"\"\n",
        "        self.add_sentiment_data()\n",
        "        self.add_translation_data()\n",
        "        self.add_qa_data()\n",
        "        self.add_summarization_data()\n",
        "        \n",
        "        # Shuffle the dataset\n",
        "        random.shuffle(self.data)\n",
        "        \n",
        "        return self.data\n",
        "    \n",
        "    def get_statistics(self):\n",
        "        \"\"\"Get dataset statistics\"\"\"\n",
        "        total_examples = len(self.data)\n",
        "        stats = {\n",
        "            'total_examples': total_examples,\n",
        "            'tasks': dict(self.task_counts),\n",
        "            'task_distribution': {task: count/total_examples for task, count in self.task_counts.items()}\n",
        "        }\n",
        "        return stats\n",
        "\n",
        "# Create the multi-task dataset\n",
        "dataset_creator = MultiTaskDataset()\n",
        "multi_task_data = dataset_creator.create_dataset()\n",
        "stats = dataset_creator.get_statistics()\n",
        "\n",
        "print(\"MULTI-TASK T5 DATASET CREATED\")\n",
        "print(\"=\" * 40)\n",
        "print(f\"Total Examples: {stats['total_examples']}\")\n",
        "print(\"\\nTask Distribution:\")\n",
        "for task, count in stats['tasks'].items():\n",
        "    percentage = stats['task_distribution'][task] * 100\n",
        "    print(f\"  {task}: {count} examples ({percentage:.1f}%)\")\n",
        "\n",
        "print(\"\\nSample Examples:\")\n",
        "print(\"-\" * 40)\n",
        "for i, example in enumerate(multi_task_data[:5]):\n",
        "    print(f\"Example {i+1} ({example['task']}):\")\n",
        "    print(f\"  Input:  {example['input']}\")\n",
        "    print(f\"  Output: {example['output']}\")\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize the multi-task dataset distribution\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# Task distribution pie chart\n",
        "tasks = list(stats['tasks'].keys())\n",
        "counts = list(stats['tasks'].values())\n",
        "colors = sns.color_palette(\"husl\", len(tasks))\n",
        "\n",
        "ax1.pie(counts, labels=tasks, autopct='%1.1f%%', colors=colors, startangle=90)\n",
        "ax1.set_title('Task Distribution in Multi-Task Dataset', fontsize=14, fontweight='bold')\n",
        "\n",
        "# Task count bar chart\n",
        "ax2.bar(tasks, counts, color=colors)\n",
        "ax2.set_title('Number of Examples per Task', fontsize=14, fontweight='bold')\n",
        "ax2.set_ylabel('Number of Examples')\n",
        "ax2.set_xlabel('Task Type')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Analyze input/output length distributions\n",
        "input_lengths = [len(example['input'].split()) for example in multi_task_data]\n",
        "output_lengths = [len(example['output'].split()) for example in multi_task_data]\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# Input length distribution\n",
        "ax1.hist(input_lengths, bins=20, alpha=0.7, color='skyblue', edgecolor='black')\n",
        "ax1.set_title('Input Length Distribution', fontsize=14, fontweight='bold')\n",
        "ax1.set_xlabel('Number of Words')\n",
        "ax1.set_ylabel('Frequency')\n",
        "ax1.axvline(np.mean(input_lengths), color='red', linestyle='--', \n",
        "           label=f'Mean: {np.mean(input_lengths):.1f}')\n",
        "ax1.legend()\n",
        "\n",
        "# Output length distribution\n",
        "ax2.hist(output_lengths, bins=20, alpha=0.7, color='lightcoral', edgecolor='black')\n",
        "ax2.set_title('Output Length Distribution', fontsize=14, fontweight='bold')\n",
        "ax2.set_xlabel('Number of Words')\n",
        "ax2.set_ylabel('Frequency')\n",
        "ax2.axvline(np.mean(output_lengths), color='red', linestyle='--', \n",
        "           label=f'Mean: {np.mean(output_lengths):.1f}')\n",
        "ax2.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"DATASET ANALYSIS\")\n",
        "print(\"=\" * 30)\n",
        "print(f\"Average input length: {np.mean(input_lengths):.1f} words\")\n",
        "print(f\"Average output length: {np.mean(output_lengths):.1f} words\")\n",
        "print(f\"Max input length: {max(input_lengths)} words\")\n",
        "print(f\"Max output length: {max(output_lengths)} words\")\n",
        "print(f\"Min input length: {min(input_lengths)} words\")\n",
        "print(f\"Min output length: {min(output_lengths)} words\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 4. T5 vs Traditional Models: Advantages and Challenges\n",
        "\n",
        "### Advantages of T5's Text-to-Text Approach\n",
        "\n",
        "1. **Unified Architecture**: One model for all tasks\n",
        "2. **Transfer Learning**: Knowledge from one task helps others\n",
        "3. **Simplified Training**: Same loss function (cross-entropy) for all tasks\n",
        "4. **Easy Task Addition**: Just add new prefixes\n",
        "5. **Multi-Task Learning**: Learn multiple tasks simultaneously\n",
        "\n",
        "### Challenges\n",
        "\n",
        "1. **Computational Cost**: Large models require significant resources\n",
        "2. **Task Interference**: Tasks might hurt each other's performance\n",
        "3. **Output Format**: All outputs must be text (no direct classification scores)\n",
        "4. **Prefix Design**: Task prefixes need careful design\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simulate performance comparison between traditional and T5 approaches\n",
        "\n",
        "def simulate_performance_comparison():\n",
        "    \"\"\"Simulate performance metrics for traditional vs T5 approaches\"\"\"\n",
        "    \n",
        "    tasks = ['Sentiment', 'Translation', 'QA', 'Summarization', 'Classification']\n",
        "    \n",
        "    # Simulated performance data (accuracy/BLEU scores)\n",
        "    traditional_performance = {\n",
        "        'Sentiment': 0.85,\n",
        "        'Translation': 0.72,\n",
        "        'QA': 0.78,\n",
        "        'Summarization': 0.68,\n",
        "        'Classification': 0.82\n",
        "    }\n",
        "    \n",
        "    # T5 tends to have more consistent performance across tasks\n",
        "    t5_performance = {\n",
        "        'Sentiment': 0.83,\n",
        "        'Translation': 0.74,\n",
        "        'QA': 0.80,\n",
        "        'Summarization': 0.71,\n",
        "        'Classification': 0.81\n",
        "    }\n",
        "    \n",
        "    # Model complexity (parameters in millions)\n",
        "    traditional_complexity = {\n",
        "        'Sentiment': 50,   # BERT-base for sentiment\n",
        "        'Translation': 120, # Transformer for translation\n",
        "        'QA': 110,         # BERT-large for QA\n",
        "        'Summarization': 130, # BART for summarization\n",
        "        'Classification': 60   # RoBERTa for classification\n",
        "    }\n",
        "    \n",
        "    t5_complexity = {\n",
        "        'Sentiment': 220,  # T5-base for all tasks\n",
        "        'Translation': 220,\n",
        "        'QA': 220,\n",
        "        'Summarization': 220,\n",
        "        'Classification': 220\n",
        "    }\n",
        "    \n",
        "    return tasks, traditional_performance, t5_performance, traditional_complexity, t5_complexity\n",
        "\n",
        "# Get simulation data\n",
        "tasks, trad_perf, t5_perf, trad_complex, t5_complex = simulate_performance_comparison()\n",
        "\n",
        "# Create comparison visualizations\n",
        "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "# Performance comparison\n",
        "x = np.arange(len(tasks))\n",
        "width = 0.35\n",
        "\n",
        "ax1.bar(x - width/2, [trad_perf[task] for task in tasks], width, \n",
        "        label='Traditional Models', alpha=0.8, color='lightblue')\n",
        "ax1.bar(x + width/2, [t5_perf[task] for task in tasks], width, \n",
        "        label='T5', alpha=0.8, color='lightcoral')\n",
        "\n",
        "ax1.set_xlabel('Tasks')\n",
        "ax1.set_ylabel('Performance Score')\n",
        "ax1.set_title('Performance Comparison: Traditional vs T5', fontweight='bold')\n",
        "ax1.set_xticks(x)\n",
        "ax1.set_xticklabels(tasks, rotation=45)\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Model complexity comparison\n",
        "total_trad_params = sum(trad_complex.values())\n",
        "total_t5_params = sum(t5_complex.values())\n",
        "\n",
        "ax2.bar(['Traditional\\n(5 models)', 'T5\\n(1 model)'], \n",
        "        [total_trad_params, total_t5_params], \n",
        "        color=['lightblue', 'lightcoral'], alpha=0.8)\n",
        "ax2.set_ylabel('Total Parameters (Millions)')\n",
        "ax2.set_title('Model Complexity Comparison', fontweight='bold')\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "# Add value labels on bars\n",
        "for i, v in enumerate([total_trad_params, total_t5_params]):\n",
        "    ax2.text(i, v + 10, f'{v}M', ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "# Task-specific complexity\n",
        "ax3.bar(x - width/2, [trad_complex[task] for task in tasks], width, \n",
        "        label='Traditional Models', alpha=0.8, color='lightblue')\n",
        "ax3.bar(x + width/2, [t5_complex[task] for task in tasks], width, \n",
        "        label='T5', alpha=0.8, color='lightcoral')\n",
        "\n",
        "ax3.set_xlabel('Tasks')\n",
        "ax3.set_ylabel('Parameters (Millions)')\n",
        "ax3.set_title('Per-Task Model Complexity', fontweight='bold')\n",
        "ax3.set_xticks(x)\n",
        "ax3.set_xticklabels(tasks, rotation=45)\n",
        "ax3.legend()\n",
        "ax3.grid(True, alpha=0.3)\n",
        "\n",
        "# Performance variance\n",
        "trad_scores = list(trad_perf.values())\n",
        "t5_scores = list(t5_perf.values())\n",
        "\n",
        "ax4.boxplot([trad_scores, t5_scores], labels=['Traditional', 'T5'])\n",
        "ax4.set_ylabel('Performance Score')\n",
        "ax4.set_title('Performance Consistency Across Tasks', fontweight='bold')\n",
        "ax4.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print detailed comparison\n",
        "print(\"TRADITIONAL vs T5 COMPARISON\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"Traditional approach - Total parameters: {total_trad_params}M\")\n",
        "print(f\"T5 approach - Total parameters: {total_t5_params}M\")\n",
        "print(f\"Parameter efficiency: T5 is {total_trad_params/total_t5_params:.1f}x more efficient\")\n",
        "print()\n",
        "\n",
        "print(\"Performance Analysis:\")\n",
        "trad_mean = np.mean(trad_scores)\n",
        "t5_mean = np.mean(t5_scores)\n",
        "trad_std = np.std(trad_scores)\n",
        "t5_std = np.std(t5_scores)\n",
        "\n",
        "print(f\"Traditional - Mean: {trad_mean:.3f}, Std: {trad_std:.3f}\")\n",
        "print(f\"T5 - Mean: {t5_mean:.3f}, Std: {t5_std:.3f}\")\n",
        "print(f\"T5 is {'more' if t5_std < trad_std else 'less'} consistent across tasks\")\n",
        "\n",
        "print(\"\\nKey Insights:\")\n",
        "print(\"- T5 uses one model for all tasks vs. multiple specialized models\")\n",
        "print(\"- T5 shows more consistent performance across different tasks\")\n",
        "print(\"- Traditional models may excel in specific tasks but lack generalization\")\n",
        "print(\"- T5 enables easier deployment and maintenance with unified architecture\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 5. Key Takeaways and Future Directions\n",
        "\n",
        "### What We Learned About T5\n",
        "\n",
        "1. **Text-to-Text Paradigm**: Revolutionary approach that unifies all NLP tasks\n",
        "2. **Task Prefixes**: Simple yet powerful way to specify different tasks\n",
        "3. **Multi-Task Learning**: One model can handle multiple tasks simultaneously\n",
        "4. **Transfer Learning**: Knowledge from one task helps improve others\n",
        "5. **Consistency**: More stable performance across different tasks\n",
        "\n",
        "### Impact on NLP Field\n",
        "\n",
        "- **Simplified Architecture**: No need for task-specific model designs\n",
        "- **Easier Deployment**: One model serves multiple purposes\n",
        "- **Better Transfer**: Cross-task knowledge sharing\n",
        "- **Research Direction**: Led to further developments like PaLM, UL2, etc.\n",
        "\n",
        "### Future Directions\n",
        "\n",
        "- **Larger Models**: T5-11B ‚Üí PaLM-540B ‚Üí GPT-3/4\n",
        "- **Better Prefixes**: More sophisticated task specification\n",
        "- **Multi-Modal**: Extending text-to-text to vision, audio, etc.\n",
        "- **Efficiency**: Making large models more computationally efficient\n",
        "\n",
        "### Next Steps for Learning\n",
        "\n",
        "1. **Hands-on Practice**: Try T5 with HuggingFace Transformers\n",
        "2. **Fine-tuning**: Adapt T5 to your specific tasks\n",
        "3. **Prompt Engineering**: Learn to design effective task prefixes\n",
        "4. **Modern Variants**: Explore UL2, PaLM, and other T5 successors\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Final demonstration: Interactive T5-style task processor\n",
        "\n",
        "class InteractiveT5Demo:\n",
        "    \"\"\"Interactive demonstration of T5's text-to-text approach\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.formatter = T5TaskFormatter()\n",
        "        \n",
        "        # Simple rule-based responses for demonstration\n",
        "        self.responses = {\n",
        "            'sentiment': {\n",
        "                'good': 'positive', 'great': 'positive', 'excellent': 'positive',\n",
        "                'love': 'positive', 'amazing': 'positive', 'fantastic': 'positive',\n",
        "                'bad': 'negative', 'terrible': 'negative', 'awful': 'negative',\n",
        "                'hate': 'negative', 'horrible': 'negative', 'worst': 'negative',\n",
        "                'okay': 'neutral', 'average': 'neutral', 'fine': 'neutral'\n",
        "            },\n",
        "            'translate_en_fr': {\n",
        "                'hello': 'bonjour', 'goodbye': 'au revoir', 'thank you': 'merci',\n",
        "                'yes': 'oui', 'no': 'non', 'please': 's\\'il vous pla√Æt',\n",
        "                'how are you': 'comment allez-vous', 'good morning': 'bonjour'\n",
        "            }\n",
        "        }\n",
        "    \n",
        "    def process_sentiment(self, text: str) -> str:\n",
        "        \"\"\"Process sentiment analysis task\"\"\"\n",
        "        text_lower = text.lower()\n",
        "        for word, sentiment in self.responses['sentiment'].items():\n",
        "            if word in text_lower:\n",
        "                return sentiment\n",
        "        return 'neutral'\n",
        "    \n",
        "    def process_translation(self, text: str) -> str:\n",
        "        \"\"\"Process translation task\"\"\"\n",
        "        text_lower = text.lower().strip()\n",
        "        return self.responses['translate_en_fr'].get(text_lower, 'translation not available')\n",
        "    \n",
        "    def process_qa(self, question: str, context: str) -> str:\n",
        "        \"\"\"Process question answering task\"\"\"\n",
        "        # Simple keyword-based QA\n",
        "        q_lower = question.lower()\n",
        "        c_lower = context.lower()\n",
        "        \n",
        "        if 'capital' in q_lower:\n",
        "            if 'france' in c_lower and 'paris' in c_lower:\n",
        "                return 'Paris'\n",
        "            elif 'japan' in c_lower and 'tokyo' in c_lower:\n",
        "                return 'Tokyo'\n",
        "        \n",
        "        if 'who' in q_lower and 'invented' in q_lower:\n",
        "            if 'bell' in c_lower:\n",
        "                return 'Alexander Graham Bell'\n",
        "        \n",
        "        return 'answer not found'\n",
        "    \n",
        "    def process_task(self, task_input: str) -> str:\n",
        "        \"\"\"Process any T5-formatted task input\"\"\"\n",
        "        task_input = task_input.strip()\n",
        "        \n",
        "        if task_input.startswith('sentiment:'):\n",
        "            text = task_input[10:].strip()\n",
        "            return self.process_sentiment(text)\n",
        "        \n",
        "        elif task_input.startswith('translate English to French:'):\n",
        "            text = task_input[28:].strip()\n",
        "            return self.process_translation(text)\n",
        "        \n",
        "        elif task_input.startswith('question:'):\n",
        "            # Extract question and context\n",
        "            parts = task_input[9:].split(' context: ')\n",
        "            if len(parts) == 2:\n",
        "                question, context = parts[0].strip(), parts[1].strip()\n",
        "                return self.process_qa(question, context)\n",
        "        \n",
        "        elif task_input.startswith('summarize:'):\n",
        "            text = task_input[10:].strip()\n",
        "            # Simple summarization - return first few words\n",
        "            words = text.split()[:5]\n",
        "            return ' '.join(words) + '...'\n",
        "        \n",
        "        return 'Task not supported in this demo'\n",
        "\n",
        "# Create demo instance\n",
        "demo = InteractiveT5Demo()\n",
        "\n",
        "# Test various tasks\n",
        "test_inputs = [\n",
        "    \"sentiment: I love this new phone!\",\n",
        "    \"sentiment: This product is terrible.\",\n",
        "    \"translate English to French: hello\",\n",
        "    \"translate English to French: thank you\",\n",
        "    \"question: What is the capital of France? context: Paris is the capital of France.\",\n",
        "    \"summarize: Machine learning is a powerful technology that enables computers to learn from data and make predictions.\",\n",
        "    \"generate: The weather today is\"  # Not implemented\n",
        "]\n",
        "\n",
        "print(\"T5 INTERACTIVE DEMO\")\n",
        "print(\"=\" * 40)\n",
        "print(\"Testing various T5-formatted tasks:\")\n",
        "print()\n",
        "\n",
        "for i, task_input in enumerate(test_inputs, 1):\n",
        "    output = demo.process_task(task_input)\n",
        "    print(f\"Test {i}:\")\n",
        "    print(f\"  Input:  {task_input}\")\n",
        "    print(f\"  Output: {output}\")\n",
        "    print()\n",
        "\n",
        "print(\"=\" * 40)\n",
        "print(\"This demonstrates how T5 processes different tasks\")\n",
        "print(\"using the same input-output format!\")\n",
        "print(\"In a real T5 model, all these tasks would be\")\n",
        "print(\"handled by the same neural network architecture.\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# T5: Text-to-Text Transfer Transformer\n",
        "\n",
        "## Learning Objectives\n",
        "- Understand the text-to-text concept\n",
        "- Learn T5 unified NLP framework\n",
        "- Implement text-to-text data preparation\n",
        "- Explore multi-task learning benefits\n",
        "\n",
        "## The Text-to-Text Paradigm\n",
        "T5 treats every NLP task as text transformation:\n",
        "- Translation: \"translate: Hello\" ‚Üí \"Bonjour\"  \n",
        "- Summarization: \"summarize: [text]\" ‚Üí \"[summary]\"\n",
        "- QA: \"question: What is AI?\" ‚Üí \"[answer]\"\n",
        "\n",
        "## Key Benefits\n",
        "- Unified training framework\n",
        "- Task transfer learning\n",
        "- Simplified architecture\n",
        "- Scalable to multiple tasks\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "raw",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "raw",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "raw",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
