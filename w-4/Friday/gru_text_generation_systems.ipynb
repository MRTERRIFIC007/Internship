{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# GRU-based Text Generation Systems\n",
        "\n",
        "## Learning Objectives\n",
        "In this notebook, we'll implement efficient text generation using GRU architectures:\n",
        "- GRU vs LSTM comparison for text generation tasks\n",
        "- Memory efficiency and computational optimization techniques\n",
        "- Bidirectional GRU for context-aware generation\n",
        "- Attention-enhanced GRU generation systems\n",
        "- Real-time text generation optimization\n",
        "- Performance analysis and benchmarking\n",
        "\n",
        "## Introduction to GRU Text Generation\n",
        "\n",
        "GRUs offer several advantages for text generation:\n",
        "- **Computational Efficiency**: Fewer parameters than LSTMs\n",
        "- **Training Speed**: Faster convergence in many cases\n",
        "- **Memory Usage**: Lower memory requirements\n",
        "- **Performance**: Often comparable to LSTM with less complexity\n",
        "\n",
        "This makes GRUs particularly suitable for real-time applications and resource-constrained environments.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import time\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "print(\"GRU Text Generation Systems initialized!\")\n",
        "\n",
        "# Set plotting style\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "# 1. GRU Text Generator with Performance Optimization\n",
        "class OptimizedGRUGenerator:\n",
        "    \"\"\"\n",
        "    Memory and computationally efficient GRU-based text generator\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, vocab_size, embedding_dim=128, gru_units=256, num_layers=2):\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.gru_units = gru_units\n",
        "        self.num_layers = num_layers\n",
        "        self.model = None\n",
        "        \n",
        "    def build_model(self, sequence_length):\n",
        "        \"\"\"\n",
        "        Build optimized GRU model for text generation\n",
        "        \"\"\"\n",
        "        model = keras.Sequential([\n",
        "            layers.Embedding(self.vocab_size, self.embedding_dim, \n",
        "                           input_length=sequence_length),\n",
        "            layers.Dropout(0.2)\n",
        "        ])\n",
        "        \n",
        "        # Add GRU layers\n",
        "        for i in range(self.num_layers):\n",
        "            return_sequences = (i < self.num_layers - 1)\n",
        "            model.add(layers.GRU(\n",
        "                self.gru_units,\n",
        "                return_sequences=return_sequences,\n",
        "                dropout=0.2,\n",
        "                recurrent_dropout=0.2\n",
        "            ))\n",
        "            \n",
        "            if return_sequences:\n",
        "                model.add(layers.Dropout(0.2))\n",
        "        \n",
        "        # Output layer with optimized activation\n",
        "        model.add(layers.Dense(self.vocab_size, activation='softmax'))\n",
        "        \n",
        "        self.model = model\n",
        "        return model\n",
        "    \n",
        "    def build_bidirectional_model(self, sequence_length):\n",
        "        \"\"\"\n",
        "        Build bidirectional GRU model for enhanced context understanding\n",
        "        \"\"\"\n",
        "        model = keras.Sequential([\n",
        "            layers.Embedding(self.vocab_size, self.embedding_dim, \n",
        "                           input_length=sequence_length),\n",
        "            layers.Dropout(0.2),\n",
        "            layers.Bidirectional(layers.GRU(\n",
        "                self.gru_units//2,  # Halve units since bidirectional doubles them\n",
        "                return_sequences=True,\n",
        "                dropout=0.2,\n",
        "                recurrent_dropout=0.2\n",
        "            )),\n",
        "            layers.Dropout(0.3),\n",
        "            layers.GRU(self.gru_units//2, dropout=0.2, recurrent_dropout=0.2),\n",
        "            layers.Dense(self.vocab_size, activation='softmax')\n",
        "        ])\n",
        "        \n",
        "        self.model = model\n",
        "        return model\n",
        "\n",
        "# 2. Performance Benchmark System\n",
        "class GenerationBenchmark:\n",
        "    \"\"\"\n",
        "    Benchmark system for comparing generation performance\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.results = {}\n",
        "    \n",
        "    def benchmark_models(self, models_dict, test_data, sequence_length=50):\n",
        "        \"\"\"\n",
        "        Benchmark multiple models for generation performance\n",
        "        \"\"\"\n",
        "        results = {}\n",
        "        \n",
        "        for name, model in models_dict.items():\n",
        "            print(f\"Benchmarking {name}...\")\n",
        "            \n",
        "            # Measure training time\n",
        "            start_time = time.time()\n",
        "            \n",
        "            # Simple training (reduced for demo)\n",
        "            X, y = test_data\n",
        "            model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "            history = model.fit(X[:100], y[:100], epochs=3, batch_size=16, verbose=0)\n",
        "            \n",
        "            training_time = time.time() - start_time\n",
        "            \n",
        "            # Measure inference time\n",
        "            start_time = time.time()\n",
        "            sample_input = X[:10]\n",
        "            predictions = model.predict(sample_input, verbose=0)\n",
        "            inference_time = time.time() - start_time\n",
        "            \n",
        "            # Calculate model size\n",
        "            param_count = model.count_params()\n",
        "            \n",
        "            # Store results\n",
        "            results[name] = {\n",
        "                'training_time': training_time,\n",
        "                'inference_time': inference_time,\n",
        "                'param_count': param_count,\n",
        "                'final_accuracy': history.history['accuracy'][-1],\n",
        "                'final_loss': history.history['loss'][-1]\n",
        "            }\n",
        "            \n",
        "            print(f\"  Training time: {training_time:.2f}s\")\n",
        "            print(f\"  Inference time: {inference_time:.4f}s\")\n",
        "            print(f\"  Parameters: {param_count:,}\")\n",
        "        \n",
        "        self.results = results\n",
        "        return results\n",
        "    \n",
        "    def visualize_benchmark(self):\n",
        "        \"\"\"\n",
        "        Visualize benchmark results\n",
        "        \"\"\"\n",
        "        if not self.results:\n",
        "            print(\"No benchmark results to visualize\")\n",
        "            return\n",
        "        \n",
        "        fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "        \n",
        "        names = list(self.results.keys())\n",
        "        \n",
        "        # Training time comparison\n",
        "        training_times = [self.results[name]['training_time'] for name in names]\n",
        "        axes[0, 0].bar(names, training_times, alpha=0.7, color='skyblue')\n",
        "        axes[0, 0].set_title('Training Time Comparison')\n",
        "        axes[0, 0].set_ylabel('Time (seconds)')\n",
        "        axes[0, 0].tick_params(axis='x', rotation=45)\n",
        "        \n",
        "        # Inference time comparison\n",
        "        inference_times = [self.results[name]['inference_time'] for name in names]\n",
        "        axes[0, 1].bar(names, inference_times, alpha=0.7, color='lightcoral')\n",
        "        axes[0, 1].set_title('Inference Time Comparison')\n",
        "        axes[0, 1].set_ylabel('Time (seconds)')\n",
        "        axes[0, 1].tick_params(axis='x', rotation=45)\n",
        "        \n",
        "        # Parameter count comparison\n",
        "        param_counts = [self.results[name]['param_count'] for name in names]\n",
        "        axes[0, 2].bar(names, param_counts, alpha=0.7, color='lightgreen')\n",
        "        axes[0, 2].set_title('Parameter Count Comparison')\n",
        "        axes[0, 2].set_ylabel('Number of Parameters')\n",
        "        axes[0, 2].tick_params(axis='x', rotation=45)\n",
        "        \n",
        "        # Accuracy comparison\n",
        "        accuracies = [self.results[name]['final_accuracy'] for name in names]\n",
        "        axes[1, 0].bar(names, accuracies, alpha=0.7, color='orange')\n",
        "        axes[1, 0].set_title('Final Accuracy Comparison')\n",
        "        axes[1, 0].set_ylabel('Accuracy')\n",
        "        axes[1, 0].tick_params(axis='x', rotation=45)\n",
        "        \n",
        "        # Efficiency analysis (accuracy per parameter)\n",
        "        efficiency = [acc / (params / 1000) for acc, params in zip(accuracies, param_counts)]\n",
        "        axes[1, 1].bar(names, efficiency, alpha=0.7, color='purple')\n",
        "        axes[1, 1].set_title('Efficiency (Accuracy per 1K Params)')\n",
        "        axes[1, 1].set_ylabel('Efficiency Score')\n",
        "        axes[1, 1].tick_params(axis='x', rotation=45)\n",
        "        \n",
        "        # Speed vs Accuracy trade-off\n",
        "        axes[1, 2].scatter(training_times, accuracies, s=100, alpha=0.7)\n",
        "        for i, name in enumerate(names):\n",
        "            axes[1, 2].annotate(name, (training_times[i], accuracies[i]), \n",
        "                              xytext=(5, 5), textcoords='offset points')\n",
        "        axes[1, 2].set_xlabel('Training Time (s)')\n",
        "        axes[1, 2].set_ylabel('Final Accuracy')\n",
        "        axes[1, 2].set_title('Speed vs Accuracy Trade-off')\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "# 3. Create sample data and models for comparison\n",
        "def create_sample_text_data(vocab_size=50, seq_length=30, num_samples=200):\n",
        "    \"\"\"\n",
        "    Create sample text data for benchmarking\n",
        "    \"\"\"\n",
        "    # Generate random sequences that simulate text\n",
        "    X = np.random.randint(1, vocab_size, size=(num_samples, seq_length))\n",
        "    y = np.random.randint(0, vocab_size, size=(num_samples, seq_length))\n",
        "    return X, y\n",
        "\n",
        "# Generate sample data\n",
        "vocab_size = 50\n",
        "sequence_length = 30\n",
        "X_sample, y_sample = create_sample_text_data(vocab_size, sequence_length, 200)\n",
        "\n",
        "print(f\"Sample data shape: X={X_sample.shape}, y={y_sample.shape}\")\n",
        "\n",
        "# Create different GRU model variants\n",
        "gru_generator = OptimizedGRUGenerator(vocab_size, embedding_dim=64, gru_units=128, num_layers=2)\n",
        "\n",
        "models_to_compare = {}\n",
        "\n",
        "# Standard GRU\n",
        "models_to_compare['Standard_GRU'] = gru_generator.build_model(sequence_length)\n",
        "\n",
        "# Bidirectional GRU\n",
        "gru_generator_bi = OptimizedGRUGenerator(vocab_size, embedding_dim=64, gru_units=128, num_layers=1)\n",
        "models_to_compare['Bidirectional_GRU'] = gru_generator_bi.build_bidirectional_model(sequence_length)\n",
        "\n",
        "# LSTM for comparison\n",
        "lstm_model = keras.Sequential([\n",
        "    layers.Embedding(vocab_size, 64, input_length=sequence_length),\n",
        "    layers.Dropout(0.2),\n",
        "    layers.LSTM(128, dropout=0.2, recurrent_dropout=0.2),\n",
        "    layers.Dense(vocab_size, activation='softmax')\n",
        "])\n",
        "models_to_compare['LSTM_Baseline'] = lstm_model\n",
        "\n",
        "# SimpleRNN for comparison\n",
        "rnn_model = keras.Sequential([\n",
        "    layers.Embedding(vocab_size, 64, input_length=sequence_length),\n",
        "    layers.Dropout(0.2),\n",
        "    layers.SimpleRNN(128, dropout=0.2),\n",
        "    layers.Dense(vocab_size, activation='softmax')\n",
        "])\n",
        "models_to_compare['SimpleRNN_Baseline'] = rnn_model\n",
        "\n",
        "print(f\"Created {len(models_to_compare)} models for comparison:\")\n",
        "for name, model in models_to_compare.items():\n",
        "    print(f\"  {name}: {model.count_params():,} parameters\")\n",
        "\n",
        "# Run benchmark\n",
        "benchmark = GenerationBenchmark()\n",
        "print(f\"\\nRunning performance benchmark...\")\n",
        "benchmark_results = benchmark.benchmark_models(models_to_compare, (X_sample, y_sample))\n",
        "\n",
        "# Visualize results\n",
        "print(f\"\\nGenerating benchmark visualization...\")\n",
        "benchmark.visualize_benchmark()\n",
        "\n",
        "# Print detailed analysis\n",
        "print(f\"\\nGRU vs LSTM Performance Analysis:\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "for name, result in benchmark_results.items():\n",
        "    print(f\"\\n{name}:\")\n",
        "    print(f\"  Training Time: {result['training_time']:.3f}s\")\n",
        "    print(f\"  Inference Time: {result['inference_time']:.4f}s\")\n",
        "    print(f\"  Parameters: {result['param_count']:,}\")\n",
        "    print(f\"  Final Accuracy: {result['final_accuracy']:.4f}\")\n",
        "    print(f\"  Efficiency: {result['final_accuracy'] / (result['param_count'] / 1000):.4f}\")\n",
        "\n",
        "# Find best performers\n",
        "best_speed = min(benchmark_results.keys(), key=lambda x: benchmark_results[x]['training_time'])\n",
        "best_accuracy = max(benchmark_results.keys(), key=lambda x: benchmark_results[x]['final_accuracy'])\n",
        "most_efficient = max(benchmark_results.keys(), \n",
        "                    key=lambda x: benchmark_results[x]['final_accuracy'] / (benchmark_results[x]['param_count'] / 1000))\n",
        "\n",
        "print(f\"\\nPerformance Leaders:\")\n",
        "print(f\"Fastest Training: {best_speed}\")\n",
        "print(f\"Highest Accuracy: {best_accuracy}\")\n",
        "print(f\"Most Efficient: {most_efficient}\")\n",
        "\n",
        "print(f\"\\nKey Insights:\")\n",
        "print(\"- GRU typically offers good balance of speed and performance\")\n",
        "print(\"- Bidirectional models provide better context but with computational cost\")\n",
        "print(\"- LSTM may achieve slightly higher accuracy but requires more parameters\")\n",
        "print(\"- SimpleRNN is fastest but may struggle with longer dependencies\")\n",
        "\n",
        "# Performance optimization tips\n",
        "print(f\"\\nGRU Optimization Tips:\")\n",
        "print(\"1. Use smaller embedding dimensions for faster training\")\n",
        "print(\"2. Bidirectional GRUs for better context understanding\")\n",
        "print(\"3. Gradient clipping for training stability\")\n",
        "print(\"4. Mixed precision training for inference speed\")\n",
        "print(\"5. Model quantization for deployment optimization\")\n",
        "\n",
        "print(f\"\\nGRU Text Generation Systems Analysis Complete!\")\n",
        "print(f\"Ready for hybrid models and advanced optimization techniques!\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
