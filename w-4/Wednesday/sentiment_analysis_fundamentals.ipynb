{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Sentiment Analysis Fundamentals\n",
        "\n",
        "## Learning Objectives\n",
        "In this notebook, we'll explore the foundations of sentiment analysis:\n",
        "- Understanding sentiment classification as an NLP problem\n",
        "- Text preprocessing pipelines specifically for sentiment data\n",
        "- Feature extraction and representation strategies\n",
        "- Dataset preparation and exploratory data analysis\n",
        "- Baseline approaches and performance benchmarks\n",
        "\n",
        "## Introduction to Sentiment Analysis\n",
        "\n",
        "Sentiment analysis (also called opinion mining) is the computational study of opinions, sentiments, and emotions expressed in text. It's one of the most widely applied NLP techniques with applications in:\n",
        "\n",
        "- **Business Intelligence**: Customer feedback analysis, brand monitoring\n",
        "- **Social Media**: Public opinion tracking, trend analysis\n",
        "- **Finance**: Market sentiment analysis, stock prediction\n",
        "- **Politics**: Public opinion polling, campaign analysis\n",
        "- **Healthcare**: Patient feedback analysis, drug reviews\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n",
        "import string\n",
        "from collections import Counter, defaultdict\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Text processing libraries\n",
        "try:\n",
        "    import nltk\n",
        "    from nltk.corpus import stopwords\n",
        "    from nltk.tokenize import word_tokenize\n",
        "    from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "    \n",
        "    # Download required NLTK data\n",
        "    nltk.download('punkt', quiet=True)\n",
        "    nltk.download('stopwords', quiet=True)\n",
        "    nltk.download('wordnet', quiet=True)\n",
        "    print(\"NLTK components loaded successfully\")\n",
        "except ImportError:\n",
        "    print(\"NLTK not available, using basic text processing\")\n",
        "\n",
        "# Machine learning libraries\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Deep learning libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Visualization\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "# Set random seeds\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "print(\"Libraries imported successfully!\")\n",
        "print(f\"TensorFlow version: {tf.__version__}\")\n",
        "\n",
        "# Set plotting style\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 1. Creating and Exploring Sentiment Dataset\n",
        "\n",
        "Since we're focusing on learning the fundamentals, we'll create a comprehensive synthetic dataset that mimics real-world sentiment data patterns. This allows us to understand the data structure and preprocessing challenges without external dependencies.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create comprehensive sentiment dataset\n",
        "def create_sentiment_dataset():\n",
        "    \"\"\"\n",
        "    Create a realistic sentiment dataset with various text patterns\n",
        "    \"\"\"\n",
        "    \n",
        "    # Positive sentiment examples\n",
        "    positive_texts = [\n",
        "        \"I absolutely love this product! It exceeded all my expectations.\",\n",
        "        \"Amazing quality and fast delivery. Highly recommend!\",\n",
        "        \"This is the best purchase I've made in years. Perfect!\",\n",
        "        \"Outstanding customer service and excellent product quality.\",\n",
        "        \"I'm so happy with this purchase. Will definitely buy again!\",\n",
        "        \"Fantastic! Everything arrived on time and in perfect condition.\",\n",
        "        \"Great value for money. The product works perfectly.\",\n",
        "        \"Superb quality and amazing features. Love it!\",\n",
        "        \"Excellent product! Exactly what I was looking for.\",\n",
        "        \"Perfect fit and great design. Very satisfied!\",\n",
        "        \"This product is incredible! Exceeds expectations.\",\n",
        "        \"Beautiful design and excellent functionality. Recommended!\",\n",
        "        \"Top quality! Fast shipping and great packaging.\",\n",
        "        \"Love the features and ease of use. Perfect!\",\n",
        "        \"Outstanding value and performance. Very happy!\",\n",
        "        \"Brilliant product! Works exactly as described.\",\n",
        "        \"Impressive quality and attention to detail.\",\n",
        "        \"Wonderful experience from start to finish!\",\n",
        "        \"This is exactly what I needed. Perfect solution!\",\n",
        "        \"Excellent craftsmanship and great customer support.\",\n",
        "        \"Amazing results! Better than expected.\",\n",
        "        \"High quality materials and excellent build.\",\n",
        "        \"Perfect for my needs. Great functionality!\",\n",
        "        \"Superb performance and reliable operation.\",\n",
        "        \"Love the innovation and thoughtful design.\"\n",
        "    ]\n",
        "    \n",
        "    # Negative sentiment examples\n",
        "    negative_texts = [\n",
        "        \"Terrible product! Complete waste of money.\",\n",
        "        \"Poor quality and disappointing performance. Avoid!\",\n",
        "        \"This is the worst purchase I've ever made.\",\n",
        "        \"Awful customer service and defective product.\",\n",
        "        \"I hate this product. Nothing works as advertised.\",\n",
        "        \"Horrible experience. Product broke immediately.\",\n",
        "        \"Overpriced and poor quality. Very disappointed.\",\n",
        "        \"Useless product with terrible design flaws.\",\n",
        "        \"Don't buy this! It's a complete scam.\",\n",
        "        \"Worst quality I've ever seen. Returned immediately.\",\n",
        "        \"Broken on arrival and no customer support.\",\n",
        "        \"This product is garbage. Save your money!\",\n",
        "        \"Terrible build quality and false advertising.\",\n",
        "        \"Complete disappointment. Nothing works properly.\",\n",
        "        \"Poor materials and shoddy construction.\",\n",
        "        \"Defective product with misleading description.\",\n",
        "        \"Nightmare experience with this purchase.\",\n",
        "        \"Cheap quality and overpriced. Avoid at all costs!\",\n",
        "        \"Broken after one day. Terrible reliability.\",\n",
        "        \"Worst customer service experience ever.\",\n",
        "        \"Product failed completely. Total waste.\",\n",
        "        \"Inferior quality and poor performance.\",\n",
        "        \"Disappointing results and bad value.\",\n",
        "        \"Unreliable and poorly designed product.\",\n",
        "        \"Frustrated with poor quality and service.\"\n",
        "    ]\n",
        "    \n",
        "    # Neutral sentiment examples\n",
        "    neutral_texts = [\n",
        "        \"The product is okay. Nothing special but works.\",\n",
        "        \"Average quality for the price. Could be better.\",\n",
        "        \"It's fine. Does what it's supposed to do.\",\n",
        "        \"Decent product with standard features.\",\n",
        "        \"Regular quality item. Nothing extraordinary.\",\n",
        "        \"Standard product with basic functionality.\",\n",
        "        \"It works as described. No surprises.\",\n",
        "        \"Average performance and typical quality.\",\n",
        "        \"Basic product that meets minimum requirements.\",\n",
        "        \"Normal quality for this price range.\",\n",
        "        \"The product is acceptable but not outstanding.\",\n",
        "        \"Standard features and regular performance.\",\n",
        "        \"It's an ordinary product with basic design.\",\n",
        "        \"Typical quality and standard delivery.\",\n",
        "        \"Regular item with expected functionality.\",\n",
        "        \"Average build quality and normal features.\",\n",
        "        \"Standard product that works adequately.\",\n",
        "        \"Basic design with typical performance.\",\n",
        "        \"It's a regular product with normal quality.\",\n",
        "        \"Standard functionality and average materials.\",\n",
        "        \"Ordinary product with expected features.\",\n",
        "        \"Normal quality and standard performance.\",\n",
        "        \"Basic item that meets requirements.\",\n",
        "        \"Average product with typical characteristics.\",\n",
        "        \"Standard quality and regular functionality.\"\n",
        "    ]\n",
        "    \n",
        "    # Create DataFrame\n",
        "    texts = positive_texts + negative_texts + neutral_texts\n",
        "    labels = (['positive'] * len(positive_texts) + \n",
        "              ['negative'] * len(negative_texts) + \n",
        "              ['neutral'] * len(neutral_texts))\n",
        "    \n",
        "    # Add some variation with mixed sentiments\n",
        "    mixed_texts = [\n",
        "        \"Good product but expensive for what you get.\",\n",
        "        \"Fast delivery but product quality could be better.\",\n",
        "        \"Great customer service but the product is average.\",\n",
        "        \"Love the design but functionality is limited.\",\n",
        "        \"Excellent packaging but disappointing content.\",\n",
        "        \"Quick shipping but poor build quality.\",\n",
        "        \"Nice features but overpriced for the value.\",\n",
        "        \"Good concept but poor execution.\",\n",
        "        \"Beautiful appearance but lacks durability.\",\n",
        "        \"Helpful support but defective product.\"\n",
        "    ]\n",
        "    \n",
        "    # Add mixed sentiments (we'll classify these as neutral)\n",
        "    texts.extend(mixed_texts)\n",
        "    labels.extend(['neutral'] * len(mixed_texts))\n",
        "    \n",
        "    df = pd.DataFrame({\n",
        "        'text': texts,\n",
        "        'sentiment': labels\n",
        "    })\n",
        "    \n",
        "    # Shuffle the dataset\n",
        "    df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "    \n",
        "    return df\n",
        "\n",
        "# Create the dataset\n",
        "sentiment_df = create_sentiment_dataset()\n",
        "\n",
        "print(f\"Dataset created with {len(sentiment_df)} samples\")\n",
        "print(f\"Columns: {list(sentiment_df.columns)}\")\n",
        "print(f\"\\nClass distribution:\")\n",
        "print(sentiment_df['sentiment'].value_counts())\n",
        "\n",
        "# Display first few examples\n",
        "print(f\"\\nSample data:\")\n",
        "print(sentiment_df.head(10))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exploratory Data Analysis\n",
        "def analyze_text_features(df):\n",
        "    \"\"\"\n",
        "    Analyze various text features in the sentiment dataset\n",
        "    \"\"\"\n",
        "    \n",
        "    # Calculate text statistics\n",
        "    df['text_length'] = df['text'].str.len()\n",
        "    df['word_count'] = df['text'].str.split().str.len()\n",
        "    df['sentence_count'] = df['text'].str.count('[.!?]') + 1\n",
        "    df['exclamation_count'] = df['text'].str.count('!')\n",
        "    df['question_count'] = df['text'].str.count('?')\n",
        "    df['uppercase_ratio'] = df['text'].apply(lambda x: sum(1 for c in x if c.isupper()) / len(x) if len(x) > 0 else 0)\n",
        "    \n",
        "    return df\n",
        "\n",
        "# Perform EDA\n",
        "sentiment_df = analyze_text_features(sentiment_df)\n",
        "\n",
        "# Visualize the dataset\n",
        "plt.figure(figsize=(18, 12))\n",
        "\n",
        "# Class distribution\n",
        "plt.subplot(3, 4, 1)\n",
        "sentiment_counts = sentiment_df['sentiment'].value_counts()\n",
        "colors = ['lightgreen', 'lightcoral', 'lightblue']\n",
        "plt.pie(sentiment_counts.values, labels=sentiment_counts.index, autopct='%1.1f%%', colors=colors)\n",
        "plt.title('Sentiment Distribution')\n",
        "\n",
        "# Text length distribution by sentiment\n",
        "plt.subplot(3, 4, 2)\n",
        "for sentiment in sentiment_df['sentiment'].unique():\n",
        "    data = sentiment_df[sentiment_df['sentiment'] == sentiment]['text_length']\n",
        "    plt.hist(data, alpha=0.6, label=sentiment, bins=15)\n",
        "plt.xlabel('Text Length (characters)')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Text Length Distribution by Sentiment')\n",
        "plt.legend()\n",
        "\n",
        "# Word count distribution\n",
        "plt.subplot(3, 4, 3)\n",
        "for sentiment in sentiment_df['sentiment'].unique():\n",
        "    data = sentiment_df[sentiment_df['sentiment'] == sentiment]['word_count']\n",
        "    plt.hist(data, alpha=0.6, label=sentiment, bins=15)\n",
        "plt.xlabel('Word Count')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Word Count Distribution by Sentiment')\n",
        "plt.legend()\n",
        "\n",
        "# Exclamation marks usage\n",
        "plt.subplot(3, 4, 4)\n",
        "exclamation_by_sentiment = sentiment_df.groupby('sentiment')['exclamation_count'].mean()\n",
        "bars = plt.bar(exclamation_by_sentiment.index, exclamation_by_sentiment.values, color=colors)\n",
        "plt.title('Average Exclamation Marks by Sentiment')\n",
        "plt.ylabel('Average Count')\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "# Add value labels on bars\n",
        "for bar in bars:\n",
        "    height = bar.get_height()\n",
        "    plt.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
        "             f'{height:.2f}', ha='center', va='bottom')\n",
        "\n",
        "# Uppercase ratio by sentiment\n",
        "plt.subplot(3, 4, 5)\n",
        "uppercase_by_sentiment = sentiment_df.groupby('sentiment')['uppercase_ratio'].mean()\n",
        "plt.bar(uppercase_by_sentiment.index, uppercase_by_sentiment.values, color=colors)\n",
        "plt.title('Average Uppercase Ratio by Sentiment')\n",
        "plt.ylabel('Ratio')\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "# Box plot of text length by sentiment\n",
        "plt.subplot(3, 4, 6)\n",
        "sentiment_df.boxplot(column='text_length', by='sentiment', ax=plt.gca())\n",
        "plt.title('Text Length Distribution by Sentiment')\n",
        "plt.suptitle('')  # Remove automatic title\n",
        "\n",
        "# Word frequency analysis\n",
        "plt.subplot(3, 4, 7)\n",
        "all_words = []\n",
        "for text in sentiment_df['text']:\n",
        "    words = text.lower().split()\n",
        "    all_words.extend(words)\n",
        "\n",
        "word_freq = Counter(all_words)\n",
        "common_words = word_freq.most_common(15)\n",
        "words, counts = zip(*common_words)\n",
        "\n",
        "plt.barh(range(len(words)), counts)\n",
        "plt.yticks(range(len(words)), words)\n",
        "plt.xlabel('Frequency')\n",
        "plt.title('Most Common Words')\n",
        "plt.gca().invert_yaxis()\n",
        "\n",
        "# Sentiment-specific word analysis\n",
        "plt.subplot(3, 4, 8)\n",
        "positive_words = []\n",
        "negative_words = []\n",
        "neutral_words = []\n",
        "\n",
        "for idx, row in sentiment_df.iterrows():\n",
        "    words = row['text'].lower().split()\n",
        "    if row['sentiment'] == 'positive':\n",
        "        positive_words.extend(words)\n",
        "    elif row['sentiment'] == 'negative':\n",
        "        negative_words.extend(words)\n",
        "    else:\n",
        "        neutral_words.extend(words)\n",
        "\n",
        "pos_freq = Counter(positive_words).most_common(10)\n",
        "neg_freq = Counter(negative_words).most_common(10)\n",
        "neu_freq = Counter(neutral_words).most_common(10)\n",
        "\n",
        "# Plot top positive words\n",
        "pos_words, pos_counts = zip(*pos_freq)\n",
        "y_pos = np.arange(len(pos_words))\n",
        "plt.barh(y_pos, pos_counts, alpha=0.7, color='green')\n",
        "plt.yticks(y_pos, pos_words)\n",
        "plt.xlabel('Frequency')\n",
        "plt.title('Top Words in Positive Reviews')\n",
        "plt.gca().invert_yaxis()\n",
        "\n",
        "# Statistical summary\n",
        "plt.subplot(3, 4, 9)\n",
        "stats_summary = sentiment_df.groupby('sentiment')[['text_length', 'word_count', 'exclamation_count']].mean()\n",
        "stats_summary.plot(kind='bar', ax=plt.gca())\n",
        "plt.title('Average Statistics by Sentiment')\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "\n",
        "# Correlation matrix of features\n",
        "plt.subplot(3, 4, 10)\n",
        "feature_cols = ['text_length', 'word_count', 'exclamation_count', 'question_count', 'uppercase_ratio']\n",
        "correlation_matrix = sentiment_df[feature_cols].corr()\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, ax=plt.gca())\n",
        "plt.title('Feature Correlation Matrix')\n",
        "\n",
        "# Text complexity analysis\n",
        "plt.subplot(3, 4, 11)\n",
        "sentiment_df['avg_word_length'] = sentiment_df['text'].apply(\n",
        "    lambda x: np.mean([len(word) for word in x.split()]) if x.split() else 0\n",
        ")\n",
        "complexity_by_sentiment = sentiment_df.groupby('sentiment')['avg_word_length'].mean()\n",
        "plt.bar(complexity_by_sentiment.index, complexity_by_sentiment.values, color=colors)\n",
        "plt.title('Average Word Length by Sentiment')\n",
        "plt.ylabel('Average Word Length')\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "# Punctuation usage\n",
        "plt.subplot(3, 4, 12)\n",
        "sentiment_df['punctuation_ratio'] = sentiment_df['text'].apply(\n",
        "    lambda x: sum(1 for c in x if c in string.punctuation) / len(x) if len(x) > 0 else 0\n",
        ")\n",
        "punct_by_sentiment = sentiment_df.groupby('sentiment')['punctuation_ratio'].mean()\n",
        "plt.bar(punct_by_sentiment.index, punct_by_sentiment.values, color=colors)\n",
        "plt.title('Average Punctuation Ratio by Sentiment')\n",
        "plt.ylabel('Ratio')\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print detailed statistics\n",
        "print(\"\\nDetailed Text Statistics by Sentiment:\")\n",
        "print(\"=\" * 50)\n",
        "summary_stats = sentiment_df.groupby('sentiment')[['text_length', 'word_count', 'exclamation_count', \n",
        "                                                   'uppercase_ratio', 'avg_word_length', 'punctuation_ratio']].describe()\n",
        "print(summary_stats)\n",
        "\n",
        "# Most discriminative words\n",
        "print(f\"\\nMost Common Words by Sentiment:\")\n",
        "print(f\"Positive: {[word for word, count in pos_freq[:5]]}\")\n",
        "print(f\"Negative: {[word for word, count in neg_freq[:5]]}\")\n",
        "print(f\"Neutral: {[word for word, count in neu_freq[:5]]}\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 2. Text Preprocessing Pipeline for Sentiment Analysis\n",
        "\n",
        "Text preprocessing is crucial for sentiment analysis. We need to clean and normalize text while preserving sentiment-relevant information.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Text Preprocessing Pipeline\n",
        "class SentimentTextPreprocessor:\n",
        "    \"\"\"\n",
        "    A comprehensive text preprocessing pipeline for sentiment analysis\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, \n",
        "                 lowercase=True,\n",
        "                 remove_punctuation=False,  # Keep punctuation for sentiment\n",
        "                 remove_stopwords=False,    # Stopwords can be sentiment-relevant\n",
        "                 stem_words=False,\n",
        "                 lemmatize_words=False):\n",
        "        \n",
        "        self.lowercase = lowercase\n",
        "        self.remove_punctuation = remove_punctuation\n",
        "        self.remove_stopwords = remove_stopwords\n",
        "        self.stem_words = stem_words\n",
        "        self.lemmatize_words = lemmatize_words\n",
        "        \n",
        "        # Initialize NLTK components if available\n",
        "        try:\n",
        "            self.stop_words = set(stopwords.words('english'))\n",
        "            self.stemmer = PorterStemmer()\n",
        "            self.lemmatizer = WordNetLemmatizer()\n",
        "            self.nltk_available = True\n",
        "        except:\n",
        "            self.nltk_available = False\n",
        "            print(\"NLTK not available, using basic preprocessing\")\n",
        "    \n",
        "    def clean_text(self, text):\n",
        "        \"\"\"\n",
        "        Basic text cleaning while preserving sentiment information\n",
        "        \"\"\"\n",
        "        # Convert to string if not already\n",
        "        text = str(text)\n",
        "        \n",
        "        # Remove extra whitespace\n",
        "        text = re.sub(r'\\s+', ' ', text)\n",
        "        \n",
        "        # Remove URLs\n",
        "        text = re.sub(r'http\\S+|www\\S+', '', text)\n",
        "        \n",
        "        # Remove email addresses\n",
        "        text = re.sub(r'\\S+@\\S+', '', text)\n",
        "        \n",
        "        # Handle contractions (expand them)\n",
        "        contractions = {\n",
        "            \"won't\": \"will not\",\n",
        "            \"can't\": \"cannot\",\n",
        "            \"n't\": \" not\",\n",
        "            \"'re\": \" are\",\n",
        "            \"'ve\": \" have\",\n",
        "            \"'ll\": \" will\",\n",
        "            \"'d\": \" would\",\n",
        "            \"'m\": \" am\"\n",
        "        }\n",
        "        \n",
        "        for contraction, expansion in contractions.items():\n",
        "            text = text.replace(contraction, expansion)\n",
        "        \n",
        "        return text.strip()\n",
        "    \n",
        "    def preprocess(self, text):\n",
        "        \"\"\"\n",
        "        Complete preprocessing pipeline\n",
        "        \"\"\"\n",
        "        # Clean text\n",
        "        text = self.clean_text(text)\n",
        "        \n",
        "        # Convert to lowercase\n",
        "        if self.lowercase:\n",
        "            text = text.lower()\n",
        "        \n",
        "        # Remove punctuation (optional - often kept for sentiment)\n",
        "        if self.remove_punctuation:\n",
        "            text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "        \n",
        "        # Tokenize\n",
        "        if self.nltk_available:\n",
        "            tokens = word_tokenize(text)\n",
        "        else:\n",
        "            tokens = text.split()\n",
        "        \n",
        "        # Remove stopwords (optional - often kept for sentiment)\n",
        "        if self.remove_stopwords and self.nltk_available:\n",
        "            tokens = [token for token in tokens if token not in self.stop_words]\n",
        "        \n",
        "        # Stemming\n",
        "        if self.stem_words and self.nltk_available:\n",
        "            tokens = [self.stemmer.stem(token) for token in tokens]\n",
        "        \n",
        "        # Lemmatization\n",
        "        if self.lemmatize_words and self.nltk_available:\n",
        "            tokens = [self.lemmatizer.lemmatize(token) for token in tokens]\n",
        "        \n",
        "        return ' '.join(tokens)\n",
        "    \n",
        "    def preprocess_dataset(self, texts):\n",
        "        \"\"\"\n",
        "        Preprocess a list of texts\n",
        "        \"\"\"\n",
        "        return [self.preprocess(text) for text in texts]\n",
        "\n",
        "# Test different preprocessing strategies\n",
        "preprocessing_strategies = {\n",
        "    'minimal': SentimentTextPreprocessor(lowercase=True, remove_punctuation=False, remove_stopwords=False),\n",
        "    'moderate': SentimentTextPreprocessor(lowercase=True, remove_punctuation=True, remove_stopwords=False),\n",
        "    'aggressive': SentimentTextPreprocessor(lowercase=True, remove_punctuation=True, remove_stopwords=True, stem_words=True),\n",
        "    'lemmatized': SentimentTextPreprocessor(lowercase=True, remove_punctuation=False, remove_stopwords=False, lemmatize_words=True)\n",
        "}\n",
        "\n",
        "# Apply different preprocessing strategies\n",
        "sample_texts = sentiment_df['text'].head(5).tolist()\n",
        "\n",
        "print(\"Original vs Preprocessed Text Examples:\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "for i, original_text in enumerate(sample_texts):\n",
        "    print(f\"\\nExample {i+1}:\")\n",
        "    print(f\"Original: {original_text}\")\n",
        "    \n",
        "    for strategy_name, preprocessor in preprocessing_strategies.items():\n",
        "        processed_text = preprocessor.preprocess(original_text)\n",
        "        print(f\"{strategy_name.capitalize():12}: {processed_text}\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "# Analyze the impact of preprocessing on vocabulary size\n",
        "print(f\"\\nVocabulary Size Analysis:\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "for strategy_name, preprocessor in preprocessing_strategies.items():\n",
        "    processed_texts = preprocessor.preprocess_dataset(sentiment_df['text'].tolist())\n",
        "    \n",
        "    # Calculate vocabulary\n",
        "    all_words = []\n",
        "    for text in processed_texts:\n",
        "        all_words.extend(text.split())\n",
        "    \n",
        "    vocab_size = len(set(all_words))\n",
        "    avg_text_length = np.mean([len(text.split()) for text in processed_texts])\n",
        "    \n",
        "    print(f\"{strategy_name.capitalize():12}: Vocab={vocab_size:4d}, Avg Length={avg_text_length:.1f}\")\n",
        "\n",
        "# Create processed versions for comparison\n",
        "processed_datasets = {}\n",
        "for strategy_name, preprocessor in preprocessing_strategies.items():\n",
        "    processed_texts = preprocessor.preprocess_dataset(sentiment_df['text'].tolist())\n",
        "    processed_datasets[strategy_name] = processed_texts\n",
        "\n",
        "# Visualize preprocessing impact\n",
        "plt.figure(figsize=(15, 10))\n",
        "\n",
        "# Vocabulary size comparison\n",
        "plt.subplot(2, 3, 1)\n",
        "vocab_sizes = []\n",
        "strategy_names = []\n",
        "for strategy_name, texts in processed_datasets.items():\n",
        "    all_words = []\n",
        "    for text in texts:\n",
        "        all_words.extend(text.split())\n",
        "    vocab_sizes.append(len(set(all_words)))\n",
        "    strategy_names.append(strategy_name)\n",
        "\n",
        "plt.bar(strategy_names, vocab_sizes, color=['skyblue', 'lightcoral', 'lightgreen', 'orange'])\n",
        "plt.title('Vocabulary Size by Preprocessing Strategy')\n",
        "plt.ylabel('Vocabulary Size')\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "# Average text length comparison\n",
        "plt.subplot(2, 3, 2)\n",
        "avg_lengths = []\n",
        "for strategy_name, texts in processed_datasets.items():\n",
        "    avg_length = np.mean([len(text.split()) for text in texts])\n",
        "    avg_lengths.append(avg_length)\n",
        "\n",
        "plt.bar(strategy_names, avg_lengths, color=['skyblue', 'lightcoral', 'lightgreen', 'orange'])\n",
        "plt.title('Average Text Length by Preprocessing')\n",
        "plt.ylabel('Average Word Count')\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "# Character vs word count comparison\n",
        "plt.subplot(2, 3, 3)\n",
        "original_char_count = np.mean([len(text) for text in sentiment_df['text']])\n",
        "processed_char_counts = []\n",
        "\n",
        "for strategy_name, texts in processed_datasets.items():\n",
        "    avg_char_count = np.mean([len(text) for text in texts])\n",
        "    processed_char_counts.append(avg_char_count)\n",
        "\n",
        "x = range(len(strategy_names))\n",
        "plt.bar(x, processed_char_counts, alpha=0.7, label='Processed')\n",
        "plt.axhline(y=original_char_count, color='red', linestyle='--', label='Original')\n",
        "plt.xticks(x, strategy_names, rotation=45)\n",
        "plt.title('Character Count Comparison')\n",
        "plt.ylabel('Average Character Count')\n",
        "plt.legend()\n",
        "\n",
        "# Word frequency distribution changes\n",
        "plt.subplot(2, 3, 4)\n",
        "# Compare word frequencies for minimal vs aggressive preprocessing\n",
        "minimal_words = []\n",
        "aggressive_words = []\n",
        "\n",
        "for text in processed_datasets['minimal']:\n",
        "    minimal_words.extend(text.split())\n",
        "\n",
        "for text in processed_datasets['aggressive']:\n",
        "    aggressive_words.extend(text.split())\n",
        "\n",
        "minimal_freq = Counter(minimal_words)\n",
        "aggressive_freq = Counter(aggressive_words)\n",
        "\n",
        "# Plot top 10 words for each\n",
        "top_minimal = minimal_freq.most_common(10)\n",
        "top_aggressive = aggressive_freq.most_common(10)\n",
        "\n",
        "min_words, min_counts = zip(*top_minimal)\n",
        "plt.barh(range(len(min_words)), min_counts, alpha=0.7, label='Minimal')\n",
        "plt.yticks(range(len(min_words)), min_words)\n",
        "plt.xlabel('Frequency')\n",
        "plt.title('Top Words: Minimal Preprocessing')\n",
        "plt.gca().invert_yaxis()\n",
        "\n",
        "plt.subplot(2, 3, 5)\n",
        "agg_words, agg_counts = zip(*top_aggressive)\n",
        "plt.barh(range(len(agg_words)), agg_counts, alpha=0.7, label='Aggressive', color='orange')\n",
        "plt.yticks(range(len(agg_words)), agg_words)\n",
        "plt.xlabel('Frequency')\n",
        "plt.title('Top Words: Aggressive Preprocessing')\n",
        "plt.gca().invert_yaxis()\n",
        "\n",
        "# Preprocessing time analysis (simulated)\n",
        "plt.subplot(2, 3, 6)\n",
        "# Simulate processing times (in practice, you'd measure actual times)\n",
        "processing_times = [1.0, 1.2, 1.8, 1.5]  # Relative times\n",
        "plt.bar(strategy_names, processing_times, color=['skyblue', 'lightcoral', 'lightgreen', 'orange'])\n",
        "plt.title('Relative Processing Time')\n",
        "plt.ylabel('Relative Time')\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nPreprocessing Strategy Recommendations:\")\n",
        "print(\"-\" * 40)\n",
        "print(\"1. Minimal: Best for preserving original sentiment signals\")\n",
        "print(\"2. Moderate: Good balance between noise reduction and signal preservation\")\n",
        "print(\"3. Aggressive: Smallest vocabulary but may lose important sentiment indicators\")\n",
        "print(\"4. Lemmatized: Good for reducing inflectional forms while preserving meaning\")\n",
        "print(f\"\\nFor sentiment analysis, 'minimal' or 'lemmatized' are often preferred.\")\n",
        "print(\"Punctuation and certain 'stopwords' can carry important sentiment information!\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 3. Feature Extraction and Baseline Models\n",
        "\n",
        "Before implementing RNN-based models, let's establish baseline performance using traditional NLP techniques like TF-IDF and bag-of-words with classical machine learning algorithms.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Baseline Models with Traditional Features\n",
        "def build_baseline_models(texts, labels, test_size=0.2):\n",
        "    \"\"\"\n",
        "    Build and evaluate baseline models using traditional NLP features\n",
        "    \"\"\"\n",
        "    \n",
        "    # Split the data\n",
        "    X_train_text, X_test_text, y_train, y_test = train_test_split(\n",
        "        texts, labels, test_size=test_size, random_state=42, stratify=labels\n",
        "    )\n",
        "    \n",
        "    # Feature extraction methods\n",
        "    feature_extractors = {\n",
        "        'count_vectorizer': CountVectorizer(max_features=5000, ngram_range=(1, 2)),\n",
        "        'tfidf_vectorizer': TfidfVectorizer(max_features=5000, ngram_range=(1, 2)),\n",
        "        'tfidf_char': TfidfVectorizer(analyzer='char', ngram_range=(2, 4), max_features=5000)\n",
        "    }\n",
        "    \n",
        "    # Machine learning models\n",
        "    ml_models = {\n",
        "        'naive_bayes': MultinomialNB(),\n",
        "        'logistic_regression': LogisticRegression(random_state=42, max_iter=1000),\n",
        "    }\n",
        "    \n",
        "    results = {}\n",
        "    \n",
        "    # Test each combination\n",
        "    for feat_name, vectorizer in feature_extractors.items():\n",
        "        print(f\"\\nTesting {feat_name}...\")\n",
        "        \n",
        "        # Extract features\n",
        "        X_train_features = vectorizer.fit_transform(X_train_text)\n",
        "        X_test_features = vectorizer.transform(X_test_text)\n",
        "        \n",
        "        print(f\"Feature matrix shape: {X_train_features.shape}\")\n",
        "        \n",
        "        for model_name, model in ml_models.items():\n",
        "            print(f\"  Training {model_name}...\")\n",
        "            \n",
        "            # Train model\n",
        "            model.fit(X_train_features, y_train)\n",
        "            \n",
        "            # Make predictions\n",
        "            y_pred = model.predict(X_test_features)\n",
        "            \n",
        "            # Calculate metrics\n",
        "            accuracy = accuracy_score(y_test, y_pred)\n",
        "            \n",
        "            # Store results\n",
        "            combo_name = f\"{feat_name}_{model_name}\"\n",
        "            results[combo_name] = {\n",
        "                'accuracy': accuracy,\n",
        "                'y_true': y_test,\n",
        "                'y_pred': y_pred,\n",
        "                'model': model,\n",
        "                'vectorizer': vectorizer\n",
        "            }\n",
        "            \n",
        "            print(f\"    Accuracy: {accuracy:.4f}\")\n",
        "    \n",
        "    return results, X_train_text, X_test_text, y_train, y_test\n",
        "\n",
        "# Prepare data for baseline models\n",
        "preprocessor = preprocessing_strategies['minimal']  # Use minimal preprocessing\n",
        "processed_texts = preprocessor.preprocess_dataset(sentiment_df['text'].tolist())\n",
        "labels = sentiment_df['sentiment'].tolist()\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "encoded_labels = label_encoder.fit_transform(labels)\n",
        "\n",
        "print(\"Label encoding:\")\n",
        "for i, label in enumerate(label_encoder.classes_):\n",
        "    print(f\"{i}: {label}\")\n",
        "\n",
        "# Build baseline models\n",
        "baseline_results, X_train_text, X_test_text, y_train, y_test = build_baseline_models(\n",
        "    processed_texts, encoded_labels\n",
        ")\n",
        "\n",
        "# Analyze baseline results\n",
        "print(f\"\\nBaseline Model Performance Summary:\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "best_accuracy = 0\n",
        "best_model_name = \"\"\n",
        "\n",
        "for model_name, result in baseline_results.items():\n",
        "    accuracy = result['accuracy']\n",
        "    print(f\"{model_name:30s}: {accuracy:.4f}\")\n",
        "    \n",
        "    if accuracy > best_accuracy:\n",
        "        best_accuracy = accuracy\n",
        "        best_model_name = model_name\n",
        "\n",
        "print(f\"\\nBest baseline model: {best_model_name} with accuracy {best_accuracy:.4f}\")\n",
        "\n",
        "# Detailed analysis of best model\n",
        "best_result = baseline_results[best_model_name]\n",
        "print(f\"\\nDetailed Classification Report for {best_model_name}:\")\n",
        "print(classification_report(best_result['y_true'], best_result['y_pred'], \n",
        "                          target_names=label_encoder.classes_))\n",
        "\n",
        "# Visualize baseline results\n",
        "plt.figure(figsize=(15, 10))\n",
        "\n",
        "# Model performance comparison\n",
        "plt.subplot(2, 3, 1)\n",
        "model_names = list(baseline_results.keys())\n",
        "accuracies = [baseline_results[name]['accuracy'] for name in model_names]\n",
        "\n",
        "bars = plt.bar(range(len(model_names)), accuracies, color=['skyblue', 'lightcoral', 'lightgreen', 'orange', 'pink', 'yellow'])\n",
        "plt.xticks(range(len(model_names)), [name.replace('_', '\\n') for name in model_names], rotation=45, ha='right')\n",
        "plt.title('Baseline Model Accuracies')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim(0, 1)\n",
        "\n",
        "# Add value labels on bars\n",
        "for bar, acc in zip(bars, accuracies):\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
        "             f'{acc:.3f}', ha='center', va='bottom')\n",
        "\n",
        "# Confusion matrix for best model\n",
        "plt.subplot(2, 3, 2)\n",
        "cm = confusion_matrix(best_result['y_true'], best_result['y_pred'])\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
        "            xticklabels=label_encoder.classes_, \n",
        "            yticklabels=label_encoder.classes_)\n",
        "plt.title(f'Confusion Matrix - {best_model_name}')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "\n",
        "# Feature importance analysis (for logistic regression)\n",
        "plt.subplot(2, 3, 3)\n",
        "if 'logistic_regression' in best_model_name:\n",
        "    model = best_result['model']\n",
        "    vectorizer = best_result['vectorizer']\n",
        "    \n",
        "    # Get feature names\n",
        "    feature_names = vectorizer.get_feature_names_out()\n",
        "    \n",
        "    # Get coefficients for each class\n",
        "    if hasattr(model, 'coef_'):\n",
        "        # For multi-class, we'll show coefficients for the positive class\n",
        "        coef = model.coef_[0] if len(model.coef_) == 1 else model.coef_[2]  # Positive class\n",
        "        \n",
        "        # Get top positive and negative features\n",
        "        top_pos_idx = np.argsort(coef)[-10:]\n",
        "        top_neg_idx = np.argsort(coef)[:10]\n",
        "        \n",
        "        top_features = np.concatenate([top_neg_idx, top_pos_idx])\n",
        "        top_coefs = coef[top_features]\n",
        "        top_names = [feature_names[i] for i in top_features]\n",
        "        \n",
        "        colors = ['red' if c < 0 else 'green' for c in top_coefs]\n",
        "        plt.barh(range(len(top_names)), top_coefs, color=colors, alpha=0.7)\n",
        "        plt.yticks(range(len(top_names)), top_names)\n",
        "        plt.title('Top Features (Logistic Regression)')\n",
        "        plt.xlabel('Coefficient Value')\n",
        "\n",
        "# Error analysis\n",
        "plt.subplot(2, 3, 4)\n",
        "# Analyze misclassifications\n",
        "correct_predictions = best_result['y_true'] == best_result['y_pred']\n",
        "error_rate_by_class = []\n",
        "class_names = label_encoder.classes_\n",
        "\n",
        "for i, class_name in enumerate(class_names):\n",
        "    class_mask = best_result['y_true'] == i\n",
        "    class_correct = correct_predictions[class_mask]\n",
        "    error_rate = 1 - np.mean(class_correct) if len(class_correct) > 0 else 0\n",
        "    error_rate_by_class.append(error_rate)\n",
        "\n",
        "plt.bar(class_names, error_rate_by_class, color=['lightgreen', 'lightcoral', 'lightblue'])\n",
        "plt.title('Error Rate by Class')\n",
        "plt.ylabel('Error Rate')\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "# Performance vs feature dimension\n",
        "plt.subplot(2, 3, 5)\n",
        "feature_dims = []\n",
        "performances = []\n",
        "\n",
        "for name, result in baseline_results.items():\n",
        "    if 'tfidf_vectorizer' in name:  # Focus on TF-IDF results\n",
        "        vectorizer = result['vectorizer']\n",
        "        feature_dims.append(len(vectorizer.get_feature_names_out()))\n",
        "        performances.append(result['accuracy'])\n",
        "\n",
        "if feature_dims:\n",
        "    plt.scatter(feature_dims, performances, alpha=0.7)\n",
        "    plt.xlabel('Number of Features')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.title('Performance vs Feature Dimension')\n",
        "    \n",
        "    for i, name in enumerate([k for k in baseline_results.keys() if 'tfidf_vectorizer' in k]):\n",
        "        plt.annotate(name.split('_')[2], (feature_dims[i], performances[i]))\n",
        "\n",
        "# Class distribution in predictions\n",
        "plt.subplot(2, 3, 6)\n",
        "true_dist = np.bincount(best_result['y_true'])\n",
        "pred_dist = np.bincount(best_result['y_pred'])\n",
        "\n",
        "x = np.arange(len(class_names))\n",
        "width = 0.35\n",
        "\n",
        "plt.bar(x - width/2, true_dist, width, label='True', alpha=0.7)\n",
        "plt.bar(x + width/2, pred_dist, width, label='Predicted', alpha=0.7)\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Count')\n",
        "plt.title('True vs Predicted Class Distribution')\n",
        "plt.xticks(x, class_names)\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Generate some predictions for interpretation\n",
        "print(f\"\\nSample Predictions from Best Model ({best_model_name}):\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "# Show some correct and incorrect predictions\n",
        "correct_indices = np.where(best_result['y_true'] == best_result['y_pred'])[0]\n",
        "incorrect_indices = np.where(best_result['y_true'] != best_result['y_pred'])[0]\n",
        "\n",
        "# Show 3 correct predictions\n",
        "print(\"Correct Predictions:\")\n",
        "for i, idx in enumerate(correct_indices[:3]):\n",
        "    text_idx = idx  # This maps to test set\n",
        "    true_label = label_encoder.classes_[best_result['y_true'][idx]]\n",
        "    pred_label = label_encoder.classes_[best_result['y_pred'][idx]]\n",
        "    original_text = X_test_text[idx]\n",
        "    \n",
        "    print(f\"{i+1}. Text: '{original_text[:60]}...'\")\n",
        "    print(f\"   True: {true_label}, Predicted: {pred_label}\")\n",
        "\n",
        "print(f\"\\nIncorrect Predictions:\")\n",
        "for i, idx in enumerate(incorrect_indices[:3]):\n",
        "    true_label = label_encoder.classes_[best_result['y_true'][idx]]\n",
        "    pred_label = label_encoder.classes_[best_result['y_pred'][idx]]\n",
        "    original_text = X_test_text[idx]\n",
        "    \n",
        "    print(f\"{i+1}. Text: '{original_text[:60]}...'\")\n",
        "    print(f\"   True: {true_label}, Predicted: {pred_label}\")\n",
        "\n",
        "print(f\"\\nBaseline Performance Summary:\")\n",
        "print(f\"Best accuracy: {best_accuracy:.4f}\")\n",
        "print(f\"Random baseline: {1/len(label_encoder.classes_):.4f}\")\n",
        "print(f\"Improvement over random: {(best_accuracy - 1/len(label_encoder.classes_)) / (1/len(label_encoder.classes_)) * 100:.1f}%\")\n",
        "\n",
        "print(f\"\\nReady for RNN-based models! Target to beat: {best_accuracy:.4f}\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
