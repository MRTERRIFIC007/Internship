{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# LSTM Architecture Deep Dive\n",
        "\n",
        "## Learning Objectives\n",
        "In this notebook, we'll master the LSTM architecture:\n",
        "- Complete understanding of LSTM cell state and hidden state mechanics\n",
        "- Deep analysis of forget gate, input gate, and output gate operations\n",
        "- Mathematical formulation and step-by-step computation walkthrough\n",
        "- Cell state update mechanisms and information flow\n",
        "- LSTM vs SimpleRNN architectural comparison\n",
        "- Implementation of custom LSTM components\n",
        "\n",
        "## Introduction to LSTM Architecture\n",
        "\n",
        "Long Short-Term Memory (LSTM) networks solve the vanishing gradient problem through sophisticated gating mechanisms. Unlike SimpleRNNs, LSTMs can selectively forget, remember, and output information through three specialized gates.\n",
        "\n",
        "### Key LSTM Components:\n",
        "1. **Cell State (C_t)**: The \"memory highway\" that flows through time\n",
        "2. **Hidden State (h_t)**: The output state passed to next time step\n",
        "3. **Forget Gate**: Decides what information to discard from cell state\n",
        "4. **Input Gate**: Decides what new information to store in cell state\n",
        "5. **Output Gate**: Controls what parts of cell state to output\n",
        "\n",
        "### LSTM Mathematical Formulation:\n",
        "- **Forget Gate**: f_t = σ(W_f · [h_{t-1}, x_t] + b_f)\n",
        "- **Input Gate**: i_t = σ(W_i · [h_{t-1}, x_t] + b_i)\n",
        "- **Candidate Values**: C̃_t = tanh(W_C · [h_{t-1}, x_t] + b_C)\n",
        "- **Cell State**: C_t = f_t * C_{t-1} + i_t * C̃_t\n",
        "- **Output Gate**: o_t = σ(W_o · [h_{t-1}, x_t] + b_o)\n",
        "- **Hidden State**: h_t = o_t * tanh(C_t)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "print(\"LSTM Architecture Deep Dive initialized!\")\n",
        "\n",
        "# Set plotting style\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. Custom LSTM Implementation for Understanding\n",
        "class CustomLSTMCell:\n",
        "    \"\"\"\n",
        "    Custom LSTM cell implementation to understand the mathematics\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        \n",
        "        # Initialize weights (simplified initialization)\n",
        "        self.W_f = np.random.randn(hidden_size, input_size + hidden_size) * 0.1  # Forget gate\n",
        "        self.b_f = np.zeros((hidden_size, 1))\n",
        "        \n",
        "        self.W_i = np.random.randn(hidden_size, input_size + hidden_size) * 0.1  # Input gate\n",
        "        self.b_i = np.zeros((hidden_size, 1))\n",
        "        \n",
        "        self.W_C = np.random.randn(hidden_size, input_size + hidden_size) * 0.1  # Candidate values\n",
        "        self.b_C = np.zeros((hidden_size, 1))\n",
        "        \n",
        "        self.W_o = np.random.randn(hidden_size, input_size + hidden_size) * 0.1  # Output gate\n",
        "        self.b_o = np.zeros((hidden_size, 1))\n",
        "        \n",
        "    def sigmoid(self, x):\n",
        "        \"\"\"Sigmoid activation function\"\"\"\n",
        "        return 1 / (1 + np.exp(-np.clip(x, -500, 500)))\n",
        "    \n",
        "    def tanh(self, x):\n",
        "        \"\"\"Tanh activation function\"\"\"\n",
        "        return np.tanh(np.clip(x, -500, 500))\n",
        "    \n",
        "    def forward(self, x_t, h_prev, C_prev):\n",
        "        \"\"\"\n",
        "        Forward pass through LSTM cell\n",
        "        \n",
        "        Args:\n",
        "            x_t: Input at time t (input_size, 1)\n",
        "            h_prev: Previous hidden state (hidden_size, 1)\n",
        "            C_prev: Previous cell state (hidden_size, 1)\n",
        "            \n",
        "        Returns:\n",
        "            h_t: New hidden state\n",
        "            C_t: New cell state\n",
        "            gates: Dictionary containing gate values for analysis\n",
        "        \"\"\"\n",
        "        # Concatenate input and previous hidden state\n",
        "        concat_input = np.vstack([h_prev, x_t])\n",
        "        \n",
        "        # Compute gates\n",
        "        f_t = self.sigmoid(np.dot(self.W_f, concat_input) + self.b_f)  # Forget gate\n",
        "        i_t = self.sigmoid(np.dot(self.W_i, concat_input) + self.b_i)  # Input gate\n",
        "        C_tilde = self.tanh(np.dot(self.W_C, concat_input) + self.b_C)  # Candidate values\n",
        "        o_t = self.sigmoid(np.dot(self.W_o, concat_input) + self.b_o)  # Output gate\n",
        "        \n",
        "        # Update cell state\n",
        "        C_t = f_t * C_prev + i_t * C_tilde\n",
        "        \n",
        "        # Compute hidden state\n",
        "        h_t = o_t * self.tanh(C_t)\n",
        "        \n",
        "        # Store gate values for analysis\n",
        "        gates = {\n",
        "            'forget_gate': f_t,\n",
        "            'input_gate': i_t,\n",
        "            'candidate_values': C_tilde,\n",
        "            'output_gate': o_t\n",
        "        }\n",
        "        \n",
        "        return h_t, C_t, gates\n",
        "\n",
        "# 2. LSTM Analysis and Visualization\n",
        "class LSTMAnalyzer:\n",
        "    \"\"\"\n",
        "    Analyze LSTM behavior and visualize internal states\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, lstm_cell):\n",
        "        self.lstm_cell = lstm_cell\n",
        "        self.states_history = []\n",
        "        \n",
        "    def run_sequence(self, input_sequence):\n",
        "        \"\"\"\n",
        "        Run LSTM on a sequence and record all states\n",
        "        \"\"\"\n",
        "        sequence_length = len(input_sequence)\n",
        "        hidden_size = self.lstm_cell.hidden_size\n",
        "        \n",
        "        # Initialize states\n",
        "        h_t = np.zeros((hidden_size, 1))\n",
        "        C_t = np.zeros((hidden_size, 1))\n",
        "        \n",
        "        states_history = []\n",
        "        \n",
        "        for t, x_t in enumerate(input_sequence):\n",
        "            x_t = x_t.reshape(-1, 1)  # Ensure correct shape\n",
        "            h_t, C_t, gates = self.lstm_cell.forward(x_t, h_t, C_t)\n",
        "            \n",
        "            state_info = {\n",
        "                'timestep': t,\n",
        "                'input': x_t.flatten(),\n",
        "                'hidden_state': h_t.flatten(),\n",
        "                'cell_state': C_t.flatten(),\n",
        "                'forget_gate': gates['forget_gate'].flatten(),\n",
        "                'input_gate': gates['input_gate'].flatten(),\n",
        "                'candidate_values': gates['candidate_values'].flatten(),\n",
        "                'output_gate': gates['output_gate'].flatten()\n",
        "            }\n",
        "            \n",
        "            states_history.append(state_info)\n",
        "        \n",
        "        self.states_history = states_history\n",
        "        return states_history\n",
        "    \n",
        "    def visualize_lstm_dynamics(self):\n",
        "        \"\"\"\n",
        "        Create comprehensive visualization of LSTM internal dynamics\n",
        "        \"\"\"\n",
        "        if not self.states_history:\n",
        "            print(\"No states to visualize. Run a sequence first.\")\n",
        "            return\n",
        "        \n",
        "        # Extract data for visualization\n",
        "        timesteps = [state['timestep'] for state in self.states_history]\n",
        "        inputs = np.array([state['input'] for state in self.states_history])\n",
        "        hidden_states = np.array([state['hidden_state'] for state in self.states_history])\n",
        "        cell_states = np.array([state['cell_state'] for state in self.states_history])\n",
        "        forget_gates = np.array([state['forget_gate'] for state in self.states_history])\n",
        "        input_gates = np.array([state['input_gate'] for state in self.states_history])\n",
        "        candidate_values = np.array([state['candidate_values'] for state in self.states_history])\n",
        "        output_gates = np.array([state['output_gate'] for state in self.states_history])\n",
        "        \n",
        "        # Create visualization\n",
        "        fig, axes = plt.subplots(3, 3, figsize=(18, 15))\n",
        "        \n",
        "        # Input sequence\n",
        "        axes[0, 0].plot(timesteps, inputs.mean(axis=1), 'b-', linewidth=2)\n",
        "        axes[0, 0].set_title('Input Sequence')\n",
        "        axes[0, 0].set_xlabel('Time Step')\n",
        "        axes[0, 0].set_ylabel('Input Value')\n",
        "        axes[0, 0].grid(True, alpha=0.3)\n",
        "        \n",
        "        # Hidden state evolution\n",
        "        for i in range(min(3, hidden_states.shape[1])):\n",
        "            axes[0, 1].plot(timesteps, hidden_states[:, i], label=f'h_{i}', alpha=0.7)\n",
        "        axes[0, 1].set_title('Hidden State Evolution')\n",
        "        axes[0, 1].set_xlabel('Time Step')\n",
        "        axes[0, 1].set_ylabel('Hidden State Value')\n",
        "        axes[0, 1].legend()\n",
        "        axes[0, 1].grid(True, alpha=0.3)\n",
        "        \n",
        "        # Cell state evolution\n",
        "        for i in range(min(3, cell_states.shape[1])):\n",
        "            axes[0, 2].plot(timesteps, cell_states[:, i], label=f'C_{i}', alpha=0.7)\n",
        "        axes[0, 2].set_title('Cell State Evolution')\n",
        "        axes[0, 2].set_xlabel('Time Step')\n",
        "        axes[0, 2].set_ylabel('Cell State Value')\n",
        "        axes[0, 2].legend()\n",
        "        axes[0, 2].grid(True, alpha=0.3)\n",
        "        \n",
        "        # Forget gate heatmap\n",
        "        im1 = axes[1, 0].imshow(forget_gates.T, aspect='auto', cmap='RdYlBu_r', interpolation='nearest')\n",
        "        axes[1, 0].set_title('Forget Gate Activations')\n",
        "        axes[1, 0].set_xlabel('Time Step')\n",
        "        axes[1, 0].set_ylabel('Hidden Unit')\n",
        "        plt.colorbar(im1, ax=axes[1, 0])\n",
        "        \n",
        "        # Input gate heatmap\n",
        "        im2 = axes[1, 1].imshow(input_gates.T, aspect='auto', cmap='RdYlBu_r', interpolation='nearest')\n",
        "        axes[1, 1].set_title('Input Gate Activations')\n",
        "        axes[1, 1].set_xlabel('Time Step')\n",
        "        axes[1, 1].set_ylabel('Hidden Unit')\n",
        "        plt.colorbar(im2, ax=axes[1, 1])\n",
        "        \n",
        "        # Output gate heatmap\n",
        "        im3 = axes[1, 2].imshow(output_gates.T, aspect='auto', cmap='RdYlBu_r', interpolation='nearest')\n",
        "        axes[1, 2].set_title('Output Gate Activations')\n",
        "        axes[1, 2].set_xlabel('Time Step')\n",
        "        axes[1, 2].set_ylabel('Hidden Unit')\n",
        "        plt.colorbar(im3, ax=axes[1, 2])\n",
        "        \n",
        "        # Gate activation distributions\n",
        "        all_forget = forget_gates.flatten()\n",
        "        all_input = input_gates.flatten()\n",
        "        all_output = output_gates.flatten()\n",
        "        \n",
        "        axes[2, 0].hist([all_forget, all_input, all_output], bins=30, alpha=0.7, \n",
        "                       label=['Forget', 'Input', 'Output'], color=['red', 'blue', 'green'])\n",
        "        axes[2, 0].set_title('Gate Activation Distributions')\n",
        "        axes[2, 0].set_xlabel('Activation Value')\n",
        "        axes[2, 0].set_ylabel('Frequency')\n",
        "        axes[2, 0].legend()\n",
        "        \n",
        "        # Information flow analysis\n",
        "        forget_avg = forget_gates.mean(axis=1)\n",
        "        input_avg = input_gates.mean(axis=1)\n",
        "        output_avg = output_gates.mean(axis=1)\n",
        "        \n",
        "        axes[2, 1].plot(timesteps, forget_avg, 'r-', label='Forget Gate', alpha=0.7)\n",
        "        axes[2, 1].plot(timesteps, input_avg, 'b-', label='Input Gate', alpha=0.7)\n",
        "        axes[2, 1].plot(timesteps, output_avg, 'g-', label='Output Gate', alpha=0.7)\n",
        "        axes[2, 1].set_title('Average Gate Activations Over Time')\n",
        "        axes[2, 1].set_xlabel('Time Step')\n",
        "        axes[2, 1].set_ylabel('Average Activation')\n",
        "        axes[2, 1].legend()\n",
        "        axes[2, 1].grid(True, alpha=0.3)\n",
        "        \n",
        "        # Memory retention analysis\n",
        "        cell_magnitude = np.linalg.norm(cell_states, axis=1)\n",
        "        hidden_magnitude = np.linalg.norm(hidden_states, axis=1)\n",
        "        \n",
        "        axes[2, 2].plot(timesteps, cell_magnitude, 'purple', label='Cell State Magnitude', alpha=0.7)\n",
        "        axes[2, 2].plot(timesteps, hidden_magnitude, 'orange', label='Hidden State Magnitude', alpha=0.7)\n",
        "        axes[2, 2].set_title('State Magnitude Evolution')\n",
        "        axes[2, 2].set_xlabel('Time Step')\n",
        "        axes[2, 2].set_ylabel('L2 Norm')\n",
        "        axes[2, 2].legend()\n",
        "        axes[2, 2].grid(True, alpha=0.3)\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "# 3. LSTM vs SimpleRNN Comparison\n",
        "def create_comparison_models(input_size, hidden_size, sequence_length):\n",
        "    \"\"\"\n",
        "    Create LSTM and SimpleRNN models for comparison\n",
        "    \"\"\"\n",
        "    # LSTM model\n",
        "    lstm_model = keras.Sequential([\n",
        "        layers.LSTM(hidden_size, return_sequences=True, return_state=False),\n",
        "        layers.Dense(input_size, activation='linear')\n",
        "    ], name='LSTM_Model')\n",
        "    \n",
        "    # SimpleRNN model  \n",
        "    rnn_model = keras.Sequential([\n",
        "        layers.SimpleRNN(hidden_size, return_sequences=True, return_state=False),\n",
        "        layers.Dense(input_size, activation='linear')\n",
        "    ], name='SimpleRNN_Model')\n",
        "    \n",
        "    # Compile models\n",
        "    lstm_model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "    rnn_model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "    \n",
        "    return lstm_model, rnn_model\n",
        "\n",
        "# Initialize custom LSTM for analysis\n",
        "input_size = 3\n",
        "hidden_size = 8\n",
        "custom_lstm = CustomLSTMCell(input_size, hidden_size)\n",
        "analyzer = LSTMAnalyzer(custom_lstm)\n",
        "\n",
        "# Create test sequence\n",
        "test_sequence = [\n",
        "    np.array([1.0, 0.5, 0.2]),   # t=0\n",
        "    np.array([0.8, 1.0, 0.1]),   # t=1  \n",
        "    np.array([0.3, 0.7, 0.9]),   # t=2\n",
        "    np.array([0.1, 0.2, 0.8]),   # t=3\n",
        "    np.array([0.9, 0.1, 0.3]),   # t=4\n",
        "    np.array([0.5, 0.8, 0.4]),   # t=5\n",
        "    np.array([0.2, 0.9, 0.7]),   # t=6\n",
        "    np.array([0.7, 0.3, 0.6])    # t=7\n",
        "]\n",
        "\n",
        "print(\"Running LSTM analysis on test sequence...\")\n",
        "states_history = analyzer.run_sequence(test_sequence)\n",
        "\n",
        "print(f\"Analyzed {len(states_history)} time steps\")\n",
        "print(\"Generating LSTM dynamics visualization...\")\n",
        "\n",
        "# Visualize LSTM dynamics\n",
        "analyzer.visualize_lstm_dynamics()\n",
        "\n",
        "# Print some statistics\n",
        "print(f\"\\nLSTM Analysis Summary:\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "final_state = states_history[-1]\n",
        "print(f\"Final hidden state range: [{final_state['hidden_state'].min():.3f}, {final_state['hidden_state'].max():.3f}]\")\n",
        "print(f\"Final cell state range: [{final_state['cell_state'].min():.3f}, {final_state['cell_state'].max():.3f}]\")\n",
        "\n",
        "# Gate activation statistics\n",
        "all_forget = np.array([state['forget_gate'] for state in states_history])\n",
        "all_input = np.array([state['input_gate'] for state in states_history])\n",
        "all_output = np.array([state['output_gate'] for state in states_history])\n",
        "\n",
        "print(f\"\\nGate Activation Statistics:\")\n",
        "print(f\"Forget gate - Mean: {all_forget.mean():.3f}, Std: {all_forget.std():.3f}\")\n",
        "print(f\"Input gate - Mean: {all_input.mean():.3f}, Std: {all_input.std():.3f}\")\n",
        "print(f\"Output gate - Mean: {all_output.mean():.3f}, Std: {all_output.std():.3f}\")\n",
        "\n",
        "print(f\"\\nLSTM Architecture Deep Dive Complete!\")\n",
        "print(f\"Understanding of gate mechanisms and cell dynamics achieved!\")\n",
        "print(f\"Ready for LSTM variations and improvements!\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
