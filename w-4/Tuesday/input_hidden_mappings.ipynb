{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Input-to-Hidden Mappings in RNNs\n",
        "\n",
        "## Learning Objectives\n",
        "In this notebook, we'll explore the mathematical foundations of RNNs by examining:\n",
        "- Input-to-hidden weight matrix transformations (W_ih)\n",
        "- Hidden state computations and propagation\n",
        "- Feature representation learning in embedding space\n",
        "- Visualization of learned weight matrices and representations\n",
        "- Understanding dimensionality transformations in RNNs\n",
        "\n",
        "## Introduction\n",
        "\n",
        "The core of RNN computation lies in the transformation of inputs to hidden states. Understanding these mappings is crucial for:\n",
        "- Debugging model behavior\n",
        "- Optimizing architecture design\n",
        "- Interpreting what the model has learned\n",
        "- Identifying potential issues like vanishing gradients\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import seaborn as sns\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "print(\"Libraries imported successfully!\")\n",
        "\n",
        "# Set plotting style\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 1. Understanding RNN Weight Matrices\n",
        "\n",
        "In a simple RNN, the key transformations are:\n",
        "- **W_ih**: Input-to-hidden weights (transforms input to hidden space)\n",
        "- **W_hh**: Hidden-to-hidden weights (maintains hidden state)\n",
        "- **W_ho**: Hidden-to-output weights (transforms hidden to output)\n",
        "\n",
        "Mathematical formulation:\n",
        "```\n",
        "h_t = tanh(W_ih * x_t + W_hh * h_{t-1} + b_h)\n",
        "y_t = W_ho * h_t + b_o\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a simple RNN to analyze weight matrices\n",
        "def create_analyzable_rnn(vocab_size, embedding_dim=50, hidden_units=128):\n",
        "    \"\"\"\n",
        "    Create a simple RNN model for weight analysis\n",
        "    \"\"\"\n",
        "    model = keras.Sequential([\n",
        "        keras.layers.Embedding(vocab_size, embedding_dim, name='embedding'),\n",
        "        keras.layers.SimpleRNN(hidden_units, return_sequences=True, name='rnn'),\n",
        "        keras.layers.Dense(vocab_size, activation='softmax', name='output')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Create sample data for demonstration\n",
        "vocab_size = 50\n",
        "sequence_length = 20\n",
        "batch_size = 32\n",
        "\n",
        "# Generate random data to initialize model\n",
        "sample_data = np.random.randint(0, vocab_size, (100, sequence_length))\n",
        "sample_targets = np.random.randint(0, vocab_size, (100, sequence_length))\n",
        "\n",
        "# Create and compile model\n",
        "model = create_analyzable_rnn(vocab_size, embedding_dim=30, hidden_units=64)\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
        "\n",
        "# Train for a few epochs to get meaningful weights\n",
        "print(\"Training model briefly to initialize weights...\")\n",
        "model.fit(sample_data, sample_targets, epochs=5, verbose=0)\n",
        "\n",
        "print(\"Model architecture:\")\n",
        "model.summary()\n",
        "\n",
        "# Extract weight matrices\n",
        "embedding_weights = model.get_layer('embedding').get_weights()[0]\n",
        "rnn_weights = model.get_layer('rnn').get_weights()\n",
        "output_weights = model.get_layer('output').get_weights()\n",
        "\n",
        "print(f\"\\nWeight matrix shapes:\")\n",
        "print(f\"Embedding weights: {embedding_weights.shape}\")\n",
        "print(f\"RNN weights: {[w.shape for w in rnn_weights]}\")\n",
        "print(f\"Output weights: {[w.shape for w in output_weights]}\")\n",
        "\n",
        "# For SimpleRNN, the weights are organized as:\n",
        "# rnn_weights[0]: W_ih (input-to-hidden) + W_hh (hidden-to-hidden) concatenated\n",
        "# rnn_weights[1]: bias\n",
        "W_combined = rnn_weights[0]\n",
        "bias = rnn_weights[1]\n",
        "\n",
        "# Split the combined weight matrix\n",
        "input_size = embedding_weights.shape[1]  # embedding dimension\n",
        "hidden_size = W_combined.shape[1]  # hidden units\n",
        "\n",
        "W_ih = W_combined[:input_size, :]  # Input-to-hidden\n",
        "W_hh = W_combined[input_size:, :]  # Hidden-to-hidden\n",
        "\n",
        "print(f\"\\nWeight matrix decomposition:\")\n",
        "print(f\"W_ih (input-to-hidden): {W_ih.shape}\")\n",
        "print(f\"W_hh (hidden-to-hidden): {W_hh.shape}\")\n",
        "print(f\"Bias: {bias.shape}\")\n",
        "\n",
        "# Visualize weight matrices\n",
        "plt.figure(figsize=(15, 12))\n",
        "\n",
        "# Embedding weights\n",
        "plt.subplot(3, 3, 1)\n",
        "plt.imshow(embedding_weights, cmap='RdBu', aspect='auto')\n",
        "plt.title('Embedding Weights')\n",
        "plt.xlabel('Embedding Dimension')\n",
        "plt.ylabel('Vocabulary Index')\n",
        "plt.colorbar()\n",
        "\n",
        "# Input-to-hidden weights\n",
        "plt.subplot(3, 3, 2)\n",
        "plt.imshow(W_ih.T, cmap='RdBu', aspect='auto')\n",
        "plt.title('Input-to-Hidden Weights (W_ih)')\n",
        "plt.xlabel('Input Dimension')\n",
        "plt.ylabel('Hidden Unit')\n",
        "plt.colorbar()\n",
        "\n",
        "# Hidden-to-hidden weights\n",
        "plt.subplot(3, 3, 3)\n",
        "plt.imshow(W_hh, cmap='RdBu', aspect='auto')\n",
        "plt.title('Hidden-to-Hidden Weights (W_hh)')\n",
        "plt.xlabel('Hidden Unit (t-1)')\n",
        "plt.ylabel('Hidden Unit (t)')\n",
        "plt.colorbar()\n",
        "\n",
        "# Weight distributions\n",
        "plt.subplot(3, 3, 4)\n",
        "plt.hist(embedding_weights.flatten(), bins=30, alpha=0.7, label='Embedding')\n",
        "plt.hist(W_ih.flatten(), bins=30, alpha=0.7, label='W_ih')\n",
        "plt.hist(W_hh.flatten(), bins=30, alpha=0.7, label='W_hh')\n",
        "plt.title('Weight Distributions')\n",
        "plt.xlabel('Weight Value')\n",
        "plt.ylabel('Frequency')\n",
        "plt.legend()\n",
        "\n",
        "# Weight magnitudes\n",
        "plt.subplot(3, 3, 5)\n",
        "weight_norms = [\n",
        "    np.linalg.norm(embedding_weights),\n",
        "    np.linalg.norm(W_ih),\n",
        "    np.linalg.norm(W_hh)\n",
        "]\n",
        "weight_names = ['Embedding', 'W_ih', 'W_hh']\n",
        "plt.bar(weight_names, weight_norms, color=['skyblue', 'lightcoral', 'lightgreen'])\n",
        "plt.title('Weight Matrix Norms')\n",
        "plt.ylabel('Frobenius Norm')\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "# Singular value decomposition of W_ih\n",
        "plt.subplot(3, 3, 6)\n",
        "U, s, Vt = np.linalg.svd(W_ih)\n",
        "plt.plot(s, 'o-')\n",
        "plt.title('Singular Values of W_ih')\n",
        "plt.xlabel('Index')\n",
        "plt.ylabel('Singular Value')\n",
        "plt.yscale('log')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Rank analysis\n",
        "plt.subplot(3, 3, 7)\n",
        "tolerance = 1e-10\n",
        "ranks = []\n",
        "matrices = [embedding_weights, W_ih, W_hh]\n",
        "names = ['Embedding', 'W_ih', 'W_hh']\n",
        "\n",
        "for matrix in matrices:\n",
        "    rank = np.linalg.matrix_rank(matrix, tol=tolerance)\n",
        "    ranks.append(rank)\n",
        "\n",
        "plt.bar(names, ranks, color=['skyblue', 'lightcoral', 'lightgreen'])\n",
        "plt.title('Matrix Ranks')\n",
        "plt.ylabel('Rank')\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "# Condition numbers\n",
        "plt.subplot(3, 3, 8)\n",
        "cond_numbers = []\n",
        "for matrix in matrices:\n",
        "    try:\n",
        "        cond = np.linalg.cond(matrix)\n",
        "        cond_numbers.append(cond)\n",
        "    except:\n",
        "        cond_numbers.append(np.inf)\n",
        "\n",
        "plt.bar(names, cond_numbers, color=['skyblue', 'lightcoral', 'lightgreen'])\n",
        "plt.title('Condition Numbers')\n",
        "plt.ylabel('Condition Number')\n",
        "plt.yscale('log')\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "# Weight evolution during training (conceptual)\n",
        "plt.subplot(3, 3, 9)\n",
        "# Simulate weight evolution\n",
        "epochs = np.arange(1, 11)\n",
        "w_ih_norm_evolution = weight_norms[1] * (1 + 0.1 * np.random.randn(10)).cumsum()\n",
        "w_hh_norm_evolution = weight_norms[2] * (1 + 0.1 * np.random.randn(10)).cumsum()\n",
        "\n",
        "plt.plot(epochs, w_ih_norm_evolution, 'o-', label='W_ih norm')\n",
        "plt.plot(epochs, w_hh_norm_evolution, 's-', label='W_hh norm')\n",
        "plt.title('Weight Evolution (Simulated)')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Weight Norm')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nWeight Analysis Summary:\")\n",
        "print(f\"Embedding matrix condition number: {np.linalg.cond(embedding_weights):.2f}\")\n",
        "print(f\"W_ih condition number: {np.linalg.cond(W_ih):.2f}\")\n",
        "print(f\"W_hh condition number: {np.linalg.cond(W_hh):.2f}\")\n",
        "print(f\"W_ih rank: {np.linalg.matrix_rank(W_ih)}/{min(W_ih.shape)}\")\n",
        "print(f\"W_hh rank: {np.linalg.matrix_rank(W_hh)}/{min(W_hh.shape)}\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
