{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# CNN Fundamentals\n",
        "\n",
        "## Learning Objectives\n",
        "- Understand the core principles of convolutional layers\n",
        "- Explore different ConvNet layer types\n",
        "- Distinguish between activation and pooling layers\n",
        "- Implement basic CNN operations from scratch\n",
        "\n",
        "## Session 1: 10:30-11:30 - Deep Dive into Convolutional Neural Networks\n",
        "\n",
        "Welcome to the visual world of deep learning! CNNs have revolutionized computer vision by mimicking how our visual cortex processes images - through hierarchical feature detection.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Essential imports for CNN exploration\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import cv2\n",
        "from skimage import data, filters, feature\n",
        "import seaborn as sns\n",
        "from scipy import ndimage, signal\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set style for better visualizations\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"üöÄ Ready to explore CNNs!\")\n",
        "print(f\"TensorFlow version: {tf.__version__}\")\n",
        "print(f\"OpenCV version: {cv2.__version__}\")\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 1. The Convolution Operation\n",
        "\n",
        "The heart of CNNs is the convolution operation. Unlike fully connected layers that look at the entire input, convolution focuses on local patterns using small filters (kernels).\n",
        "\n",
        "**Mathematical Definition:**\n",
        "For a 2D image I and filter K, convolution is:\n",
        "(I * K)(i,j) = Œ£Œ£ I(m,n) √ó K(i-m, j-n)\n",
        "\n",
        "**Key Properties:**\n",
        "- **Translation Invariance**: A feature detected at position (x,y) can be detected anywhere\n",
        "- **Parameter Sharing**: Same filter weights used across all positions\n",
        "- **Sparse Connectivity**: Each output connects to only a small region of input\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Let's implement convolution from scratch to understand the operation\n",
        "def conv2d_manual(image, kernel, stride=1, padding=0):\n",
        "    \"\"\"\n",
        "    Manual implementation of 2D convolution\n",
        "    \n",
        "    Args:\n",
        "        image: Input image (2D numpy array)\n",
        "        kernel: Convolution kernel/filter (2D numpy array)\n",
        "        stride: Stride for convolution\n",
        "        padding: Padding size\n",
        "    \n",
        "    Returns:\n",
        "        Convolved feature map\n",
        "    \"\"\"\n",
        "    # Add padding if specified\n",
        "    if padding > 0:\n",
        "        image = np.pad(image, padding, mode='constant', constant_values=0)\n",
        "    \n",
        "    # Get dimensions\n",
        "    img_h, img_w = image.shape\n",
        "    kernel_h, kernel_w = kernel.shape\n",
        "    \n",
        "    # Calculate output dimensions\n",
        "    out_h = (img_h - kernel_h) // stride + 1\n",
        "    out_w = (img_w - kernel_w) // stride + 1\n",
        "    \n",
        "    # Initialize output\n",
        "    output = np.zeros((out_h, out_w))\n",
        "    \n",
        "    # Perform convolution\n",
        "    for i in range(0, out_h):\n",
        "        for j in range(0, out_w):\n",
        "            # Extract region of interest\n",
        "            h_start = i * stride\n",
        "            h_end = h_start + kernel_h\n",
        "            w_start = j * stride\n",
        "            w_end = w_start + kernel_w\n",
        "            \n",
        "            # Element-wise multiplication and sum\n",
        "            output[i, j] = np.sum(image[h_start:h_end, w_start:w_end] * kernel)\n",
        "    \n",
        "    return output\n",
        "\n",
        "# Create a sample image and demonstrate convolution\n",
        "np.random.seed(42)\n",
        "sample_image = np.random.rand(8, 8)\n",
        "\n",
        "# Define common computer vision kernels\n",
        "kernels = {\n",
        "    'Edge Detection (Sobel X)': np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]]),\n",
        "    'Edge Detection (Sobel Y)': np.array([[-1, -2, -1], [0, 0, 0], [1, 2, 1]]),\n",
        "    'Blur (Average)': np.ones((3, 3)) / 9,\n",
        "    'Sharpen': np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]]),\n",
        "    'Identity': np.array([[0, 0, 0], [0, 1, 0], [0, 0, 0]])\n",
        "}\n",
        "\n",
        "print(\"üîç Manual Convolution Demonstration:\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"Original image shape: {sample_image.shape}\")\n",
        "\n",
        "# Apply different kernels\n",
        "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "fig.suptitle('Convolution with Different Kernels', fontsize=16, fontweight='bold')\n",
        "\n",
        "# Show original image\n",
        "axes[0, 0].imshow(sample_image, cmap='gray')\n",
        "axes[0, 0].set_title('Original Image')\n",
        "axes[0, 0].axis('off')\n",
        "\n",
        "# Apply each kernel\n",
        "for idx, (name, kernel) in enumerate(list(kernels.items())[:5]):\n",
        "    row = (idx + 1) // 3\n",
        "    col = (idx + 1) % 3\n",
        "    \n",
        "    # Perform convolution\n",
        "    convolved = conv2d_manual(sample_image, kernel, padding=1)\n",
        "    \n",
        "    # Display result\n",
        "    axes[row, col].imshow(convolved, cmap='gray')\n",
        "    axes[row, col].set_title(f'{name}\\nOutput: {convolved.shape}')\n",
        "    axes[row, col].axis('off')\n",
        "    \n",
        "    print(f\"{name}: {sample_image.shape} -> {convolved.shape}\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nüìä Key Observations:\")\n",
        "print(\"‚Ä¢ Convolution creates feature maps that highlight specific patterns\")\n",
        "print(\"‚Ä¢ Different kernels detect different features (edges, blur, etc.)\")\n",
        "print(\"‚Ä¢ Output size depends on input size, kernel size, stride, and padding\")\n",
        "print(\"‚Ä¢ Each kernel acts as a feature detector\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 2. CNN Architecture Components\n",
        "\n",
        "A complete CNN consists of several types of layers working together:\n",
        "\n",
        "### 2.1 Convolutional Layers\n",
        "- **Purpose**: Feature extraction using learnable filters\n",
        "- **Parameters**: Weights of the kernels (learned during training)\n",
        "- **Output**: Feature maps showing detected patterns\n",
        "\n",
        "### 2.2 Activation Layers  \n",
        "- **Purpose**: Add non-linearity after convolution\n",
        "- **Common choices**: ReLU, Leaky ReLU, ELU\n",
        "- **Why needed**: Enable learning of complex patterns\n",
        "\n",
        "### 2.3 Pooling Layers\n",
        "- **Purpose**: Reduce spatial dimensions and computational load\n",
        "- **Types**: Max pooling, Average pooling, Global pooling\n",
        "- **Benefits**: Translation invariance, reduced overfitting\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Implement pooling operations from scratch\n",
        "def max_pool2d(feature_map, pool_size=2, stride=2):\n",
        "    \"\"\"\n",
        "    Manual implementation of max pooling\n",
        "    \n",
        "    Args:\n",
        "        feature_map: Input feature map (2D array)\n",
        "        pool_size: Size of pooling window\n",
        "        stride: Stride for pooling\n",
        "    \n",
        "    Returns:\n",
        "        Pooled feature map\n",
        "    \"\"\"\n",
        "    h, w = feature_map.shape\n",
        "    out_h = (h - pool_size) // stride + 1\n",
        "    out_w = (w - pool_size) // stride + 1\n",
        "    \n",
        "    output = np.zeros((out_h, out_w))\n",
        "    \n",
        "    for i in range(out_h):\n",
        "        for j in range(out_w):\n",
        "            h_start = i * stride\n",
        "            h_end = h_start + pool_size\n",
        "            w_start = j * stride\n",
        "            w_end = w_start + pool_size\n",
        "            \n",
        "            # Take maximum value in the window\n",
        "            output[i, j] = np.max(feature_map[h_start:h_end, w_start:w_end])\n",
        "    \n",
        "    return output\n",
        "\n",
        "def avg_pool2d(feature_map, pool_size=2, stride=2):\n",
        "    \"\"\"\n",
        "    Manual implementation of average pooling\n",
        "    \"\"\"\n",
        "    h, w = feature_map.shape\n",
        "    out_h = (h - pool_size) // stride + 1\n",
        "    out_w = (w - pool_size) // stride + 1\n",
        "    \n",
        "    output = np.zeros((out_h, out_w))\n",
        "    \n",
        "    for i in range(out_h):\n",
        "        for j in range(out_w):\n",
        "            h_start = i * stride\n",
        "            h_end = h_start + pool_size\n",
        "            w_start = j * stride\n",
        "            w_end = w_start + pool_size\n",
        "            \n",
        "            # Take average value in the window\n",
        "            output[i, j] = np.mean(feature_map[h_start:h_end, w_start:w_end])\n",
        "    \n",
        "    return output\n",
        "\n",
        "# Build a complete CNN from scratch using TensorFlow\n",
        "def create_simple_cnn(input_shape, num_classes):\n",
        "    \"\"\"\n",
        "    Create a simple CNN architecture\n",
        "    \n",
        "    Args:\n",
        "        input_shape: Shape of input images (height, width, channels)\n",
        "        num_classes: Number of output classes\n",
        "    \n",
        "    Returns:\n",
        "        Compiled Keras model\n",
        "    \"\"\"\n",
        "    model = keras.Sequential([\n",
        "        # First convolutional block\n",
        "        layers.Conv2D(32, (3, 3), input_shape=input_shape, name='conv1'),\n",
        "        layers.Activation('relu', name='relu1'),\n",
        "        layers.MaxPooling2D((2, 2), name='pool1'),\n",
        "        \n",
        "        # Second convolutional block\n",
        "        layers.Conv2D(64, (3, 3), name='conv2'),\n",
        "        layers.Activation('relu', name='relu2'),\n",
        "        layers.MaxPooling2D((2, 2), name='pool2'),\n",
        "        \n",
        "        # Third convolutional block\n",
        "        layers.Conv2D(128, (3, 3), name='conv3'),\n",
        "        layers.Activation('relu', name='relu3'),\n",
        "        layers.MaxPooling2D((2, 2), name='pool3'),\n",
        "        \n",
        "        # Flatten and dense layers\n",
        "        layers.Flatten(name='flatten'),\n",
        "        layers.Dense(512, name='dense1'),\n",
        "        layers.Activation('relu', name='relu4'),\n",
        "        layers.Dropout(0.5, name='dropout'),\n",
        "        layers.Dense(num_classes, activation='softmax', name='output')\n",
        "    ])\n",
        "    \n",
        "    return model\n",
        "\n",
        "# Demonstrate pooling operations\n",
        "# Create a sample feature map with clear patterns\n",
        "test_feature_map = np.array([\n",
        "    [1, 3, 2, 4, 1, 2, 3, 1],\n",
        "    [2, 8, 7, 1, 4, 5, 2, 3],\n",
        "    [3, 2, 9, 6, 2, 1, 4, 2],\n",
        "    [1, 4, 3, 8, 3, 6, 1, 4],\n",
        "    [4, 1, 2, 5, 7, 2, 8, 1],\n",
        "    [2, 6, 4, 1, 2, 9, 3, 5],\n",
        "    [3, 2, 7, 8, 1, 4, 6, 2],\n",
        "    [1, 5, 2, 3, 4, 1, 2, 7]\n",
        "], dtype=float)\n",
        "\n",
        "# Apply pooling operations\n",
        "max_pooled = max_pool2d(test_feature_map, pool_size=2, stride=2)\n",
        "avg_pooled = avg_pool2d(test_feature_map, pool_size=2, stride=2)\n",
        "\n",
        "# Visualize pooling effects\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "fig.suptitle('Pooling Operations Comparison', fontsize=16, fontweight='bold')\n",
        "\n",
        "# Original feature map\n",
        "im1 = axes[0].imshow(test_feature_map, cmap='viridis', interpolation='nearest')\n",
        "axes[0].set_title(f'Original Feature Map\\n{test_feature_map.shape}')\n",
        "axes[0].set_xlabel('Width')\n",
        "axes[0].set_ylabel('Height')\n",
        "plt.colorbar(im1, ax=axes[0])\n",
        "\n",
        "# Add grid lines for clarity\n",
        "for i in range(test_feature_map.shape[0] + 1):\n",
        "    axes[0].axhline(i - 0.5, color='white', linewidth=0.5)\n",
        "for j in range(test_feature_map.shape[1] + 1):\n",
        "    axes[0].axvline(j - 0.5, color='white', linewidth=0.5)\n",
        "\n",
        "# Max pooled\n",
        "im2 = axes[1].imshow(max_pooled, cmap='viridis', interpolation='nearest')\n",
        "axes[1].set_title(f'Max Pooled\\n{max_pooled.shape}')\n",
        "axes[1].set_xlabel('Width')\n",
        "axes[1].set_ylabel('Height')\n",
        "plt.colorbar(im2, ax=axes[1])\n",
        "\n",
        "# Average pooled\n",
        "im3 = axes[2].imshow(avg_pooled, cmap='viridis', interpolation='nearest')\n",
        "axes[2].set_title(f'Average Pooled\\n{avg_pooled.shape}')\n",
        "axes[2].set_xlabel('Width')\n",
        "axes[2].set_ylabel('Height')\n",
        "plt.colorbar(im3, ax=axes[2])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Create and display CNN architecture\n",
        "model = create_simple_cnn((32, 32, 3), 10)  # CIFAR-10 like input\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "print(\"\\nüèóÔ∏è CNN Architecture Summary:\")\n",
        "print(\"=\" * 50)\n",
        "model.summary()\n",
        "\n",
        "print(\"\\nüìä Pooling Results:\")\n",
        "print(f\"Original size: {test_feature_map.shape}\")\n",
        "print(f\"Max pooled size: {max_pooled.shape}\")\n",
        "print(f\"Average pooled size: {avg_pooled.shape}\")\n",
        "print(f\"Size reduction: {test_feature_map.size} -> {max_pooled.size} ({max_pooled.size/test_feature_map.size:.1%})\")\n",
        "\n",
        "print(\"\\nüîç Key Insights:\")\n",
        "print(\"‚Ä¢ Max pooling preserves strongest activations (important features)\")\n",
        "print(\"‚Ä¢ Average pooling provides smoother representation\")\n",
        "print(\"‚Ä¢ Both reduce spatial dimensions while preserving important information\")\n",
        "print(\"‚Ä¢ Pooling provides translation invariance\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Personal Reflection: Session 1 Complete\n",
        "\n",
        "### What I've Learned:\n",
        "\n",
        "1. **Convolution is Feature Detection**: Each filter learns to detect specific patterns - edges, textures, shapes\n",
        "2. **Hierarchical Learning**: Early layers detect simple features, deeper layers combine them into complex patterns\n",
        "3. **Parameter Efficiency**: Shared weights make CNNs much more efficient than fully connected networks\n",
        "4. **Translation Invariance**: Features detected anywhere in the image contribute to classification\n",
        "\n",
        "### Connection to Yesterday:\n",
        "The activation functions we studied yesterday (ReLU, Leaky ReLU) are crucial for CNNs. They provide the non-linearity needed after each convolution to enable complex pattern learning.\n",
        "\n",
        "### Looking Ahead:\n",
        "Understanding these fundamentals prepares us for advanced topics like transfer learning, object detection, and modern architectures like ResNet and DenseNet.\n",
        "\n",
        "**Next Session Preview**: We'll apply these concepts to real image classification tasks and compare CNN performance to traditional methods!\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
