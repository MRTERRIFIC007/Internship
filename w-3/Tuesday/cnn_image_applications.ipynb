{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# CNN Image Applications\n",
        "\n",
        "## Learning Objectives\n",
        "- Understand advantages and disadvantages of CNNs for image processing\n",
        "- Explore digital image processing basics\n",
        "- Work with different image types (grayscale, RGB, etc.)\n",
        "- Compare CNN vs traditional computer vision methods\n",
        "\n",
        "## Session 2: 11:30-12:30 & 13:30-14:30 - Real-World CNN Applications\n",
        "\n",
        "Time to see CNNs in action! We'll work with real images and understand why CNNs revolutionized computer vision.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Essential imports for CNN image applications\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import cv2\n",
        "from skimage import data, feature, filters, segmentation, color\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "from PIL import Image\n",
        "import requests\n",
        "from io import BytesIO\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set style for better visualizations\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"üöÄ Ready to explore CNN applications on real images!\")\n",
        "print(f\"TensorFlow version: {tf.__version__}\")\n",
        "print(f\"OpenCV version: {cv2.__version__}\")\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 1. Digital Image Processing Fundamentals\n",
        "\n",
        "### 1.1 Understanding Image Types\n",
        "\n",
        "**Grayscale Images:**\n",
        "- Single channel (intensity values 0-255)\n",
        "- Shape: (height, width)\n",
        "- Memory efficient, good for many CV tasks\n",
        "\n",
        "**RGB Images:**\n",
        "- Three channels (Red, Green, Blue)\n",
        "- Shape: (height, width, 3)\n",
        "- Each pixel has color information\n",
        "\n",
        "**Other Color Spaces:**\n",
        "- HSV (Hue, Saturation, Value)\n",
        "- LAB (Lightness, A, B)\n",
        "- YUV (Luminance, Chrominance)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load and explore different image types\n",
        "def load_sample_images():\n",
        "    \"\"\"Load various types of sample images for demonstration\"\"\"\n",
        "    \n",
        "    # Load built-in sample images from scikit-image\n",
        "    images = {\n",
        "        'Cameraman': data.camera(),           # Grayscale\n",
        "        'Astronaut': data.astronaut(),        # RGB\n",
        "        'Coins': data.coins(),                # Grayscale\n",
        "        'Coffee': data.coffee(),              # RGB\n",
        "        'Chelsea (Cat)': data.chelsea(),      # RGB\n",
        "    }\n",
        "    \n",
        "    return images\n",
        "\n",
        "# Load sample images\n",
        "sample_images = load_sample_images()\n",
        "\n",
        "# Analyze image properties\n",
        "def analyze_image_properties(image, name):\n",
        "    \"\"\"Analyze and display properties of an image\"\"\"\n",
        "    print(f\"\\nüìä {name} Image Analysis:\")\n",
        "    print(\"-\" * 40)\n",
        "    print(f\"Shape: {image.shape}\")\n",
        "    print(f\"Data type: {image.dtype}\")\n",
        "    print(f\"Min value: {image.min()}\")\n",
        "    print(f\"Max value: {image.max()}\")\n",
        "    print(f\"Mean value: {image.mean():.2f}\")\n",
        "    print(f\"Memory usage: {image.nbytes} bytes\")\n",
        "    \n",
        "    if len(image.shape) == 2:\n",
        "        print(\"Type: Grayscale\")\n",
        "        print(f\"Unique values: {len(np.unique(image))}\")\n",
        "    else:\n",
        "        print(f\"Type: {image.shape[2]}-channel color\")\n",
        "        for i in range(image.shape[2]):\n",
        "            channel_name = ['Red', 'Green', 'Blue'][i] if image.shape[2] == 3 else f'Channel {i}'\n",
        "            print(f\"{channel_name} - Min: {image[:,:,i].min()}, Max: {image[:,:,i].max()}, Mean: {image[:,:,i].mean():.2f}\")\n",
        "\n",
        "# Display sample images with their properties\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "fig.suptitle('Digital Image Types and Properties', fontsize=16, fontweight='bold')\n",
        "\n",
        "for idx, (name, img) in enumerate(sample_images.items()):\n",
        "    row = idx // 3\n",
        "    col = idx % 3\n",
        "    \n",
        "    if len(img.shape) == 2:  # Grayscale\n",
        "        axes[row, col].imshow(img, cmap='gray')\n",
        "    else:  # Color\n",
        "        axes[row, col].imshow(img)\n",
        "    \n",
        "    axes[row, col].set_title(f'{name}\\nShape: {img.shape}')\n",
        "    axes[row, col].axis('off')\n",
        "    \n",
        "    # Analyze properties\n",
        "    analyze_image_properties(img, name)\n",
        "\n",
        "# Hide the last subplot if we have an odd number of images\n",
        "if len(sample_images) % 3 != 0:\n",
        "    axes[1, 2].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Demonstrate color space conversions\n",
        "def demonstrate_color_spaces(rgb_image, image_name):\n",
        "    \"\"\"Demonstrate different color space representations\"\"\"\n",
        "    \n",
        "    # Convert to different color spaces\n",
        "    hsv_image = color.rgb2hsv(rgb_image)\n",
        "    lab_image = color.rgb2lab(rgb_image)\n",
        "    gray_image = color.rgb2gray(rgb_image)\n",
        "    \n",
        "    # Create visualization\n",
        "    fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
        "    fig.suptitle(f'Color Space Conversions: {image_name}', fontsize=14, fontweight='bold')\n",
        "    \n",
        "    # Original RGB\n",
        "    axes[0, 0].imshow(rgb_image)\n",
        "    axes[0, 0].set_title('Original RGB')\n",
        "    axes[0, 0].axis('off')\n",
        "    \n",
        "    # RGB channels separately\n",
        "    for i, channel in enumerate(['Red', 'Green', 'Blue']):\n",
        "        axes[0, i+1].imshow(rgb_image[:,:,i], cmap='gray')\n",
        "        axes[0, i+1].set_title(f'{channel} Channel')\n",
        "        axes[0, i+1].axis('off')\n",
        "    \n",
        "    # Grayscale\n",
        "    axes[1, 0].imshow(gray_image, cmap='gray')\n",
        "    axes[1, 0].set_title('Grayscale')\n",
        "    axes[1, 0].axis('off')\n",
        "    \n",
        "    # HSV channels\n",
        "    hsv_channels = ['Hue', 'Saturation', 'Value']\n",
        "    for i, channel in enumerate(hsv_channels):\n",
        "        axes[1, i+1].imshow(hsv_image[:,:,i], cmap='gray')\n",
        "        axes[1, i+1].set_title(f'HSV {channel}')\n",
        "        axes[1, i+1].axis('off')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    return hsv_image, lab_image, gray_image\n",
        "\n",
        "# Demonstrate color space conversions on astronaut image\n",
        "if 'Astronaut' in sample_images:\n",
        "    astronaut_img = sample_images['Astronaut']\n",
        "    hsv_img, lab_img, gray_img = demonstrate_color_spaces(astronaut_img, 'Astronaut')\n",
        "\n",
        "print(\"\\nüîç Key Insights about Digital Images:\")\n",
        "print(\"‚Ä¢ Grayscale images are memory efficient and sufficient for many tasks\")\n",
        "print(\"‚Ä¢ RGB images provide full color information but require 3x memory\")\n",
        "print(\"‚Ä¢ Different color spaces highlight different image properties\")\n",
        "print(\"‚Ä¢ Image preprocessing often involves converting between color spaces\")\n",
        "print(\"‚Ä¢ CNNs can work with any color space, but RGB is most common\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 2. CNN vs Traditional Computer Vision\n",
        "\n",
        "Let's compare modern CNN approaches with traditional computer vision methods for image classification.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load and prepare CIFAR-10 dataset for comparison\n",
        "(X_train, y_train), (X_test, y_test) = keras.datasets.cifar10.load_data()\n",
        "\n",
        "# CIFAR-10 class names\n",
        "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', \n",
        "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "# Normalize pixel values\n",
        "X_train = X_train.astype('float32') / 255.0\n",
        "X_test = X_test.astype('float32') / 255.0\n",
        "\n",
        "# Convert labels to categorical\n",
        "y_train_cat = keras.utils.to_categorical(y_train, 10)\n",
        "y_test_cat = keras.utils.to_categorical(y_test, 10)\n",
        "\n",
        "print(\"üìä CIFAR-10 Dataset Overview:\")\n",
        "print(f\"Training images: {X_train.shape}\")\n",
        "print(f\"Test images: {X_test.shape}\")\n",
        "print(f\"Number of classes: {len(class_names)}\")\n",
        "print(f\"Classes: {class_names}\")\n",
        "\n",
        "# Visualize sample images\n",
        "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
        "fig.suptitle('CIFAR-10 Sample Images', fontsize=14, fontweight='bold')\n",
        "\n",
        "for i in range(10):\n",
        "    row = i // 5\n",
        "    col = i % 5\n",
        "    \n",
        "    # Find first occurrence of each class\n",
        "    class_idx = np.where(y_train == i)[0][0]\n",
        "    \n",
        "    axes[row, col].imshow(X_train[class_idx])\n",
        "    axes[row, col].set_title(f'{class_names[i]}')\n",
        "    axes[row, col].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Traditional Computer Vision Approach using Hand-crafted Features\n",
        "def extract_traditional_features(images):\n",
        "    \"\"\"Extract traditional computer vision features\"\"\"\n",
        "    features_list = []\n",
        "    \n",
        "    for img in images:\n",
        "        # Convert to grayscale for traditional methods\n",
        "        if len(img.shape) == 3:\n",
        "            gray = cv2.cvtColor((img * 255).astype(np.uint8), cv2.COLOR_RGB2GRAY)\n",
        "        else:\n",
        "            gray = (img * 255).astype(np.uint8)\n",
        "        \n",
        "        feature_vector = []\n",
        "        \n",
        "        # 1. Color histogram features (using original color image)\n",
        "        if len(img.shape) == 3:\n",
        "            for channel in range(3):\n",
        "                hist = cv2.calcHist([img[:,:,channel]], [0], None, [16], [0, 1])\n",
        "                feature_vector.extend(hist.flatten())\n",
        "        \n",
        "        # 2. Texture features (Local Binary Pattern)\n",
        "        try:\n",
        "            lbp = feature.local_binary_pattern(gray, P=8, R=1, method='uniform')\n",
        "            lbp_hist, _ = np.histogram(lbp, bins=16, range=(0, 16))\n",
        "            feature_vector.extend(lbp_hist)\n",
        "        except:\n",
        "            # Fallback if LBP fails\n",
        "            feature_vector.extend(np.zeros(16))\n",
        "        \n",
        "        # 3. Edge features\n",
        "        edges = feature.canny(gray, sigma=1)\n",
        "        edge_density = np.sum(edges) / edges.size\n",
        "        feature_vector.append(edge_density)\n",
        "        \n",
        "        # 4. Basic statistical features\n",
        "        feature_vector.extend([\n",
        "            np.mean(gray),\n",
        "            np.std(gray),\n",
        "            np.min(gray),\n",
        "            np.max(gray)\n",
        "        ])\n",
        "        \n",
        "        features_list.append(feature_vector)\n",
        "    \n",
        "    return np.array(features_list)\n",
        "\n",
        "# Extract features for a subset (to speed up computation)\n",
        "n_samples = 5000\n",
        "indices = np.random.choice(len(X_train), n_samples, replace=False)\n",
        "X_train_subset = X_train[indices]\n",
        "y_train_subset = y_train[indices]\n",
        "\n",
        "print(\"\\\\nüîß Extracting traditional computer vision features...\")\n",
        "traditional_features = extract_traditional_features(X_train_subset)\n",
        "traditional_features_test = extract_traditional_features(X_test[:1000])  # Subset for testing\n",
        "\n",
        "print(f\"Traditional features shape: {traditional_features.shape}\")\n",
        "\n",
        "# Train traditional classifier (Random Forest)\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "traditional_classifier = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "traditional_classifier.fit(traditional_features, y_train_subset.ravel())\n",
        "\n",
        "# Predict with traditional method\n",
        "trad_predictions = traditional_classifier.predict(traditional_features_test)\n",
        "trad_accuracy = accuracy_score(y_test[:1000].ravel(), trad_predictions)\n",
        "\n",
        "print(f\"\\\\nüìä Traditional CV Accuracy: {trad_accuracy:.4f}\")\n",
        "\n",
        "# Create and train CNN\n",
        "def create_cnn_model():\n",
        "    model = keras.Sequential([\n",
        "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Train CNN (on subset for faster training)\n",
        "cnn_model = create_cnn_model()\n",
        "cnn_model.compile(optimizer='adam', \n",
        "                  loss='categorical_crossentropy', \n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "print(\"\\\\nüß† Training CNN...\")\n",
        "cnn_history = cnn_model.fit(\n",
        "    X_train_subset, keras.utils.to_categorical(y_train_subset, 10),\n",
        "    epochs=10,\n",
        "    batch_size=32,\n",
        "    validation_split=0.2,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluate CNN\n",
        "cnn_test_loss, cnn_accuracy = cnn_model.evaluate(\n",
        "    X_test[:1000], keras.utils.to_categorical(y_test[:1000], 10), \n",
        "    verbose=0\n",
        ")\n",
        "\n",
        "print(f\"\\\\nüìä CNN Accuracy: {cnn_accuracy:.4f}\")\n",
        "\n",
        "# Compare results\n",
        "comparison_data = {\n",
        "    'Method': ['Traditional CV', 'CNN'],\n",
        "    'Accuracy': [trad_accuracy, cnn_accuracy],\n",
        "    'Features': ['Hand-crafted', 'Learned'],\n",
        "    'Training Time': ['Fast', 'Slow'],\n",
        "    'Generalization': ['Limited', 'Excellent']\n",
        "}\n",
        "\n",
        "print(\"\\\\nüèÜ Method Comparison:\")\n",
        "print(\"=\" * 50)\n",
        "for method, acc in zip(comparison_data['Method'], comparison_data['Accuracy']):\n",
        "    print(f\"{method:15}: {acc:.4f} ({acc*100:.2f}%)\")\n",
        "\n",
        "print(\"\\\\nüí° Key Insights:\")\n",
        "print(\"‚Ä¢ CNNs automatically learn optimal features for the task\")\n",
        "print(\"‚Ä¢ Traditional methods require domain expertise for feature engineering\")\n",
        "print(\"‚Ä¢ CNNs generalize better to new, unseen data\")\n",
        "print(\"‚Ä¢ Traditional methods are faster to train but plateau in performance\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
