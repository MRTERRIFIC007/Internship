{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# DBSCAN and Anomaly Detection\n",
        "\n",
        "## Learning Objectives\n",
        "- Understand density-based clustering with DBSCAN\n",
        "- Distinguish between core points, border points, and noise points\n",
        "- Implement DBSCAN for different datasets\n",
        "- Apply statistical methods for anomaly detection\n",
        "- Compare clustering-based vs statistical anomaly detection\n",
        "\n",
        "## DBSCAN Theory\n",
        "\n",
        "**DBSCAN** (Density-Based Spatial Clustering of Applications with Noise):\n",
        "- Groups together points that are closely packed\n",
        "- Marks outliers as noise points in low-density regions\n",
        "\n",
        "### Key Concepts:\n",
        "- **Core Point**: Has at least `min_samples` points within `eps` distance\n",
        "- **Border Point**: Within `eps` distance of a core point but not core itself\n",
        "- **Noise Point**: Neither core nor border point (potential outlier)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.datasets import make_blobs, make_moons, make_circles\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.metrics import silhouette_score, adjusted_rand_score\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.svm import OneClassSVM\n",
        "from sklearn.covariance import EllipticEnvelope\n",
        "from scipy import stats\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "print(\"Libraries imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Dataset Creation\n",
        "\n",
        "Let's create different types of datasets to test DBSCAN and anomaly detection methods.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create different datasets for DBSCAN testing\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "\n",
        "# 1. Blobs dataset\n",
        "X_blobs, y_blobs = make_blobs(n_samples=300, centers=4, n_features=2, \n",
        "                              cluster_std=0.8, random_state=42)\n",
        "axes[0, 0].scatter(X_blobs[:, 0], X_blobs[:, 1], c=y_blobs, cmap='viridis', alpha=0.7)\n",
        "axes[0, 0].set_title('Blobs Dataset')\n",
        "axes[0, 0].set_xlabel('Feature 1')\n",
        "axes[0, 0].set_ylabel('Feature 2')\n",
        "\n",
        "# 2. Moons dataset (non-convex clusters)\n",
        "X_moons, y_moons = make_moons(n_samples=300, noise=0.1, random_state=42)\n",
        "axes[0, 1].scatter(X_moons[:, 0], X_moons[:, 1], c=y_moons, cmap='viridis', alpha=0.7)\n",
        "axes[0, 1].set_title('Moons Dataset (Non-convex)')\n",
        "axes[0, 1].set_xlabel('Feature 1')\n",
        "axes[0, 1].set_ylabel('Feature 2')\n",
        "\n",
        "# 3. Circles dataset (nested clusters)\n",
        "X_circles, y_circles = make_circles(n_samples=300, noise=0.05, factor=0.6, random_state=42)\n",
        "axes[0, 2].scatter(X_circles[:, 0], X_circles[:, 1], c=y_circles, cmap='viridis', alpha=0.7)\n",
        "axes[0, 2].set_title('Circles Dataset (Nested)')\n",
        "axes[0, 2].set_xlabel('Feature 1')\n",
        "axes[0, 2].set_ylabel('Feature 2')\n",
        "\n",
        "# 4. Dataset with outliers\n",
        "np.random.seed(42)\n",
        "X_normal = np.random.normal(0, 1, (280, 2))\n",
        "X_outliers = np.random.uniform(-4, 4, (20, 2))\n",
        "X_with_outliers = np.vstack([X_normal, X_outliers])\n",
        "outlier_labels = np.array([0]*280 + [1]*20)\n",
        "\n",
        "axes[1, 0].scatter(X_with_outliers[:, 0], X_with_outliers[:, 1], \n",
        "                  c=outlier_labels, cmap='coolwarm', alpha=0.7)\n",
        "axes[1, 0].set_title('Dataset with Outliers')\n",
        "axes[1, 0].set_xlabel('Feature 1')\n",
        "axes[1, 0].set_ylabel('Feature 2')\n",
        "\n",
        "# 5. Varying density clusters\n",
        "X_var_density = np.vstack([\n",
        "    np.random.normal([0, 0], 0.5, (100, 2)),\n",
        "    np.random.normal([3, 3], 1.5, (100, 2)),\n",
        "    np.random.normal([-2, 3], 0.3, (50, 2))\n",
        "])\n",
        "axes[1, 1].scatter(X_var_density[:, 0], X_var_density[:, 1], alpha=0.7)\n",
        "axes[1, 1].set_title('Varying Density Clusters')\n",
        "axes[1, 1].set_xlabel('Feature 1')\n",
        "axes[1, 1].set_ylabel('Feature 2')\n",
        "\n",
        "# 6. Noise dataset\n",
        "X_noise = np.random.uniform(-3, 3, (200, 2))\n",
        "axes[1, 2].scatter(X_noise[:, 0], X_noise[:, 1], alpha=0.7)\n",
        "axes[1, 2].set_title('Random Noise')\n",
        "axes[1, 2].set_xlabel('Feature 1')\n",
        "axes[1, 2].set_ylabel('Feature 2')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Store datasets for later use\n",
        "datasets = {\n",
        "    'Blobs': (X_blobs, y_blobs),\n",
        "    'Moons': (X_moons, y_moons),\n",
        "    'Circles': (X_circles, y_circles),\n",
        "    'With Outliers': (X_with_outliers, outlier_labels),\n",
        "    'Varying Density': (X_var_density, None),\n",
        "    'Noise': (X_noise, None)\n",
        "}\n",
        "\n",
        "print(\"Created 6 different datasets for DBSCAN testing\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Finding Optimal DBSCAN Parameters\n",
        "\n",
        "The key challenge with DBSCAN is choosing appropriate `eps` and `min_samples` parameters.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def find_optimal_eps(X, min_samples=5):\n",
        "    \"\"\"Find optimal eps parameter using k-distance graph\"\"\"\n",
        "    # Calculate k-distances (distance to k-th nearest neighbor)\n",
        "    neighbors = NearestNeighbors(n_neighbors=min_samples)\n",
        "    neighbors_fit = neighbors.fit(X)\n",
        "    distances, indices = neighbors_fit.kneighbors(X)\n",
        "    \n",
        "    # Sort distances and plot\n",
        "    k_distances = distances[:, min_samples-1]  # k-th nearest neighbor distance\n",
        "    k_distances = np.sort(k_distances, reverse=True)\n",
        "    \n",
        "    return k_distances\n",
        "\n",
        "# Demonstrate parameter selection for moons dataset\n",
        "X_demo = X_moons\n",
        "min_samples_options = [3, 5, 10]\n",
        "\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "\n",
        "for i, min_samples in enumerate(min_samples_options):\n",
        "    # Plot k-distance graph\n",
        "    k_distances = find_optimal_eps(X_demo, min_samples)\n",
        "    axes[0, i].plot(range(len(k_distances)), k_distances, 'b-', linewidth=2)\n",
        "    axes[0, i].set_title(f'K-Distance Graph (min_samples={min_samples})')\n",
        "    axes[0, i].set_xlabel('Points sorted by distance')\n",
        "    axes[0, i].set_ylabel(f'{min_samples}-NN Distance')\n",
        "    axes[0, i].grid(True, alpha=0.3)\n",
        "    \n",
        "    # Find elbow point (simplified approach)\n",
        "    # Look for the point where the slope changes most dramatically\n",
        "    diffs = np.diff(k_distances)\n",
        "    elbow_idx = np.argmax(diffs)\n",
        "    optimal_eps = k_distances[elbow_idx]\n",
        "    \n",
        "    axes[0, i].axhline(y=optimal_eps, color='r', linestyle='--', \n",
        "                      label=f'Suggested eps: {optimal_eps:.3f}')\n",
        "    axes[0, i].legend()\n",
        "    \n",
        "    # Apply DBSCAN with suggested parameters\n",
        "    dbscan = DBSCAN(eps=optimal_eps, min_samples=min_samples)\n",
        "    cluster_labels = dbscan.fit_predict(X_demo)\n",
        "    \n",
        "    # Plot clustering results\n",
        "    n_clusters = len(set(cluster_labels)) - (1 if -1 in cluster_labels else 0)\n",
        "    n_noise = list(cluster_labels).count(-1)\n",
        "    \n",
        "    scatter = axes[1, i].scatter(X_demo[:, 0], X_demo[:, 1], c=cluster_labels, \n",
        "                               cmap='viridis', alpha=0.7)\n",
        "    axes[1, i].set_title(f'DBSCAN Results\\\\nClusters: {n_clusters}, Noise: {n_noise}')\n",
        "    axes[1, i].set_xlabel('Feature 1')\n",
        "    axes[1, i].set_ylabel('Feature 2')\n",
        "    \n",
        "    # Highlight noise points\n",
        "    noise_mask = cluster_labels == -1\n",
        "    if np.any(noise_mask):\n",
        "        axes[1, i].scatter(X_demo[noise_mask, 0], X_demo[noise_mask, 1], \n",
        "                         c='red', marker='x', s=50, label='Noise')\n",
        "        axes[1, i].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Parameter selection guidelines:\")\n",
        "print(\"- eps: Look for 'elbow' in k-distance graph\")\n",
        "print(\"- min_samples: Start with 2*dimensions, adjust based on noise tolerance\")\n",
        "print(\"- Higher min_samples = more conservative clustering (less noise)\")\n",
        "print(\"- Lower eps = more clusters, higher eps = fewer clusters\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
