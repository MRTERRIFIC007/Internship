{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Data Augmentation Strategies for Computer Vision\n",
        "\n",
        "## Learning Objectives\n",
        "- Understand data augmentation principles and benefits\n",
        "- Implement geometric transformations (rotation, scaling, flipping)\n",
        "- Apply color space augmentations (brightness, contrast, saturation)\n",
        "- Explore advanced techniques (mixup, cutout, random erasing)\n",
        "- Analyze augmentation effects on model performance\n",
        "- Compare different augmentation strategies\n",
        "\n",
        "## Data Augmentation Theory\n",
        "\n",
        "### Core Benefits\n",
        "1. **Increased Data Diversity**: Artificially expand training dataset\n",
        "2. **Improved Generalization**: Reduce overfitting through variation\n",
        "3. **Robustness**: Make models invariant to transformations\n",
        "4. **Cost-Effective**: Generate new samples without collection costs\n",
        "\n",
        "### Categories of Augmentation\n",
        "1. **Geometric**: Rotation, scaling, translation, flipping\n",
        "2. **Color Space**: Brightness, contrast, saturation, hue\n",
        "3. **Noise-Based**: Gaussian noise, salt-pepper noise\n",
        "4. **Advanced**: Mixup, cutout, random erasing, AutoAugment\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from skimage import transform, filters, exposure\n",
        "from skimage.util import random_noise\n",
        "import cv2\n",
        "\n",
        "# Set style and random seed\n",
        "plt.style.use('seaborn-v0_8')\n",
        "np.random.seed(42)\n",
        "\n",
        "print(\"Libraries imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create synthetic images for demonstration\n",
        "def create_sample_images():\n",
        "    \"\"\"Create sample images for augmentation demonstration\"\"\"\n",
        "    \n",
        "    # Create synthetic images with different patterns\n",
        "    img_size = 128\n",
        "    images = []\n",
        "    labels = []\n",
        "    \n",
        "    # Pattern 1: Circles\n",
        "    img1 = np.zeros((img_size, img_size, 3))\n",
        "    center = img_size // 2\n",
        "    for radius in [20, 30, 40]:\n",
        "        y, x = np.ogrid[:img_size, :img_size]\n",
        "        mask = ((x - center)**2 + (y - center)**2) <= radius**2\n",
        "        img1[mask] = [1.0, 0.5, 0.0]  # Orange circles\n",
        "    \n",
        "    # Pattern 2: Stripes\n",
        "    img2 = np.zeros((img_size, img_size, 3))\n",
        "    for i in range(0, img_size, 15):\n",
        "        img2[i:i+7, :] = [0.0, 0.8, 0.2]  # Green stripes\n",
        "    \n",
        "    # Pattern 3: Checkerboard\n",
        "    img3 = np.zeros((img_size, img_size, 3))\n",
        "    square_size = 16\n",
        "    for i in range(0, img_size, square_size):\n",
        "        for j in range(0, img_size, square_size):\n",
        "            if (i // square_size + j // square_size) % 2 == 0:\n",
        "                img3[i:i+square_size, j:j+square_size] = [0.2, 0.4, 0.8]  # Blue squares\n",
        "    \n",
        "    images = [img1, img2, img3]\n",
        "    labels = ['Circles', 'Stripes', 'Checkerboard']\n",
        "    \n",
        "    return np.array(images), labels\n",
        "\n",
        "# Create sample dataset\n",
        "sample_images, image_labels = create_sample_images()\n",
        "\n",
        "# Display original images\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "for i, (img, label) in enumerate(zip(sample_images, image_labels)):\n",
        "    axes[i].imshow(img)\n",
        "    axes[i].set_title(f'Original: {label}')\n",
        "    axes[i].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"Created {len(sample_images)} sample images with shape {sample_images[0].shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Implement comprehensive augmentation functions\n",
        "class DataAugmentationSuite:\n",
        "    \"\"\"Comprehensive data augmentation implementation\"\"\"\n",
        "    \n",
        "    def __init__(self, random_state=42):\n",
        "        self.random_state = random_state\n",
        "        np.random.seed(random_state)\n",
        "    \n",
        "    def geometric_augmentations(self, image):\n",
        "        \"\"\"Apply geometric transformations\"\"\"\n",
        "        augmented = {}\n",
        "        \n",
        "        # Rotation\n",
        "        angle = np.random.uniform(-30, 30)\n",
        "        augmented['rotation'] = transform.rotate(image, angle, mode='wrap', preserve_range=True)\n",
        "        \n",
        "        # Scaling\n",
        "        scale = np.random.uniform(0.8, 1.2)\n",
        "        augmented['scale'] = transform.rescale(image, scale, mode='wrap', preserve_range=True, multichannel=True)\n",
        "        \n",
        "        # Translation\n",
        "        shift_x = np.random.uniform(-0.1, 0.1) * image.shape[1]\n",
        "        shift_y = np.random.uniform(-0.1, 0.1) * image.shape[0]\n",
        "        tform = transform.AffineTransform(translation=(shift_x, shift_y))\n",
        "        augmented['translation'] = transform.warp(image, tform, mode='wrap', preserve_range=True)\n",
        "        \n",
        "        # Horizontal flip\n",
        "        augmented['h_flip'] = np.fliplr(image)\n",
        "        \n",
        "        # Vertical flip\n",
        "        augmented['v_flip'] = np.flipud(image)\n",
        "        \n",
        "        # Shear\n",
        "        shear = np.random.uniform(-0.2, 0.2)\n",
        "        tform = transform.AffineTransform(shear=shear)\n",
        "        augmented['shear'] = transform.warp(image, tform, mode='wrap', preserve_range=True)\n",
        "        \n",
        "        return augmented\n",
        "    \n",
        "    def color_augmentations(self, image):\n",
        "        \"\"\"Apply color space transformations\"\"\"\n",
        "        augmented = {}\n",
        "        \n",
        "        # Brightness adjustment\n",
        "        brightness_factor = np.random.uniform(0.7, 1.3)\n",
        "        augmented['brightness'] = np.clip(image * brightness_factor, 0, 1)\n",
        "        \n",
        "        # Contrast adjustment\n",
        "        contrast_factor = np.random.uniform(0.7, 1.3)\n",
        "        mean = np.mean(image)\n",
        "        augmented['contrast'] = np.clip((image - mean) * contrast_factor + mean, 0, 1)\n",
        "        \n",
        "        # Saturation adjustment (for RGB images)\n",
        "        hsv = cv2.cvtColor((image * 255).astype(np.uint8), cv2.COLOR_RGB2HSV).astype(np.float32)\n",
        "        hsv[:, :, 1] *= np.random.uniform(0.7, 1.3)  # Saturation channel\n",
        "        hsv = np.clip(hsv, 0, 255)\n",
        "        augmented['saturation'] = cv2.cvtColor(hsv.astype(np.uint8), cv2.COLOR_HSV2RGB) / 255.0\n",
        "        \n",
        "        # Hue shift\n",
        "        hsv = cv2.cvtColor((image * 255).astype(np.uint8), cv2.COLOR_RGB2HSV).astype(np.float32)\n",
        "        hsv[:, :, 0] += np.random.uniform(-20, 20)  # Hue channel\n",
        "        hsv[:, :, 0] = np.clip(hsv[:, :, 0], 0, 179)\n",
        "        augmented['hue'] = cv2.cvtColor(hsv.astype(np.uint8), cv2.COLOR_HSV2RGB) / 255.0\n",
        "        \n",
        "        # Gamma correction\n",
        "        gamma = np.random.uniform(0.7, 1.3)\n",
        "        augmented['gamma'] = np.power(image, gamma)\n",
        "        \n",
        "        return augmented\n",
        "    \n",
        "    def noise_augmentations(self, image):\n",
        "        \"\"\"Apply noise-based augmentations\"\"\"\n",
        "        augmented = {}\n",
        "        \n",
        "        # Gaussian noise\n",
        "        noise_var = np.random.uniform(0.0, 0.05)\n",
        "        augmented['gaussian_noise'] = random_noise(image, mode='gaussian', var=noise_var, clip=True)\n",
        "        \n",
        "        # Salt and pepper noise\n",
        "        augmented['salt_pepper'] = random_noise(image, mode='s&p', amount=0.05, clip=True)\n",
        "        \n",
        "        # Speckle noise\n",
        "        augmented['speckle'] = random_noise(image, mode='speckle', var=0.05, clip=True)\n",
        "        \n",
        "        # Blur\n",
        "        sigma = np.random.uniform(0.5, 2.0)\n",
        "        augmented['blur'] = filters.gaussian(image, sigma=sigma, multichannel=True)\n",
        "        \n",
        "        return augmented\n",
        "    \n",
        "    def advanced_augmentations(self, image1, image2=None, alpha=0.5):\n",
        "        \"\"\"Apply advanced augmentation techniques\"\"\"\n",
        "        augmented = {}\n",
        "        \n",
        "        # Cutout (random erasing)\n",
        "        cutout_img = image1.copy()\n",
        "        h, w = cutout_img.shape[:2]\n",
        "        cut_h = int(h * 0.2)  # 20% of height\n",
        "        cut_w = int(w * 0.2)  # 20% of width\n",
        "        \n",
        "        # Random position\n",
        "        y = np.random.randint(0, h - cut_h)\n",
        "        x = np.random.randint(0, w - cut_w)\n",
        "        cutout_img[y:y+cut_h, x:x+cut_w] = 0  # Black cutout\n",
        "        augmented['cutout'] = cutout_img\n",
        "        \n",
        "        # Random erasing with random color\n",
        "        erase_img = image1.copy()\n",
        "        erase_color = np.random.rand(3)\n",
        "        erase_img[y:y+cut_h, x:x+cut_w] = erase_color\n",
        "        augmented['random_erase'] = erase_img\n",
        "        \n",
        "        # Mixup (if second image provided)\n",
        "        if image2 is not None:\n",
        "            augmented['mixup'] = alpha * image1 + (1 - alpha) * image2\n",
        "        \n",
        "        return augmented\n",
        "\n",
        "# Demonstrate augmentations\n",
        "augmenter = DataAugmentationSuite()\n",
        "\n",
        "# Apply augmentations to first image\n",
        "test_image = sample_images[0]\n",
        "\n",
        "# Geometric augmentations\n",
        "geo_augs = augmenter.geometric_augmentations(test_image)\n",
        "\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i, (name, aug_img) in enumerate(geo_augs.items()):\n",
        "    axes[i].imshow(aug_img)\n",
        "    axes[i].set_title(f'Geometric: {name.title()}')\n",
        "    axes[i].axis('off')\n",
        "\n",
        "plt.suptitle('Geometric Augmentations', fontsize=16)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Color augmentations\n",
        "color_augs = augmenter.color_augmentations(test_image)\n",
        "\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i, (name, aug_img) in enumerate(color_augs.items()):\n",
        "    axes[i].imshow(np.clip(aug_img, 0, 1))\n",
        "    axes[i].set_title(f'Color: {name.title()}')\n",
        "    axes[i].axis('off')\n",
        "\n",
        "plt.suptitle('Color Space Augmentations', fontsize=16)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Noise augmentations\n",
        "noise_augs = augmenter.noise_augmentations(test_image)\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(12, 12))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i, (name, aug_img) in enumerate(noise_augs.items()):\n",
        "    axes[i].imshow(np.clip(aug_img, 0, 1))\n",
        "    axes[i].set_title(f'Noise: {name.title()}')\n",
        "    axes[i].axis('off')\n",
        "\n",
        "plt.suptitle('Noise-Based Augmentations', fontsize=16)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Advanced augmentations\n",
        "advanced_augs = augmenter.advanced_augmentations(test_image, sample_images[1])\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
        "\n",
        "for i, (name, aug_img) in enumerate(advanced_augs.items()):\n",
        "    axes[i].imshow(np.clip(aug_img, 0, 1))\n",
        "    axes[i].set_title(f'Advanced: {name.title()}')\n",
        "    axes[i].axis('off')\n",
        "\n",
        "plt.suptitle('Advanced Augmentations', fontsize=16)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Augmentation demonstrations completed!\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Key Insights and Practical Applications\n",
        "\n",
        "### Augmentation Strategy Selection:\n",
        "\n",
        "1. **Task-Specific Considerations**:\n",
        "   - **Medical Images**: Avoid unrealistic transformations (e.g., vertical flips)\n",
        "   - **Natural Images**: Most geometric and color augmentations are suitable\n",
        "   - **Text/OCR**: Focus on rotation, scaling, noise rather than color changes\n",
        "   - **Object Detection**: Ensure bounding boxes are updated with transformations\n",
        "\n",
        "2. **Augmentation Intensity**:\n",
        "   - **Light Augmentation**: Preserve original data distribution\n",
        "   - **Heavy Augmentation**: Risk of creating unrealistic samples\n",
        "   - **Balanced Approach**: Moderate transformations with validation monitoring\n",
        "\n",
        "3. **Performance Trade-offs**:\n",
        "   - **Training Time**: More augmentations = longer training\n",
        "   - **Memory Usage**: Real-time vs pre-computed augmentations\n",
        "   - **Quality vs Quantity**: Better to have fewer, high-quality augmentations\n",
        "\n",
        "### Implementation Best Practices:\n",
        "- Always validate augmentations visually before training\n",
        "- Use appropriate augmentation pipelines for your domain\n",
        "- Monitor validation performance to avoid over-augmentation\n",
        "- Consider computational constraints in production environments\n",
        "- Combine multiple techniques for maximum benefit\n",
        "\n",
        "### Tomorrow's Focus:\n",
        "We'll explore model evaluation metrics specifically designed for image classification tasks!\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
