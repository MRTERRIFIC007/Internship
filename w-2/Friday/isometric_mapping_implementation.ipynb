{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Isometric Mapping (Isomap) Implementation\n",
        "\n",
        "## Learning Objectives\n",
        "- Understand Isomap's theoretical foundations in manifold learning\n",
        "- Implement Isomap algorithm from scratch using graph theory\n",
        "- Compare Isomap with other manifold learning techniques\n",
        "- Apply Isomap to various datasets and analyze geodesic distance preservation\n",
        "- Explore parameter effects: k-neighbors, distance metrics\n",
        "- Evaluate manifold learning quality using trustworthiness metrics\n",
        "\n",
        "## Isomap Theory Overview\n",
        "\n",
        "### Geodesic Distance Preservation\n",
        "**Isomap** (Isometric Mapping) seeks to preserve **geodesic distances** on the manifold:\n",
        "\n",
        "1. **Assumption**: Data lies on a smooth, non-linear manifold\n",
        "2. **Geodesic Distance**: Shortest path along the manifold surface\n",
        "3. **Graph Approximation**: Use k-nearest neighbor graph to approximate manifold\n",
        "4. **Shortest Path**: Apply Dijkstra's or Floyd-Warshall algorithm\n",
        "5. **MDS Embedding**: Use classical multidimensional scaling on geodesic distances\n",
        "\n",
        "### Key Advantages\n",
        "- **Global Structure**: Preserves global geometric relationships\n",
        "- **Non-linear Manifolds**: Handles complex curved surfaces\n",
        "- **Theoretical Foundation**: Based on Riemannian geometry\n",
        "- **Interpretable**: Geodesic distances have clear geometric meaning\n",
        "\n",
        "### Algorithm Steps\n",
        "1. **Construct neighborhood graph** using k-NN or Îµ-ball\n",
        "2. **Compute shortest paths** between all point pairs\n",
        "3. **Apply classical MDS** to geodesic distance matrix\n",
        "4. **Return low-dimensional embedding** preserving geodesic structure\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_swiss_roll, make_s_curve, load_digits\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.metrics import euclidean_distances\n",
        "from sklearn.manifold import Isomap, TSNE, MDS\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import trustworthiness\n",
        "from scipy.sparse import csr_matrix\n",
        "from scipy.sparse.csgraph import shortest_path\n",
        "import networkx as nx\n",
        "import time\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set style and random seed\n",
        "plt.style.use('seaborn-v0_8')\n",
        "np.random.seed(42)\n",
        "\n",
        "print(\"Libraries imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Custom Isomap implementation\n",
        "class CustomIsomap:\n",
        "    \"\"\"Custom implementation of Isomap for educational purposes\"\"\"\n",
        "    \n",
        "    def __init__(self, n_neighbors=5, n_components=2, metric='euclidean'):\n",
        "        self.n_neighbors = n_neighbors\n",
        "        self.n_components = n_components\n",
        "        self.metric = metric\n",
        "        \n",
        "        # Results storage\n",
        "        self.geodesic_distances_ = None\n",
        "        self.embedding_ = None\n",
        "        self.eigenvalues_ = None\n",
        "        self.neighborhood_graph_ = None\n",
        "        \n",
        "    def _build_neighborhood_graph(self, X):\n",
        "        \"\"\"Build k-nearest neighbor graph\"\"\"\n",
        "        print(f\"Building {self.n_neighbors}-NN graph...\")\n",
        "        \n",
        "        # Find k-nearest neighbors\n",
        "        nbrs = NearestNeighbors(n_neighbors=self.n_neighbors + 1, metric=self.metric)\n",
        "        nbrs.fit(X)\n",
        "        distances, indices = nbrs.kneighbors(X)\n",
        "        \n",
        "        # Remove self-distances\n",
        "        distances = distances[:, 1:]\n",
        "        indices = indices[:, 1:]\n",
        "        \n",
        "        # Build sparse adjacency matrix\n",
        "        n_samples = X.shape[0]\n",
        "        row_ind = np.repeat(np.arange(n_samples), self.n_neighbors)\n",
        "        col_ind = indices.flatten()\n",
        "        data = distances.flatten()\n",
        "        \n",
        "        # Create symmetric graph\n",
        "        adjacency = csr_matrix((data, (row_ind, col_ind)), shape=(n_samples, n_samples))\n",
        "        adjacency = adjacency + adjacency.T\n",
        "        adjacency.data = adjacency.data / 2  # Average overlapping edges\n",
        "        \n",
        "        self.neighborhood_graph_ = adjacency\n",
        "        return adjacency\n",
        "    \n",
        "    def _compute_geodesic_distances(self, adjacency):\n",
        "        \"\"\"Compute geodesic distances using shortest path algorithm\"\"\"\n",
        "        print(\"Computing geodesic distances...\")\n",
        "        \n",
        "        # Use scipy's shortest path algorithm (Dijkstra's for sparse graphs)\n",
        "        geodesic_dist = shortest_path(adjacency, directed=False, method='auto')\n",
        "        \n",
        "        # Check for disconnected components\n",
        "        if np.isinf(geodesic_dist).any():\n",
        "            print(\"Warning: Graph has disconnected components!\")\n",
        "            print(f\"Number of infinite distances: {np.isinf(geodesic_dist).sum()}\")\n",
        "            \n",
        "            # Replace infinite distances with large finite values\n",
        "            max_finite = np.max(geodesic_dist[np.isfinite(geodesic_dist)])\n",
        "            geodesic_dist[np.isinf(geodesic_dist)] = max_finite * 10\n",
        "        \n",
        "        self.geodesic_distances_ = geodesic_dist\n",
        "        return geodesic_dist\n",
        "    \n",
        "    def _classical_mds(self, distance_matrix):\n",
        "        \"\"\"Apply classical multidimensional scaling\"\"\"\n",
        "        print(\"Applying classical MDS...\")\n",
        "        \n",
        "        n = distance_matrix.shape[0]\n",
        "        \n",
        "        # Double centering: H = I - (1/n) * 1 * 1^T\n",
        "        H = np.eye(n) - np.ones((n, n)) / n\n",
        "        \n",
        "        # Gram matrix: G = -0.5 * H * D^2 * H\n",
        "        D_squared = distance_matrix ** 2\n",
        "        G = -0.5 * H @ D_squared @ H\n",
        "        \n",
        "        # Eigendecomposition\n",
        "        eigenvalues, eigenvectors = np.linalg.eigh(G)\n",
        "        \n",
        "        # Sort eigenvalues and eigenvectors in descending order\n",
        "        idx = np.argsort(eigenvalues)[::-1]\n",
        "        eigenvalues = eigenvalues[idx]\n",
        "        eigenvectors = eigenvectors[:, idx]\n",
        "        \n",
        "        # Take first n_components\n",
        "        eigenvalues = eigenvalues[:self.n_components]\n",
        "        eigenvectors = eigenvectors[:, :self.n_components]\n",
        "        \n",
        "        # Handle negative eigenvalues\n",
        "        eigenvalues = np.maximum(eigenvalues, 0)\n",
        "        \n",
        "        # Compute embedding\n",
        "        embedding = eigenvectors @ np.diag(np.sqrt(eigenvalues))\n",
        "        \n",
        "        self.eigenvalues_ = eigenvalues\n",
        "        return embedding\n",
        "    \n",
        "    def fit_transform(self, X):\n",
        "        \"\"\"Fit Isomap and return embedding\"\"\"\n",
        "        print(f\"Fitting Custom Isomap on {X.shape[0]} samples...\")\n",
        "        \n",
        "        # Step 1: Build neighborhood graph\n",
        "        adjacency = self._build_neighborhood_graph(X)\n",
        "        \n",
        "        # Step 2: Compute geodesic distances\n",
        "        geodesic_distances = self._compute_geodesic_distances(adjacency)\n",
        "        \n",
        "        # Step 3: Apply classical MDS\n",
        "        embedding = self._classical_mds(geodesic_distances)\n",
        "        \n",
        "        self.embedding_ = embedding\n",
        "        print(\"Custom Isomap fitting completed!\")\n",
        "        \n",
        "        return embedding\n",
        "    \n",
        "    def get_graph_statistics(self):\n",
        "        \"\"\"Get statistics about the neighborhood graph\"\"\"\n",
        "        if self.neighborhood_graph_ is None:\n",
        "            return None\n",
        "        \n",
        "        graph = self.neighborhood_graph_\n",
        "        n_edges = graph.nnz // 2  # Divide by 2 for undirected graph\n",
        "        n_nodes = graph.shape[0]\n",
        "        \n",
        "        # Convert to NetworkX for more statistics\n",
        "        G = nx.from_scipy_sparse_matrix(graph)\n",
        "        \n",
        "        stats = {\n",
        "            'n_nodes': n_nodes,\n",
        "            'n_edges': n_edges,\n",
        "            'density': n_edges / (n_nodes * (n_nodes - 1) / 2),\n",
        "            'is_connected': nx.is_connected(G),\n",
        "            'n_components': nx.number_connected_components(G),\n",
        "            'avg_clustering': nx.average_clustering(G),\n",
        "            'avg_path_length': nx.average_shortest_path_length(G) if nx.is_connected(G) else float('inf')\n",
        "        }\n",
        "        \n",
        "        return stats\n",
        "\n",
        "# Test custom Isomap implementation\n",
        "def test_custom_isomap():\n",
        "    \"\"\"Test custom Isomap on Swiss Roll dataset\"\"\"\n",
        "    \n",
        "    # Generate Swiss Roll data\n",
        "    X, color = make_swiss_roll(n_samples=1000, noise=0.1, random_state=42)\n",
        "    \n",
        "    # Standardize data\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "    \n",
        "    print(\"=== Testing Custom Isomap ===\")\n",
        "    print(f\"Dataset shape: {X_scaled.shape}\")\n",
        "    \n",
        "    # Apply custom Isomap\n",
        "    custom_isomap = CustomIsomap(n_neighbors=10, n_components=2)\n",
        "    Y_custom = custom_isomap.fit_transform(X_scaled)\n",
        "    \n",
        "    # Get graph statistics\n",
        "    graph_stats = custom_isomap.get_graph_statistics()\n",
        "    print(\"\\\\nGraph Statistics:\")\n",
        "    for key, value in graph_stats.items():\n",
        "        print(f\"  {key}: {value}\")\n",
        "    \n",
        "    # Compare with sklearn's Isomap\n",
        "    print(\"\\\\nComparing with sklearn Isomap...\")\n",
        "    sklearn_isomap = Isomap(n_neighbors=10, n_components=2)\n",
        "    Y_sklearn = sklearn_isomap.fit_transform(X_scaled)\n",
        "    \n",
        "    # Calculate trustworthiness\n",
        "    trust_custom = trustworthiness(X_scaled, Y_custom, n_neighbors=10)\n",
        "    trust_sklearn = trustworthiness(X_scaled, Y_sklearn, n_neighbors=10)\n",
        "    \n",
        "    print(f\"\\\\nTrustworthiness Comparison:\")\n",
        "    print(f\"Custom Isomap: {trust_custom:.4f}\")\n",
        "    print(f\"Sklearn Isomap: {trust_sklearn:.4f}\")\n",
        "    \n",
        "    # Visualization\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "    \n",
        "    # Original data (3D projected to first 2 dims)\n",
        "    axes[0].scatter(X_scaled[:, 0], X_scaled[:, 1], c=color, cmap='viridis', alpha=0.6)\n",
        "    axes[0].set_title('Original Swiss Roll\\\\n(First 2 Dimensions)')\n",
        "    axes[0].set_xlabel('Dimension 1')\n",
        "    axes[0].set_ylabel('Dimension 2')\n",
        "    \n",
        "    # Custom Isomap\n",
        "    axes[1].scatter(Y_custom[:, 0], Y_custom[:, 1], c=color, cmap='viridis', alpha=0.6)\n",
        "    axes[1].set_title(f'Custom Isomap\\\\nTrustworthiness: {trust_custom:.3f}')\n",
        "    axes[1].set_xlabel('Isomap 1')\n",
        "    axes[1].set_ylabel('Isomap 2')\n",
        "    \n",
        "    # Sklearn Isomap\n",
        "    axes[2].scatter(Y_sklearn[:, 0], Y_sklearn[:, 1], c=color, cmap='viridis', alpha=0.6)\n",
        "    axes[2].set_title(f'Sklearn Isomap\\\\nTrustworthiness: {trust_sklearn:.3f}')\n",
        "    axes[2].set_xlabel('Isomap 1')\n",
        "    axes[2].set_ylabel('Isomap 2')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    return custom_isomap, Y_custom, Y_sklearn\n",
        "\n",
        "# Run the test\n",
        "custom_isomap_model, custom_embedding, sklearn_embedding = test_custom_isomap()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Comprehensive manifold learning comparison\n",
        "def comprehensive_manifold_comparison():\n",
        "    \"\"\"Compare multiple manifold learning methods\"\"\"\n",
        "    \n",
        "    # Create diverse datasets\n",
        "    datasets = {}\n",
        "    \n",
        "    # 1. Swiss Roll\n",
        "    X_swiss, color_swiss = make_swiss_roll(n_samples=800, noise=0.1, random_state=42)\n",
        "    scaler = StandardScaler()\n",
        "    datasets['Swiss Roll'] = (scaler.fit_transform(X_swiss), color_swiss)\n",
        "    \n",
        "    # 2. S-Curve\n",
        "    X_s, color_s = make_s_curve(n_samples=800, noise=0.1, random_state=42)\n",
        "    scaler = StandardScaler()\n",
        "    datasets['S-Curve'] = (scaler.fit_transform(X_s), color_s)\n",
        "    \n",
        "    # 3. Digits dataset (high-dimensional)\n",
        "    digits = load_digits()\n",
        "    X_digits = digits.data[:400]  # Subset for speed\n",
        "    y_digits = digits.target[:400]\n",
        "    scaler = StandardScaler()\n",
        "    datasets['Digits'] = (scaler.fit_transform(X_digits), y_digits)\n",
        "    \n",
        "    # 4. 3D Spiral\n",
        "    t = np.linspace(0, 4*np.pi, 600)\n",
        "    X_spiral = np.column_stack([\n",
        "        t * np.cos(t) * 0.1,\n",
        "        t * np.sin(t) * 0.1,\n",
        "        t * 0.1\n",
        "    ])\n",
        "    noise = np.random.normal(0, 0.02, X_spiral.shape)\n",
        "    X_spiral += noise\n",
        "    scaler = StandardScaler()\n",
        "    datasets['3D Spiral'] = (scaler.fit_transform(X_spiral), t)\n",
        "    \n",
        "    # Manifold learning methods\n",
        "    methods = {\n",
        "        'Isomap': lambda X: Isomap(n_neighbors=10, n_components=2).fit_transform(X),\n",
        "        'PCA': lambda X: PCA(n_components=2).fit_transform(X),\n",
        "        't-SNE': lambda X: TSNE(n_components=2, random_state=42, perplexity=30).fit_transform(X),\n",
        "        'MDS': lambda X: MDS(n_components=2, random_state=42).fit_transform(X)\n",
        "    }\n",
        "    \n",
        "    # Results storage\n",
        "    results = {}\n",
        "    \n",
        "    for dataset_name, (X, y) in datasets.items():\n",
        "        print(f\"\\\\n=== Processing {dataset_name} Dataset ===\")\n",
        "        print(f\"Shape: {X.shape}\")\n",
        "        \n",
        "        dataset_results = {}\n",
        "        \n",
        "        for method_name, method_func in methods.items():\n",
        "            print(f\"  Applying {method_name}...\")\n",
        "            \n",
        "            start_time = time.time()\n",
        "            try:\n",
        "                Y = method_func(X)\n",
        "                elapsed_time = time.time() - start_time\n",
        "                \n",
        "                # Calculate trustworthiness\n",
        "                trust = trustworthiness(X, Y, n_neighbors=min(10, X.shape[0]//10))\n",
        "                \n",
        "                dataset_results[method_name] = {\n",
        "                    'embedding': Y,\n",
        "                    'trustworthiness': trust,\n",
        "                    'time': elapsed_time\n",
        "                }\n",
        "                \n",
        "                print(f\"    {method_name}: Trust={trust:.3f}, Time={elapsed_time:.2f}s\")\n",
        "                \n",
        "            except Exception as e:\n",
        "                print(f\"    {method_name}: Failed - {str(e)}\")\n",
        "                dataset_results[method_name] = None\n",
        "        \n",
        "        results[dataset_name] = dataset_results\n",
        "    \n",
        "    # Visualization\n",
        "    n_datasets = len(datasets)\n",
        "    n_methods = len(methods)\n",
        "    \n",
        "    fig, axes = plt.subplots(n_datasets, n_methods + 1, figsize=(6*(n_methods+1), 5*n_datasets))\n",
        "    if n_datasets == 1:\n",
        "        axes = axes.reshape(1, -1)\n",
        "    \n",
        "    for dataset_idx, (dataset_name, (X, y)) in enumerate(datasets.items()):\n",
        "        \n",
        "        # Plot original data (first 2 dimensions if >2D)\n",
        "        if X.shape[1] >= 2:\n",
        "            axes[dataset_idx, 0].scatter(X[:, 0], X[:, 1], c=y, cmap='viridis', alpha=0.6, s=20)\n",
        "        else:\n",
        "            axes[dataset_idx, 0].scatter(X[:, 0], np.zeros_like(X[:, 0]), c=y, cmap='viridis', alpha=0.6, s=20)\n",
        "        \n",
        "        axes[dataset_idx, 0].set_title(f'{dataset_name}\\\\nOriginal (2D projection)')\n",
        "        axes[dataset_idx, 0].set_xlabel('Dim 1')\n",
        "        axes[dataset_idx, 0].set_ylabel('Dim 2')\n",
        "        \n",
        "        # Plot each method's result\n",
        "        for method_idx, method_name in enumerate(methods.keys()):\n",
        "            col_idx = method_idx + 1\n",
        "            \n",
        "            if results[dataset_name][method_name] is not None:\n",
        "                Y = results[dataset_name][method_name]['embedding']\n",
        "                trust = results[dataset_name][method_name]['trustworthiness']\n",
        "                time_taken = results[dataset_name][method_name]['time']\n",
        "                \n",
        "                scatter = axes[dataset_idx, col_idx].scatter(Y[:, 0], Y[:, 1], c=y, \n",
        "                                                           cmap='viridis', alpha=0.6, s=20)\n",
        "                axes[dataset_idx, col_idx].set_title(f'{method_name}\\\\nTrust: {trust:.3f}, Time: {time_taken:.2f}s')\n",
        "            else:\n",
        "                axes[dataset_idx, col_idx].text(0.5, 0.5, 'Failed', \n",
        "                                              transform=axes[dataset_idx, col_idx].transAxes,\n",
        "                                              ha='center', va='center', fontsize=16)\n",
        "                axes[dataset_idx, col_idx].set_title(f'{method_name}\\\\n(Failed)')\n",
        "            \n",
        "            axes[dataset_idx, col_idx].set_xlabel('Component 1')\n",
        "            axes[dataset_idx, col_idx].set_ylabel('Component 2')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Summary comparison table\n",
        "    print(\"\\\\n=== Method Comparison Summary ===\")\n",
        "    \n",
        "    summary_data = []\n",
        "    for dataset_name, dataset_results in results.items():\n",
        "        for method_name, method_result in dataset_results.items():\n",
        "            if method_result is not None:\n",
        "                summary_data.append({\n",
        "                    'Dataset': dataset_name,\n",
        "                    'Method': method_name,\n",
        "                    'Trustworthiness': f\"{method_result['trustworthiness']:.3f}\",\n",
        "                    'Time (s)': f\"{method_result['time']:.2f}\"\n",
        "                })\n",
        "    \n",
        "    summary_df = pd.DataFrame(summary_data)\n",
        "    print(summary_df.to_string(index=False))\n",
        "    \n",
        "    # Best method per dataset\n",
        "    print(\"\\\\n=== Best Method per Dataset (by Trustworthiness) ===\")\n",
        "    for dataset_name, dataset_results in results.items():\n",
        "        valid_results = {k: v for k, v in dataset_results.items() if v is not None}\n",
        "        if valid_results:\n",
        "            best_method = max(valid_results.items(), key=lambda x: x[1]['trustworthiness'])\n",
        "            print(f\"{dataset_name}: {best_method[0]} (Trust: {best_method[1]['trustworthiness']:.3f})\")\n",
        "    \n",
        "    return results, summary_df\n",
        "\n",
        "# Run comprehensive comparison\n",
        "print(\"=== Comprehensive Manifold Learning Comparison ===\")\n",
        "comparison_results, comparison_summary = comprehensive_manifold_comparison()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Parameter analysis for Isomap\n",
        "def isomap_parameter_analysis():\n",
        "    \"\"\"Analyze the effect of different Isomap parameters\"\"\"\n",
        "    \n",
        "    # Use Swiss Roll for parameter analysis\n",
        "    X, color = make_swiss_roll(n_samples=600, noise=0.1, random_state=42)\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "    \n",
        "    print(\"=== Isomap Parameter Analysis ===\")\n",
        "    print(f\"Dataset shape: {X_scaled.shape}\")\n",
        "    \n",
        "    # Test different numbers of neighbors\n",
        "    neighbor_values = [5, 10, 15, 20, 30, 50]\n",
        "    neighbor_results = {}\n",
        "    \n",
        "    print(\"\\\\n1. Testing different k-neighbors values:\")\n",
        "    for k in neighbor_values:\n",
        "        print(f\"  k = {k}\")\n",
        "        \n",
        "        try:\n",
        "            isomap = Isomap(n_neighbors=k, n_components=2)\n",
        "            Y = isomap.fit_transform(X_scaled)\n",
        "            trust = trustworthiness(X_scaled, Y, n_neighbors=10)\n",
        "            \n",
        "            neighbor_results[k] = {\n",
        "                'embedding': Y,\n",
        "                'trustworthiness': trust,\n",
        "                'eigenvalues': isomap.kernel_pca_.eigenvalues_ if hasattr(isomap, 'kernel_pca_') else None\n",
        "            }\n",
        "            print(f\"    Trustworthiness: {trust:.4f}\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"    Failed: {str(e)}\")\n",
        "            neighbor_results[k] = None\n",
        "    \n",
        "    # Visualize neighbor parameter effects\n",
        "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "    axes = axes.flatten()\n",
        "    \n",
        "    for i, k in enumerate(neighbor_values):\n",
        "        if neighbor_results[k] is not None:\n",
        "            Y = neighbor_results[k]['embedding']\n",
        "            trust = neighbor_results[k]['trustworthiness']\n",
        "            \n",
        "            axes[i].scatter(Y[:, 0], Y[:, 1], c=color, cmap='viridis', alpha=0.6, s=15)\n",
        "            axes[i].set_title(f'k = {k}\\\\nTrustworthiness: {trust:.3f}')\n",
        "            axes[i].set_xlabel('Isomap 1')\n",
        "            axes[i].set_ylabel('Isomap 2')\n",
        "        else:\n",
        "            axes[i].text(0.5, 0.5, f'k={k}\\\\nFailed', transform=axes[i].transAxes,\n",
        "                        ha='center', va='center', fontsize=16)\n",
        "    \n",
        "    plt.suptitle('Effect of k-neighbors Parameter on Isomap', fontsize=16)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Plot trustworthiness vs k\n",
        "    valid_k = [k for k in neighbor_values if neighbor_results[k] is not None]\n",
        "    valid_trust = [neighbor_results[k]['trustworthiness'] for k in valid_k]\n",
        "    \n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(valid_k, valid_trust, 'o-', linewidth=2, markersize=8)\n",
        "    plt.xlabel('Number of Neighbors (k)')\n",
        "    plt.ylabel('Trustworthiness')\n",
        "    plt.title('Trustworthiness vs k-neighbors Parameter')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    \n",
        "    # Add value labels\n",
        "    for k, trust in zip(valid_k, valid_trust):\n",
        "        plt.annotate(f'{trust:.3f}', (k, trust), xytext=(5, 5), \n",
        "                    textcoords='offset points', fontsize=9)\n",
        "    \n",
        "    plt.show()\n",
        "    \n",
        "    # Analyze connectivity\n",
        "    print(\"\\\\n2. Graph Connectivity Analysis:\")\n",
        "    for k in neighbor_values:\n",
        "        if neighbor_results[k] is not None:\n",
        "            # Check connectivity by trying to build the graph\n",
        "            try:\n",
        "                nbrs = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "                nbrs.fit(X_scaled)\n",
        "                distances, indices = nbrs.kneighbors(X_scaled)\n",
        "                \n",
        "                # Build graph and check connectivity\n",
        "                n_samples = X_scaled.shape[0]\n",
        "                row_ind = np.repeat(np.arange(n_samples), k)\n",
        "                col_ind = indices[:, :k].flatten()\n",
        "                data = distances[:, :k].flatten()\n",
        "                \n",
        "                adjacency = csr_matrix((data, (row_ind, col_ind)), shape=(n_samples, n_samples))\n",
        "                adjacency = adjacency + adjacency.T\n",
        "                \n",
        "                # Convert to NetworkX and check connectivity\n",
        "                G = nx.from_scipy_sparse_matrix(adjacency)\n",
        "                is_connected = nx.is_connected(G)\n",
        "                n_components = nx.number_connected_components(G)\n",
        "                \n",
        "                print(f\"  k={k}: Connected={is_connected}, Components={n_components}\")\n",
        "                \n",
        "            except Exception as e:\n",
        "                print(f\"  k={k}: Error in connectivity analysis - {str(e)}\")\n",
        "    \n",
        "    # Distance metric comparison\n",
        "    print(\"\\\\n3. Distance Metric Comparison:\")\n",
        "    metrics = ['euclidean', 'manhattan', 'chebyshev']\n",
        "    metric_results = {}\n",
        "    \n",
        "    for metric in metrics:\n",
        "        print(f\"  Testing {metric} metric...\")\n",
        "        try:\n",
        "            isomap = Isomap(n_neighbors=15, n_components=2, metric=metric)\n",
        "            Y = isomap.fit_transform(X_scaled)\n",
        "            trust = trustworthiness(X_scaled, Y, n_neighbors=10)\n",
        "            \n",
        "            metric_results[metric] = {\n",
        "                'embedding': Y,\n",
        "                'trustworthiness': trust\n",
        "            }\n",
        "            print(f\"    Trustworthiness: {trust:.4f}\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"    Failed: {str(e)}\")\n",
        "            metric_results[metric] = None\n",
        "    \n",
        "    # Visualize metric comparison\n",
        "    fig, axes = plt.subplots(1, len(metrics), figsize=(6*len(metrics), 5))\n",
        "    if len(metrics) == 1:\n",
        "        axes = [axes]\n",
        "    \n",
        "    for i, metric in enumerate(metrics):\n",
        "        if metric_results[metric] is not None:\n",
        "            Y = metric_results[metric]['embedding']\n",
        "            trust = metric_results[metric]['trustworthiness']\n",
        "            \n",
        "            axes[i].scatter(Y[:, 0], Y[:, 1], c=color, cmap='viridis', alpha=0.6)\n",
        "            axes[i].set_title(f'{metric.title()} Metric\\\\nTrust: {trust:.3f}')\n",
        "            axes[i].set_xlabel('Isomap 1')\n",
        "            axes[i].set_ylabel('Isomap 2')\n",
        "        else:\n",
        "            axes[i].text(0.5, 0.5, f'{metric}\\\\nFailed', transform=axes[i].transAxes,\n",
        "                        ha='center', va='center', fontsize=16)\n",
        "    \n",
        "    plt.suptitle('Effect of Distance Metric on Isomap', fontsize=16)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Summary of parameter effects\n",
        "    print(\"\\\\n=== Parameter Analysis Summary ===\")\n",
        "    print(\"\\\\nOptimal k-neighbors recommendations:\")\n",
        "    print(\"- Too small (k<10): May create disconnected components\")\n",
        "    print(\"- Too large (k>30): May lose local structure, approach PCA\")\n",
        "    print(\"- Sweet spot: k=10-20 for most datasets\")\n",
        "    \n",
        "    print(\"\\\\nDistance metric insights:\")\n",
        "    for metric in metrics:\n",
        "        if metric_results[metric] is not None:\n",
        "            trust = metric_results[metric]['trustworthiness']\n",
        "            print(f\"- {metric.title()}: {trust:.4f}\")\n",
        "    \n",
        "    return neighbor_results, metric_results\n",
        "\n",
        "# Run parameter analysis\n",
        "parameter_analysis_results = isomap_parameter_analysis()\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Key Insights and Learning Reflections\n",
        "\n",
        "### Isomap Understanding:\n",
        "\n",
        "1. **Geodesic Distance Preservation**:\n",
        "   - **Core Innovation**: Uses shortest paths on k-NN graph to approximate geodesic distances\n",
        "   - **Global Structure**: Better than local methods at preserving overall manifold geometry\n",
        "   - **Graph Connectivity**: Critical requirement - disconnected graphs lead to poor embeddings\n",
        "   - **MDS Foundation**: Classical multidimensional scaling on geodesic distance matrix\n",
        "\n",
        "2. **Parameter Selection Impact**:\n",
        "   - **k-neighbors**: \n",
        "     - Too small (k<5): Risk of disconnected components\n",
        "     - Too large (k>50): Approaches PCA behavior, loses non-linear structure\n",
        "     - Optimal range: k=10-20 for most datasets\n",
        "   - **Distance Metrics**: Euclidean typically best, but Manhattan/Chebyshev can help with high-dimensional noise\n",
        "\n",
        "3. **Computational Considerations**:\n",
        "   - **Time Complexity**: O(NÂ³) due to shortest path computation\n",
        "   - **Memory Usage**: Stores full NÃN distance matrix\n",
        "   - **Scalability**: Limited to moderate-sized datasets (< 10,000 samples)\n",
        "\n",
        "### Comparison with Other Methods:\n",
        "\n",
        "1. **vs PCA**: Captures non-linear structure but computationally more expensive\n",
        "2. **vs t-SNE**: Better global structure preservation, but may miss fine local details\n",
        "3. **vs UMAP**: Similar global preservation, but UMAP is much faster and more scalable\n",
        "\n",
        "### Practical Applications:\n",
        "\n",
        "1. **Dimensionality Reduction**: Excellent for visualization of high-dimensional data\n",
        "2. **Feature Engineering**: Can create meaningful low-dimensional representations\n",
        "3. **Clustering Preprocessing**: Often improves clustering results on manifold data\n",
        "4. **Scientific Visualization**: Preserves important geometric relationships\n",
        "\n",
        "### Key Takeaways:\n",
        "- Isomap excels when global geometric relationships are important\n",
        "- Graph connectivity is crucial - always check for disconnected components\n",
        "- Parameter tuning (especially k-neighbors) significantly affects results\n",
        "- Consider computational constraints when choosing between manifold methods\n",
        "- Best suited for datasets with clear underlying manifold structure\n",
        "\n",
        "### Next Steps:\n",
        "Moving on to word embeddings - applying similar geometric principles to text data!\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
