{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Statistics Fundamentals for Machine Learning\n",
        "\n",
        "In this notebook, we'll explore key statistical concepts that form the foundation of machine learning algorithms and analysis techniques.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "\n",
        "# Set plot style\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "sns.set_palette(\"viridis\")\n",
        "\n",
        "# For reproducibility\n",
        "np.random.seed(42)\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 1. Descriptive Statistics\n",
        "\n",
        "Descriptive statistics help us understand and summarize our data. These metrics are essential for initial data exploration and feature engineering.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate sample data\n",
        "data = np.random.normal(loc=50, scale=15, size=1000)\n",
        "\n",
        "# Calculate basic statistics\n",
        "mean_val = np.mean(data)\n",
        "median_val = np.median(data)\n",
        "std_val = np.std(data)\n",
        "var_val = np.var(data)\n",
        "min_val = np.min(data)\n",
        "max_val = np.max(data)\n",
        "q1 = np.percentile(data, 25)\n",
        "q3 = np.percentile(data, 75)\n",
        "iqr = q3 - q1\n",
        "\n",
        "# Display results\n",
        "print(f\"Mean: {mean_val:.2f}\")\n",
        "print(f\"Median: {median_val:.2f}\")\n",
        "print(f\"Standard Deviation: {std_val:.2f}\")\n",
        "print(f\"Variance: {var_val:.2f}\")\n",
        "print(f\"Min: {min_val:.2f}\")\n",
        "print(f\"Max: {max_val:.2f}\")\n",
        "print(f\"Q1 (25th percentile): {q1:.2f}\")\n",
        "print(f\"Q3 (75th percentile): {q3:.2f}\")\n",
        "print(f\"IQR: {iqr:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize the distribution\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Histogram with KDE\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.histplot(data, kde=True, color='blue')\n",
        "plt.axvline(mean_val, color='red', linestyle='--', label=f'Mean: {mean_val:.2f}')\n",
        "plt.axvline(median_val, color='green', linestyle='-.', label=f'Median: {median_val:.2f}')\n",
        "plt.title('Distribution of Data')\n",
        "plt.xlabel('Value')\n",
        "plt.ylabel('Frequency')\n",
        "plt.legend()\n",
        "\n",
        "# Box plot\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.boxplot(y=data)\n",
        "plt.title('Box Plot')\n",
        "plt.ylabel('Value')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 2. Probability Distributions\n",
        "\n",
        "Understanding probability distributions is crucial for many ML algorithms, especially for modeling uncertainty and making predictions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate data from different distributions\n",
        "x = np.linspace(-5, 5, 1000)\n",
        "\n",
        "# Normal/Gaussian distribution\n",
        "normal_dist = stats.norm.pdf(x, loc=0, scale=1)\n",
        "\n",
        "# Student's t-distribution\n",
        "t_dist = stats.t.pdf(x, df=5)\n",
        "\n",
        "# Uniform distribution\n",
        "uniform_x = np.linspace(-3, 3, 1000)\n",
        "uniform_dist = stats.uniform.pdf(uniform_x, loc=-2, scale=4)\n",
        "\n",
        "# Exponential distribution\n",
        "exp_x = np.linspace(0, 5, 1000)\n",
        "exp_dist = stats.expon.pdf(exp_x, scale=1)\n",
        "\n",
        "# Plot distributions\n",
        "plt.figure(figsize=(14, 10))\n",
        "\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.plot(x, normal_dist, 'b-', lw=2)\n",
        "plt.title('Normal Distribution')\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('Probability Density')\n",
        "\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.plot(x, t_dist, 'r-', lw=2)\n",
        "plt.title(\"Student's t-Distribution (df=5)\")\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('Probability Density')\n",
        "\n",
        "plt.subplot(2, 2, 3)\n",
        "plt.plot(uniform_x, uniform_dist, 'g-', lw=2)\n",
        "plt.title('Uniform Distribution')\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('Probability Density')\n",
        "\n",
        "plt.subplot(2, 2, 4)\n",
        "plt.plot(exp_x, exp_dist, 'y-', lw=2)\n",
        "plt.title('Exponential Distribution')\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('Probability Density')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 3. Inferential Statistics\n",
        "\n",
        "Inferential statistics allows us to make predictions or inferences from data, which is the core of machine learning.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate two samples\n",
        "group_a = np.random.normal(loc=50, scale=10, size=100)\n",
        "group_b = np.random.normal(loc=55, scale=10, size=100)\n",
        "\n",
        "# Perform t-test\n",
        "t_stat, p_value = stats.ttest_ind(group_a, group_b)\n",
        "\n",
        "print(f\"T-statistic: {t_stat:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "print(f\"Statistically significant difference (α=0.05): {p_value < 0.05}\")\n",
        "\n",
        "# Visualize the two distributions\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(group_a, color='blue', label='Group A', kde=True, alpha=0.6)\n",
        "sns.histplot(group_b, color='red', label='Group B', kde=True, alpha=0.6)\n",
        "plt.axvline(np.mean(group_a), color='blue', linestyle='--', label=f'Mean A: {np.mean(group_a):.2f}')\n",
        "plt.axvline(np.mean(group_b), color='red', linestyle='--', label=f'Mean B: {np.mean(group_b):.2f}')\n",
        "plt.title('Comparison of Two Groups')\n",
        "plt.xlabel('Value')\n",
        "plt.ylabel('Frequency')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 4. Correlation and Covariance\n",
        "\n",
        "Understanding relationships between variables is crucial for feature selection and engineering in ML.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate correlated data\n",
        "n = 200\n",
        "x = np.random.normal(0, 1, n)\n",
        "\n",
        "# Different levels of correlation\n",
        "y_strong_pos = x * 0.9 + np.random.normal(0, 0.3, n)  # Strong positive\n",
        "y_weak_pos = x * 0.3 + np.random.normal(0, 0.9, n)    # Weak positive\n",
        "y_strong_neg = -x * 0.9 + np.random.normal(0, 0.3, n) # Strong negative\n",
        "y_no_corr = np.random.normal(0, 1, n)                # No correlation\n",
        "\n",
        "# Calculate correlations and covariances\n",
        "corr_strong_pos = np.corrcoef(x, y_strong_pos)[0, 1]\n",
        "cov_strong_pos = np.cov(x, y_strong_pos)[0, 1]\n",
        "\n",
        "corr_weak_pos = np.corrcoef(x, y_weak_pos)[0, 1]\n",
        "cov_weak_pos = np.cov(x, y_weak_pos)[0, 1]\n",
        "\n",
        "corr_strong_neg = np.corrcoef(x, y_strong_neg)[0, 1]\n",
        "cov_strong_neg = np.cov(x, y_strong_neg)[0, 1]\n",
        "\n",
        "corr_no_corr = np.corrcoef(x, y_no_corr)[0, 1]\n",
        "cov_no_corr = np.cov(x, y_no_corr)[0, 1]\n",
        "\n",
        "# Print results\n",
        "print(f\"Strong positive correlation: {corr_strong_pos:.4f}, covariance: {cov_strong_pos:.4f}\")\n",
        "print(f\"Weak positive correlation: {corr_weak_pos:.4f}, covariance: {cov_weak_pos:.4f}\")\n",
        "print(f\"Strong negative correlation: {corr_strong_neg:.4f}, covariance: {cov_strong_neg:.4f}\")\n",
        "print(f\"No correlation: {corr_no_corr:.4f}, covariance: {cov_no_corr:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize correlations\n",
        "plt.figure(figsize=(16, 12))\n",
        "\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.scatter(x, y_strong_pos, alpha=0.6)\n",
        "plt.title(f'Strong Positive Correlation (r = {corr_strong_pos:.4f})')\n",
        "plt.xlabel('X')\n",
        "plt.ylabel('Y')\n",
        "\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.scatter(x, y_weak_pos, alpha=0.6)\n",
        "plt.title(f'Weak Positive Correlation (r = {corr_weak_pos:.4f})')\n",
        "plt.xlabel('X')\n",
        "plt.ylabel('Y')\n",
        "\n",
        "plt.subplot(2, 2, 3)\n",
        "plt.scatter(x, y_strong_neg, alpha=0.6)\n",
        "plt.title(f'Strong Negative Correlation (r = {corr_strong_neg:.4f})')\n",
        "plt.xlabel('X')\n",
        "plt.ylabel('Y')\n",
        "\n",
        "plt.subplot(2, 2, 4)\n",
        "plt.scatter(x, y_no_corr, alpha=0.6)\n",
        "plt.title(f'No Correlation (r = {corr_no_corr:.4f})')\n",
        "plt.xlabel('X')\n",
        "plt.ylabel('Y')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 5. Hypothesis Testing in ML\n",
        "\n",
        "Hypothesis testing helps us make decisions based on data, which is particularly useful in A/B testing, model comparison, and feature selection.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate data for two models' performance\n",
        "np.random.seed(42)\n",
        "model_a_scores = np.random.normal(loc=0.75, scale=0.05, size=30)\n",
        "model_b_scores = np.random.normal(loc=0.78, scale=0.05, size=30)\n",
        "\n",
        "# Perform t-test to compare models\n",
        "t_stat, p_value = stats.ttest_ind(model_a_scores, model_b_scores)\n",
        "\n",
        "# Print results\n",
        "print(f\"Model A average score: {np.mean(model_a_scores):.4f} ± {np.std(model_a_scores):.4f}\")\n",
        "print(f\"Model B average score: {np.mean(model_b_scores):.4f} ± {np.std(model_b_scores):.4f}\")\n",
        "print(f\"T-statistic: {t_stat:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "# Interpret results\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(f\"Reject null hypothesis: There is a statistically significant difference between models (p < {alpha})\")\n",
        "else:\n",
        "    print(f\"Fail to reject null hypothesis: No statistically significant difference between models (p >= {alpha})\")\n",
        "\n",
        "# Visualize comparison\n",
        "plt.figure(figsize=(10, 6))\n",
        "box_data = [model_a_scores, model_b_scores]\n",
        "sns.boxplot(data=box_data)\n",
        "plt.xticks([0, 1], ['Model A', 'Model B'])\n",
        "plt.ylabel('Performance Score')\n",
        "plt.title('Model Performance Comparison')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 6. Statistical Concepts in ML Algorithms\n",
        "\n",
        "Many machine learning algorithms are built on statistical foundations. Understanding these concepts helps in algorithm selection and hyperparameter tuning.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a simple dataset for linear regression\n",
        "np.random.seed(42)\n",
        "X = np.random.uniform(0, 10, 100).reshape(-1, 1)\n",
        "y = 2 * X.flatten() + 5 + np.random.normal(0, 2, 100)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Fit a linear regression model\n",
        "from sklearn.linear_model import LinearRegression\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_train = model.predict(X_train)\n",
        "y_pred_test = model.predict(X_test)\n",
        "\n",
        "# Calculate errors\n",
        "train_errors = y_train - y_pred_train\n",
        "test_errors = y_test - y_pred_test\n",
        "\n",
        "# Calculate statistical metrics\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "train_mse = mean_squared_error(y_train, y_pred_train)\n",
        "test_mse = mean_squared_error(y_test, y_pred_test)\n",
        "train_r2 = r2_score(y_train, y_pred_train)\n",
        "test_r2 = r2_score(y_test, y_pred_test)\n",
        "\n",
        "print(f\"Model coefficients: {model.coef_}\")\n",
        "print(f\"Model intercept: {model.intercept_}\")\n",
        "print(f\"Training MSE: {train_mse:.4f}\")\n",
        "print(f\"Test MSE: {test_mse:.4f}\")\n",
        "print(f\"Training R²: {train_r2:.4f}\")\n",
        "print(f\"Test R²: {test_r2:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize the linear regression model and error distribution\n",
        "plt.figure(figsize=(15, 10))\n",
        "\n",
        "# Plot the regression line\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.scatter(X_train, y_train, alpha=0.6, label='Training data')\n",
        "plt.scatter(X_test, y_test, alpha=0.6, label='Test data')\n",
        "plt.plot(X_train, y_pred_train, color='red', linewidth=2, label='Regression line')\n",
        "plt.title('Linear Regression Model')\n",
        "plt.xlabel('X')\n",
        "plt.ylabel('y')\n",
        "plt.legend()\n",
        "\n",
        "# Plot error distributions\n",
        "plt.subplot(2, 2, 2)\n",
        "sns.histplot(train_errors, kde=True, color='blue', label='Training errors')\n",
        "sns.histplot(test_errors, kde=True, color='red', label='Test errors')\n",
        "plt.title('Error Distribution')\n",
        "plt.xlabel('Error')\n",
        "plt.ylabel('Frequency')\n",
        "plt.legend()\n",
        "\n",
        "# Plot residuals\n",
        "plt.subplot(2, 2, 3)\n",
        "plt.scatter(y_pred_train, train_errors, alpha=0.6, label='Training')\n",
        "plt.scatter(y_pred_test, test_errors, alpha=0.6, label='Test')\n",
        "plt.axhline(y=0, color='red', linestyle='-')\n",
        "plt.title('Residual Plot')\n",
        "plt.xlabel('Predicted values')\n",
        "plt.ylabel('Residuals')\n",
        "plt.legend()\n",
        "\n",
        "# QQ plot to check normality of residuals\n",
        "plt.subplot(2, 2, 4)\n",
        "stats.probplot(np.concatenate([train_errors, test_errors]), plot=plt)\n",
        "plt.title('Q-Q Plot of Residuals')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 7. Conclusion\n",
        "\n",
        "Statistical concepts are the foundation of machine learning. Understanding these principles helps us:\n",
        "\n",
        "1. Better interpret model results and performance metrics\n",
        "2. Make informed decisions about algorithm selection\n",
        "3. Properly validate models and avoid overfitting\n",
        "4. Communicate findings effectively to stakeholders\n",
        "5. Design more robust experiments and evaluations\n",
        "\n",
        "As we move forward with more advanced ML techniques, these statistical foundations will continue to be crucial for success.\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
