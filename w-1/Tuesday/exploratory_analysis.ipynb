{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Exploratory Data Analysis (EDA)\n",
        "\n",
        "This notebook demonstrates exploratory data analysis techniques to understand patterns and relationships in data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "\n",
        "%matplotlib inline\n",
        "plt.style.use('seaborn-whitegrid')\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams['figure.figsize'] = (12, 8)\n",
        "\n",
        "print(\"Libraries imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Loading the Dataset\n",
        "\n",
        "We'll use the Iris dataset, a classic dataset for data analysis and visualization.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the Iris dataset from seaborn\n",
        "iris = sns.load_dataset('iris')\n",
        "\n",
        "# Display the first few rows\n",
        "print(\"First 5 rows of the Iris dataset:\")\n",
        "print(iris.head())\n",
        "\n",
        "# Dataset shape\n",
        "print(\"\\nDataset shape:\", iris.shape)\n",
        "\n",
        "# Basic information\n",
        "print(\"\\nDataset information:\")\n",
        "print(iris.info())\n",
        "\n",
        "# Basic statistics\n",
        "print(\"\\nBasic statistics:\")\n",
        "print(iris.describe())\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Statistical Summaries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Class distribution\n",
        "print(\"Class distribution:\")\n",
        "print(iris['species'].value_counts())\n",
        "print(\"\\nClass distribution (percentage):\")\n",
        "print(iris['species'].value_counts(normalize=True) * 100)\n",
        "\n",
        "# Group by species and calculate statistics\n",
        "print(\"\\nStatistics by species:\")\n",
        "species_stats = iris.groupby('species').describe().transpose()\n",
        "print(species_stats)\n",
        "\n",
        "# Calculate correlation matrix\n",
        "print(\"\\nCorrelation matrix:\")\n",
        "correlation_matrix = iris.corr()\n",
        "print(correlation_matrix)\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Data Distribution Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Histograms for each feature\n",
        "plt.figure(figsize=(15, 10))\n",
        "\n",
        "for i, feature in enumerate(['sepal_length', 'sepal_width', 'petal_length', 'petal_width']):\n",
        "    plt.subplot(2, 2, i+1)\n",
        "    for species in iris['species'].unique():\n",
        "        plt.hist(iris[iris['species'] == species][feature], \n",
        "                 alpha=0.7, \n",
        "                 bins=15, \n",
        "                 label=species)\n",
        "    plt.xlabel(feature)\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.title(f'Distribution of {feature}')\n",
        "    plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Kernel Density Estimation (KDE) plots\n",
        "plt.figure(figsize=(15, 10))\n",
        "\n",
        "for i, feature in enumerate(['sepal_length', 'sepal_width', 'petal_length', 'petal_width']):\n",
        "    plt.subplot(2, 2, i+1)\n",
        "    for species in iris['species'].unique():\n",
        "        sns.kdeplot(iris[iris['species'] == species][feature], \n",
        "                   label=species, \n",
        "                   shade=True)\n",
        "    plt.xlabel(feature)\n",
        "    plt.ylabel('Density')\n",
        "    plt.title(f'Density Distribution of {feature}')\n",
        "    plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Box plots for each feature by species\n",
        "plt.figure(figsize=(15, 10))\n",
        "\n",
        "for i, feature in enumerate(['sepal_length', 'sepal_width', 'petal_length', 'petal_width']):\n",
        "    plt.subplot(2, 2, i+1)\n",
        "    sns.boxplot(x='species', y=feature, data=iris)\n",
        "    plt.title(f'Box Plot of {feature} by Species')\n",
        "    plt.xlabel('Species')\n",
        "    plt.ylabel(feature)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Violin plots for each feature by species\n",
        "plt.figure(figsize=(15, 10))\n",
        "\n",
        "for i, feature in enumerate(['sepal_length', 'sepal_width', 'petal_length', 'petal_width']):\n",
        "    plt.subplot(2, 2, i+1)\n",
        "    sns.violinplot(x='species', y=feature, data=iris, inner='quartile')\n",
        "    plt.title(f'Violin Plot of {feature} by Species')\n",
        "    plt.xlabel('Species')\n",
        "    plt.ylabel(feature)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Correlation Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Correlation heatmap\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5)\n",
        "plt.title('Correlation Matrix Heatmap')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Pairplot to show relationships between features\n",
        "plt.figure(figsize=(15, 10))\n",
        "sns.pairplot(iris, hue='species', markers=['o', 's', 'D'], height=2.5)\n",
        "plt.suptitle('Pairplot of Iris Dataset Features by Species', y=1.02)\n",
        "plt.show()\n",
        "\n",
        "# Calculate correlation by species\n",
        "print(\"Correlation by species:\")\n",
        "for species in iris['species'].unique():\n",
        "    print(f\"\\nCorrelation matrix for {species}:\")\n",
        "    species_data = iris[iris['species'] == species].drop('species', axis=1)\n",
        "    print(species_data.corr())\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Dimensionality Reduction for Visualization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Principal Component Analysis (PCA)\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Standardize the features\n",
        "features = iris.drop('species', axis=1)\n",
        "X = StandardScaler().fit_transform(features)\n",
        "\n",
        "# Apply PCA\n",
        "pca = PCA(n_components=2)\n",
        "principal_components = pca.fit_transform(X)\n",
        "pca_df = pd.DataFrame(data=principal_components, columns=['PC1', 'PC2'])\n",
        "pca_df['species'] = iris['species']\n",
        "\n",
        "# Plot the PCA results\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.scatterplot(x='PC1', y='PC2', hue='species', data=pca_df, s=100, alpha=0.8)\n",
        "plt.title('PCA of Iris Dataset')\n",
        "plt.xlabel(f'Principal Component 1 ({pca.explained_variance_ratio_[0]:.2%} variance)')\n",
        "plt.ylabel(f'Principal Component 2 ({pca.explained_variance_ratio_[1]:.2%} variance)')\n",
        "plt.grid(True, linestyle='--', alpha=0.7)\n",
        "plt.legend(title='Species')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print explained variance ratio\n",
        "print(\"Explained variance ratio:\")\n",
        "print(pca.explained_variance_ratio_)\n",
        "print(f\"Total explained variance: {sum(pca.explained_variance_ratio_):.2%}\")\n",
        "\n",
        "# PCA loading scores\n",
        "loading_scores = pd.DataFrame(\n",
        "    data=pca.components_.T * np.sqrt(pca.explained_variance_), \n",
        "    columns=['PC1', 'PC2'],\n",
        "    index=features.columns\n",
        ")\n",
        "print(\"\\nPCA loading scores:\")\n",
        "print(loading_scores)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# t-SNE visualization\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "# Apply t-SNE\n",
        "tsne = TSNE(n_components=2, random_state=42)\n",
        "tsne_results = tsne.fit_transform(X)\n",
        "tsne_df = pd.DataFrame(data=tsne_results, columns=['t-SNE1', 't-SNE2'])\n",
        "tsne_df['species'] = iris['species']\n",
        "\n",
        "# Plot the t-SNE results\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.scatterplot(x='t-SNE1', y='t-SNE2', hue='species', data=tsne_df, s=100, alpha=0.8)\n",
        "plt.title('t-SNE of Iris Dataset')\n",
        "plt.xlabel('t-SNE Dimension 1')\n",
        "plt.ylabel('t-SNE Dimension 2')\n",
        "plt.grid(True, linestyle='--', alpha=0.7)\n",
        "plt.legend(title='Species')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Statistical Tests\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ANOVA test to check if there are significant differences between species\n",
        "from scipy.stats import f_oneway\n",
        "\n",
        "print(\"One-way ANOVA test results:\")\n",
        "for feature in ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']:\n",
        "    setosa = iris[iris['species'] == 'setosa'][feature]\n",
        "    versicolor = iris[iris['species'] == 'versicolor'][feature]\n",
        "    virginica = iris[iris['species'] == 'virginica'][feature]\n",
        "    \n",
        "    f_stat, p_value = f_oneway(setosa, versicolor, virginica)\n",
        "    print(f\"{feature}: F-statistic = {f_stat:.4f}, p-value = {p_value:.10f}\")\n",
        "    \n",
        "    if p_value < 0.05:\n",
        "        print(\"   Significant difference exists between species\\n\")\n",
        "    else:\n",
        "        print(\"   No significant difference between species\\n\")\n",
        "\n",
        "# Shapiro-Wilk test for normality\n",
        "from scipy.stats import shapiro\n",
        "\n",
        "print(\"Shapiro-Wilk test for normality:\")\n",
        "for feature in ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']:\n",
        "    stat, p = shapiro(iris[feature])\n",
        "    print(f\"{feature}: W = {stat:.4f}, p-value = {p:.10f}\")\n",
        "    \n",
        "    if p > 0.05:\n",
        "        print(\"   Data appears to be normally distributed\\n\")\n",
        "    else:\n",
        "        print(\"   Data does not appear to be normally distributed\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Correlation test (Pearson)\n",
        "from scipy.stats import pearsonr\n",
        "\n",
        "print(\"Pearson correlation tests:\")\n",
        "features = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n",
        "\n",
        "for i in range(len(features)):\n",
        "    for j in range(i+1, len(features)):\n",
        "        corr, p = pearsonr(iris[features[i]], iris[features[j]])\n",
        "        print(f\"{features[i]} vs {features[j]}: r = {corr:.4f}, p-value = {p:.10f}\")\n",
        "        \n",
        "        if p < 0.05:\n",
        "            if corr > 0:\n",
        "                print(f\"   Significant positive correlation\\n\")\n",
        "            else:\n",
        "                print(f\"   Significant negative correlation\\n\")\n",
        "        else:\n",
        "            print(f\"   No significant correlation\\n\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Identifying Clusters\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# K-means clustering\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Apply K-means with 3 clusters (since we know there are 3 species)\n",
        "kmeans = KMeans(n_clusters=3, random_state=42)\n",
        "kmeans_labels = kmeans.fit_predict(X)\n",
        "\n",
        "# Create a DataFrame with the results\n",
        "kmeans_df = pd.DataFrame(data=X, columns=features.columns)\n",
        "kmeans_df['cluster'] = kmeans_labels\n",
        "kmeans_df['actual_species'] = iris['species']\n",
        "\n",
        "# Map cluster numbers to species names for better comparison\n",
        "cluster_species_map = {}\n",
        "for cluster in range(3):\n",
        "    species_in_cluster = kmeans_df[kmeans_df['cluster'] == cluster]['actual_species'].value_counts()\n",
        "    dominant_species = species_in_cluster.idxmax()\n",
        "    cluster_species_map[cluster] = dominant_species\n",
        "\n",
        "kmeans_df['predicted_species'] = kmeans_df['cluster'].map(cluster_species_map)\n",
        "\n",
        "# Visualize clusters using PCA\n",
        "plt.figure(figsize=(15, 6))\n",
        "\n",
        "# Plot 1: K-means clusters\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.scatterplot(x=principal_components[:, 0], y=principal_components[:, 1], \n",
        "                hue=kmeans_labels, palette='viridis', s=100, alpha=0.8)\n",
        "plt.title('K-means Clustering (3 clusters)')\n",
        "plt.xlabel('Principal Component 1')\n",
        "plt.ylabel('Principal Component 2')\n",
        "plt.legend(title='Cluster')\n",
        "\n",
        "# Plot 2: Actual species\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.scatterplot(x=principal_components[:, 0], y=principal_components[:, 1], \n",
        "                hue=iris['species'], palette='viridis', s=100, alpha=0.8)\n",
        "plt.title('Actual Species')\n",
        "plt.xlabel('Principal Component 1')\n",
        "plt.ylabel('Principal Component 2')\n",
        "plt.legend(title='Species')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Confusion matrix between clusters and actual species\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "conf_matrix = confusion_matrix(iris['species'], kmeans_df['predicted_species'])\n",
        "conf_df = pd.DataFrame(conf_matrix, \n",
        "                      index=iris['species'].unique(), \n",
        "                      columns=iris['species'].unique())\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_df, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title('Confusion Matrix: Actual vs. Predicted Species')\n",
        "plt.xlabel('Predicted Species')\n",
        "plt.ylabel('Actual Species')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = (kmeans_df['actual_species'] == kmeans_df['predicted_species']).mean()\n",
        "print(f\"K-means clustering accuracy: {accuracy:.2%}\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Feature Importance Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Random Forest for feature importance\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Encode species labels\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(iris['species'])\n",
        "\n",
        "# Train Random Forest\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(X, y)\n",
        "\n",
        "# Get feature importance\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': features.columns,\n",
        "    'Importance': rf.feature_importances_\n",
        "}).sort_values('Importance', ascending=False)\n",
        "\n",
        "print(\"Feature importance:\")\n",
        "print(feature_importance)\n",
        "\n",
        "# Visualize feature importance\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x='Importance', y='Feature', data=feature_importance, palette='viridis')\n",
        "plt.title('Feature Importance from Random Forest')\n",
        "plt.xlabel('Importance')\n",
        "plt.ylabel('Feature')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Summary of Exploratory Data Analysis\n",
        "\n",
        "In this notebook, we've performed a comprehensive exploratory data analysis on the Iris dataset:\n",
        "\n",
        "1. **Data Inspection**\n",
        "   - Examined basic statistics and data structure\n",
        "   - Analyzed class distribution\n",
        "\n",
        "2. **Distribution Analysis**\n",
        "   - Created histograms and density plots to visualize feature distributions\n",
        "   - Used box plots and violin plots to compare distributions across species\n",
        "\n",
        "3. **Correlation Analysis**\n",
        "   - Calculated and visualized correlation matrices\n",
        "   - Created pairplots to show relationships between features\n",
        "   - Performed statistical tests to confirm correlations\n",
        "\n",
        "4. **Dimensionality Reduction**\n",
        "   - Applied PCA to reduce dimensions and visualize data\n",
        "   - Used t-SNE for non-linear dimensionality reduction\n",
        "   - Analyzed explained variance and feature contributions\n",
        "\n",
        "5. **Statistical Testing**\n",
        "   - Performed ANOVA tests to identify significant differences between species\n",
        "   - Tested for normality using Shapiro-Wilk test\n",
        "   - Conducted correlation tests to quantify relationships\n",
        "\n",
        "6. **Cluster Analysis**\n",
        "   - Applied K-means clustering to identify natural groupings\n",
        "   - Compared clusters with actual species labels\n",
        "   - Evaluated clustering accuracy\n",
        "\n",
        "7. **Feature Importance**\n",
        "   - Used Random Forest to determine feature importance\n",
        "   - Identified the most discriminative features for species classification\n",
        "\n",
        "These exploratory techniques have provided valuable insights into the structure and patterns within the Iris dataset, forming a solid foundation for subsequent modeling and analysis.\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
