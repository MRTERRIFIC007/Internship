{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Data Cleaning Techniques\n",
        "\n",
        "This notebook covers various techniques for identifying and addressing data quality issues.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "%matplotlib inline\n",
        "plt.style.use('seaborn-whitegrid')\n",
        "sns.set_style(\"whitegrid\")\n",
        "\n",
        "print(\"Libraries imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Creating a Sample Dataset with Common Data Quality Issues\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a sample dataset with various data quality issues\n",
        "data = {\n",
        "    'customer_id': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15],\n",
        "    'name': ['John Smith', 'Sarah Johnson', 'Michael Brown', 'Emily Davis', 'Robert Wilson', \n",
        "             'Jennifer Lee', 'David Miller', 'Lisa Wang', 'James Taylor', 'Amanda Garcia',\n",
        "             'Thomas Martin', np.nan, 'Kevin Lewis', 'Michelle Chen', 'Daniel White'],\n",
        "    'age': [34, -28, 45, 31, 39, 33, 41, 36, 44, 29, 52, 38, 27, 'forty', 35],\n",
        "    'email': ['john.smith@email.com', 'sarah.johnson@email.com', 'michael.b@email', 'emily.davis@email.com', \n",
        "              'robert.wilson@email.com', 'jennifer_lee@email.com', 'david.miller@email.com', 'lisa.wang@email.com', \n",
        "              'james.taylor@email.com', 'amanda.garcia@email.com', 'thomas.martin@email.com', 'kevin.lewis@email.com', \n",
        "              'michelle.chen@email.com', 'daniel.white@email.com', 'daniel.white@email.com'],\n",
        "    'purchase_amount': [125.99, 89.50, 250.00, np.nan, 175.25, 0, 99.99, 145.75, 65.50, 199.99, \n",
        "                        145.00, 79.99, 299.99, 129.50, 1999.99],\n",
        "    'purchase_date': ['2023-01-15', '2023-01-16', '2023/01/17', '2023-01-18', '01-19-2023', \n",
        "                     '2023-01-20', '2023-01-21', '2023-01-22', '2023-01-23', '2023-01-24',\n",
        "                     '2023-01-25', '2023-01-26', '2023-01-27', '2023-01-28', '2023-01-29'],\n",
        "    'category': ['Electronics', 'Clothing', 'Electronics', 'Home', 'Electronics', \n",
        "                'Clothing', 'Sports', 'Home', 'Books', 'Electronics',\n",
        "                'Books', 'Sports', 'Electronics', 'Clothing', 'electronics'],\n",
        "    'is_member': ['Yes', 'No', 'Yes', 'No', 'Yes', 'Yes', 'No', 'Yes', 'No', 'Yes', \n",
        "                 'Y', 'N', 'TRUE', 'FALSE', '1'],\n",
        "    'discount_code': ['DISC10', 'DISC20', np.nan, 'DISC10', 'DISC20', 'DISC10', np.nan, 'DISC20', \n",
        "                     'DISC10', 'DISC20', 'DISC10', 'DISC20', 'DISC10', 'DISC20', 'DISC10']\n",
        "}\n",
        "\n",
        "# Create DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Display the data\n",
        "print(\"Sample dataset with data quality issues:\")\n",
        "print(df.head(15))\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Initial Data Inspection\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Basic information about the dataset\n",
        "print(\"Dataset shape:\", df.shape)\n",
        "print(\"\\nData types:\")\n",
        "print(df.dtypes)\n",
        "\n",
        "print(\"\\nBasic statistics:\")\n",
        "print(df.describe(include='all'))\n",
        "\n",
        "print(\"\\nMissing values count:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "print(\"\\nDuplicate rows count:\", df.duplicated().sum())\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Handling Missing Values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize missing values\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.heatmap(df.isnull(), cbar=False, cmap='viridis', yticklabels=False)\n",
        "plt.title('Missing Values Heatmap')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Handle missing values\n",
        "df_clean = df.copy()\n",
        "\n",
        "# 1. Fill missing names with \"Unknown\"\n",
        "df_clean['name'] = df_clean['name'].fillna('Unknown')\n",
        "\n",
        "# 2. Fill missing purchase amounts with the mean\n",
        "mean_purchase = df_clean['purchase_amount'].mean()\n",
        "df_clean['purchase_amount'] = df_clean['purchase_amount'].fillna(mean_purchase)\n",
        "\n",
        "# 3. Fill missing discount codes with \"NONE\"\n",
        "df_clean['discount_code'] = df_clean['discount_code'].fillna('NONE')\n",
        "\n",
        "# Check if missing values were handled\n",
        "print(\"Missing values after handling:\")\n",
        "print(df_clean.isnull().sum())\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Handling Data Type Issues\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fix the age column\n",
        "print(\"Age column before cleaning:\")\n",
        "print(df_clean['age'].head(15))\n",
        "\n",
        "# Convert age to numeric, errors become NaN\n",
        "df_clean['age'] = pd.to_numeric(df_clean['age'], errors='coerce')\n",
        "\n",
        "# Replace negative ages with absolute value\n",
        "df_clean['age'] = df_clean['age'].apply(lambda x: abs(x) if not pd.isna(x) and x < 0 else x)\n",
        "\n",
        "# Fill NaN values with median age\n",
        "median_age = df_clean['age'].median()\n",
        "df_clean['age'] = df_clean['age'].fillna(median_age)\n",
        "\n",
        "# Convert to integer\n",
        "df_clean['age'] = df_clean['age'].astype(int)\n",
        "\n",
        "print(\"\\nAge column after cleaning:\")\n",
        "print(df_clean['age'].head(15))\n",
        "\n",
        "# Standardize date format\n",
        "print(\"\\nPurchase date before cleaning:\")\n",
        "print(df_clean['purchase_date'].head(15))\n",
        "\n",
        "# Function to standardize date format\n",
        "def standardize_date(date_str):\n",
        "    try:\n",
        "        # Try different date formats\n",
        "        for fmt in ('%Y-%m-%d', '%Y/%m/%d', '%m-%d-%Y'):\n",
        "            try:\n",
        "                return pd.to_datetime(date_str, format=fmt).strftime('%Y-%m-%d')\n",
        "            except:\n",
        "                continue\n",
        "        return pd.to_datetime(date_str).strftime('%Y-%m-%d')\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "# Apply the function\n",
        "df_clean['purchase_date'] = df_clean['purchase_date'].apply(standardize_date)\n",
        "\n",
        "print(\"\\nPurchase date after cleaning:\")\n",
        "print(df_clean['purchase_date'].head(15))\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Standardizing Categorical Variables\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Standardize category names (convert to title case)\n",
        "print(\"Categories before standardization:\")\n",
        "print(df_clean['category'].value_counts())\n",
        "\n",
        "df_clean['category'] = df_clean['category'].str.title()\n",
        "\n",
        "print(\"\\nCategories after standardization:\")\n",
        "print(df_clean['category'].value_counts())\n",
        "\n",
        "# Standardize is_member column\n",
        "print(\"\\nMembership status before standardization:\")\n",
        "print(df_clean['is_member'].value_counts())\n",
        "\n",
        "# Map various values to True/False\n",
        "membership_map = {\n",
        "    'Yes': True, 'Y': True, 'TRUE': True, '1': True, 1: True,\n",
        "    'No': False, 'N': False, 'FALSE': False, '0': False, 0: False\n",
        "}\n",
        "\n",
        "df_clean['is_member'] = df_clean['is_member'].map(membership_map)\n",
        "\n",
        "print(\"\\nMembership status after standardization:\")\n",
        "print(df_clean['is_member'].value_counts())\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Handling Duplicates\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check for duplicate customer IDs\n",
        "print(\"Duplicate customer IDs:\")\n",
        "print(df_clean[df_clean.duplicated(subset=['customer_id'], keep=False)])\n",
        "\n",
        "# Check for duplicate emails\n",
        "print(\"\\nDuplicate emails:\")\n",
        "duplicate_emails = df_clean[df_clean.duplicated(subset=['email'], keep=False)]\n",
        "print(duplicate_emails)\n",
        "\n",
        "# Remove duplicate emails (keep first occurrence)\n",
        "df_clean = df_clean.drop_duplicates(subset=['email'], keep='first')\n",
        "\n",
        "print(\"\\nDataset shape after removing duplicates:\", df_clean.shape)\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Handling Outliers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Detect outliers in purchase_amount using box plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.boxplot(x=df_clean['purchase_amount'])\n",
        "plt.title('Purchase Amount Distribution')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Calculate IQR for purchase_amount\n",
        "Q1 = df_clean['purchase_amount'].quantile(0.25)\n",
        "Q3 = df_clean['purchase_amount'].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "# Define outlier boundaries\n",
        "lower_bound = Q1 - 1.5 * IQR\n",
        "upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "print(f\"Outlier boundaries for purchase_amount: Lower = {lower_bound:.2f}, Upper = {upper_bound:.2f}\")\n",
        "\n",
        "# Identify outliers\n",
        "outliers = df_clean[(df_clean['purchase_amount'] < lower_bound) | \n",
        "                    (df_clean['purchase_amount'] > upper_bound)]\n",
        "\n",
        "print(\"\\nOutliers in purchase_amount:\")\n",
        "print(outliers[['customer_id', 'name', 'purchase_amount']])\n",
        "\n",
        "# Handle outliers - cap at boundaries\n",
        "df_clean_no_outliers = df_clean.copy()\n",
        "df_clean_no_outliers['purchase_amount'] = df_clean_no_outliers['purchase_amount'].clip(lower=lower_bound, upper=upper_bound)\n",
        "\n",
        "print(\"\\nPurchase amounts after handling outliers:\")\n",
        "print(df_clean_no_outliers[['customer_id', 'name', 'purchase_amount']].head(15))\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Data Validation and Correction\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Validate and correct email addresses\n",
        "def validate_email(email):\n",
        "    if pd.isna(email):\n",
        "        return email\n",
        "    \n",
        "    # Check if email contains @ and .\n",
        "    if '@' not in email or '.' not in email.split('@')[1]:\n",
        "        return None\n",
        "    \n",
        "    return email\n",
        "\n",
        "# Apply validation\n",
        "df_clean_no_outliers['email_valid'] = df_clean_no_outliers['email'].apply(validate_email)\n",
        "\n",
        "# Show invalid emails\n",
        "invalid_emails = df_clean_no_outliers[df_clean_no_outliers['email_valid'].isna()]\n",
        "print(\"Invalid email addresses:\")\n",
        "print(invalid_emails[['customer_id', 'name', 'email']])\n",
        "\n",
        "# Correct specific email (example)\n",
        "df_clean_no_outliers.loc[df_clean_no_outliers['customer_id'] == 3, 'email'] = 'michael.brown@email.com'\n",
        "df_clean_no_outliers.loc[df_clean_no_outliers['customer_id'] == 3, 'email_valid'] = 'michael.brown@email.com'\n",
        "\n",
        "print(\"\\nAfter correction:\")\n",
        "print(df_clean_no_outliers.loc[df_clean_no_outliers['customer_id'] == 3, ['customer_id', 'name', 'email', 'email_valid']])\n",
        "\n",
        "# Remove the temporary validation column\n",
        "df_clean_no_outliers = df_clean_no_outliers.drop(columns=['email_valid'])\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## String Manipulation for Text Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split name into first_name and last_name\n",
        "df_clean_no_outliers[['first_name', 'last_name']] = df_clean_no_outliers['name'].str.split(' ', n=1, expand=True)\n",
        "\n",
        "# Handle cases where last_name might be None\n",
        "df_clean_no_outliers['last_name'] = df_clean_no_outliers['last_name'].fillna('')\n",
        "\n",
        "print(\"Names split into first and last name:\")\n",
        "print(df_clean_no_outliers[['name', 'first_name', 'last_name']].head(15))\n",
        "\n",
        "# Standardize discount codes (uppercase)\n",
        "df_clean_no_outliers['discount_code'] = df_clean_no_outliers['discount_code'].str.upper()\n",
        "\n",
        "print(\"\\nStandardized discount codes:\")\n",
        "print(df_clean_no_outliers['discount_code'].value_counts())\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Final Cleaned Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Review the final cleaned dataset\n",
        "print(\"Original dataset shape:\", df.shape)\n",
        "print(\"Cleaned dataset shape:\", df_clean_no_outliers.shape)\n",
        "\n",
        "# Final data types\n",
        "print(\"\\nData types after cleaning:\")\n",
        "print(df_clean_no_outliers.dtypes)\n",
        "\n",
        "# Basic statistics of cleaned data\n",
        "print(\"\\nBasic statistics of cleaned data:\")\n",
        "print(df_clean_no_outliers.describe())\n",
        "\n",
        "# Save the cleaned dataset to CSV\n",
        "df_clean_no_outliers.to_csv('cleaned_customer_data.csv', index=False)\n",
        "print(\"\\nCleaned dataset saved to 'cleaned_customer_data.csv'\")\n",
        "\n",
        "# Compare original and cleaned data\n",
        "print(\"\\nComparison of original vs cleaned data:\")\n",
        "comparison = pd.DataFrame({\n",
        "    'Original': df.dtypes,\n",
        "    'Cleaned': df_clean_no_outliers.dtypes\n",
        "})\n",
        "print(comparison)\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Summary of Data Cleaning Steps\n",
        "\n",
        "In this notebook, we've performed the following data cleaning operations:\n",
        "\n",
        "1. **Initial Data Inspection**\n",
        "   - Examined data types, basic statistics, and identified issues\n",
        "\n",
        "2. **Handling Missing Values**\n",
        "   - Visualized missing values with a heatmap\n",
        "   - Filled missing names with \"Unknown\"\n",
        "   - Filled missing purchase amounts with the mean\n",
        "   - Filled missing discount codes with \"NONE\"\n",
        "\n",
        "3. **Handling Data Type Issues**\n",
        "   - Converted age to numeric and fixed negative values\n",
        "   - Standardized date formats across different input styles\n",
        "\n",
        "4. **Standardizing Categorical Variables**\n",
        "   - Standardized category names to title case\n",
        "   - Converted various representations of Yes/No to boolean values\n",
        "\n",
        "5. **Handling Duplicates**\n",
        "   - Identified duplicate emails\n",
        "   - Removed duplicate records keeping the first occurrence\n",
        "\n",
        "6. **Handling Outliers**\n",
        "   - Detected outliers in purchase amounts using IQR method\n",
        "   - Capped outliers at lower and upper boundaries\n",
        "\n",
        "7. **Data Validation and Correction**\n",
        "   - Validated email addresses for proper format\n",
        "   - Corrected invalid email addresses\n",
        "\n",
        "8. **String Manipulation**\n",
        "   - Split full names into first and last names\n",
        "   - Standardized discount codes to uppercase\n",
        "\n",
        "These steps have transformed our raw data with various quality issues into a clean, consistent dataset ready for analysis.\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
